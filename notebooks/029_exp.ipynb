{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450ce170",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1602084551218-a28205125639?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2070&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0cc7c",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'\n",
    "     style = 'background-color:#4c1c84;\n",
    "              color:#eeebf1;\n",
    "              border-width:5px;\n",
    "              border-color:#4c1c84;\n",
    "              font-family:Comic Sans MS;\n",
    "              border-radius: 50px 50px'>\n",
    "    <p style = 'font-size:24px'>Exp 029</p>\n",
    "    <a href = \"#Config\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">1.Config</a><br>\n",
    "    <a href = \"#Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">2.Settings</a><br>\n",
    "    <a href = \"#Data-Load\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">3.Data Load</a><br>\n",
    "    <a href = \"#Pytorch-Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">4.Pytorch Settings</a><br>\n",
    "    <a href = \"#Training\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">5.Training</a><br>\n",
    "</div>\n",
    "\n",
    "<p style = 'font-size:24px;\n",
    "            color:#4c1c84'>\n",
    "    実施したこと\n",
    "</p>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">使用データ:toxic-span</li>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">使用モデル:RoBERTa-Base</li>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">Attentionの可視化</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4303d2f4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Config\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93706376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/utils/iterative-stratification/\")\n",
    "sys.path.append(\"../src/utils/detoxify\")\n",
    "sys.path.append(\"../src/utils/coral-pytorch/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da816136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 10:12:32.965872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import psutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "from box import Box\n",
    "from typing import Optional\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from tqdm.auto import tqdm as tqdmp\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "tqdmp.pandas()\n",
    "\n",
    "## Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from transformers import RobertaModel, RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import LukeTokenizer, LukeModel, LukeConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from transformers import DebertaTokenizer, DebertaModel\n",
    "\n",
    "# Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning import LightningDataModule, LightningDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import rankdata\n",
    "from cuml.svm import SVR as cuml_SVR\n",
    "from cuml.linear_model import Ridge as cuml_Ridge\n",
    "import cudf\n",
    "from detoxify import Detoxify\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3660636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "config = {\n",
    "    \"exp_comment\":\"toxic-spanをRoBERTaで学習\",\n",
    "    \"seed\": 42,\n",
    "    \"root\": \"/content/drive/MyDrive/kaggle/Jigsaw/raw\",\n",
    "    \"n_fold\": 5,\n",
    "    \"epoch\": 5,\n",
    "    \"max_length\": 256,\n",
    "    \"environment\": \"AWS\",\n",
    "    \"project\": \"Jigsaw\",\n",
    "    \"entity\": \"dataskywalker\",\n",
    "    \"exp_name\": \"029_exp\",\n",
    "    \"margin\": 0.5,\n",
    "    \"train_fold\": [0, 1, 2, 3, 4],\n",
    "\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 1,\n",
    "        \"accumulate_grad_batches\": 8,\n",
    "        \"progress_bar_refresh_rate\": 1,\n",
    "        \"fast_dev_run\": True,\n",
    "        \"num_sanity_val_steps\": 0,\n",
    "    },\n",
    "\n",
    "    \"train_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": True,\n",
    "    },\n",
    "\n",
    "    \"valid_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"test_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"backbone\": {\n",
    "        \"name\": \"roberta-base\",\n",
    "        \"output_dim\": 1,\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"torch.optim.AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 1e-6,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"name\": \"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\",\n",
    "        \"params\": {\n",
    "            \"T_0\": 20,\n",
    "            \"eta_min\": 0,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"loss\": \"nn.BCEWithLogitsLoss\",\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "config.tokenizer = RobertaTokenizer.from_pretrained(config.backbone.name)\n",
    "config.model = RobertaModel.from_pretrained(config.backbone.name)\n",
    "# pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82bf5bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config.tokenizer.save_pretrained(f\"../data/processed/{config.backbone.name}\")\n",
    "\n",
    "pretrain_model = RobertaModel.from_pretrained(config.backbone.name)\n",
    "pretrain_model.save_pretrained(f\"../data/processed/{config.backbone.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d6a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your environment is 'AWS'.\n",
      "INPUT_DIR is /mnt/work/data/kaggle/Jigsaw\n",
      "MODEL_DIR is ../models/029_exp\n",
      "OUTPUT_DIR is ../data/interim/029_exp\n",
      "UTIL_DIR is /mnt/work/shimizu/kaggle/PetFinder/src/utils\n"
     ]
    }
   ],
   "source": [
    "# 個人的にAWSやKaggle環境やGoogle Colabを行ったり来たりしているのでまとめています\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if config.environment == 'AWS':\n",
    "    \n",
    "    INPUT_DIR = Path('/mnt/work/data/kaggle/Jigsaw/')\n",
    "    MODEL_DIR = Path(f'../models/{config.exp_name}/')\n",
    "    OUTPUT_DIR = Path(f'../data/interim/{config.exp_name}/')\n",
    "    UTIL_DIR = Path('/mnt/work/shimizu/kaggle/PetFinder/src/utils')\n",
    "    \n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"Your environment is 'AWS'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\\nUTIL_DIR is {UTIL_DIR}\")\n",
    "    \n",
    "    \n",
    "elif config.environment == 'Kaggle':\n",
    "    INPUT_DIR = Path('../input/*****')\n",
    "    MODEL_DIR = Path('./')\n",
    "    OUTPUT_DIR = Path('./')\n",
    "    print(f\"Your environment is 'Kaggle'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "\n",
    "    \n",
    "elif config.environment == 'Colab':\n",
    "    INPUT_DIR = Path('/content/drive/MyDrive/kaggle/Jigsaw/raw')\n",
    "    BASE_DIR = Path(\"/content/drive/MyDrive/kaggle/Jigsaw/interim\")\n",
    "\n",
    "    MODEL_DIR = BASE_DIR / f'{config.exp_name}'\n",
    "    OUTPUT_DIR = BASE_DIR / f'{config.exp_name}/'\n",
    "\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print('Please Mount your Google Drive.')\n",
    "    else:\n",
    "        print(f\"Your environment is 'Colab'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please choose 'AWS' or 'Kaggle' or 'Colab'.\\nINPUT_DIR is not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319fe5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed固定\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593eb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 処理時間計測\n",
    "@contextmanager\n",
    "def timer(name:str, slack:bool=False):\n",
    "    t0 = time.time()\n",
    "    p = psutil.Process(os.getpid())\n",
    "    m0 = p.memory_info()[0] / 2. ** 30\n",
    "    print(f'<< {name} >> Start')\n",
    "    yield\n",
    "    \n",
    "    m1 = p.memory_info()[0] / 2. ** 30\n",
    "    delta = m1 - m0\n",
    "    sign = '+' if delta >= 0 else '-'\n",
    "    delta = math.fabs(delta)\n",
    "    \n",
    "    print(f\"<< {name} >> {m1:.1f}GB({sign}{delta:.1f}GB):{time.time() - t0:.1f}sec\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a36c9c",
   "metadata": {
    "id": "zWE2XhHeTFos"
   },
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Data Load\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b62715",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DFxNX0CTD9t",
    "outputId": "240b449b-9f09-4519-d155-b4f865053621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/sample_submission.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "## Data Check\n",
    "for dirnames, _, filenames in os.walk(INPUT_DIR):\n",
    "    \n",
    "    for filename in filenames:\n",
    "\n",
    "        print(f'{dirnames}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd052cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1      732895  Looks like be have an abuser , can you please ...\n",
       "2     1139051  I confess to having complete (and apparently b...\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4     2084821  It is not just you. This is a laundry list of ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/validation_data.csv\")\n",
    "test_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\")\n",
    "\n",
    "display(val_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a5182",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal; \n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center;\n",
    "             border-radius: 100px 100px;\">\n",
    "    Toxic-Span\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98944e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239607</td>\n",
       "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239612</td>\n",
       "      <td>This bitch is nuts. Who would read a book by a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240311</td>\n",
       "      <td>You're an idiot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240400</td>\n",
       "      <td>Nincompoop, that's a nice one! I'm partial to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240461</td>\n",
       "      <td>testing purposes: \\n\\nyou are an idiot and i c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                       comment_text\n",
       "0      239607  Yet call out all Muslims for the acts of a few...\n",
       "1      239612  This bitch is nuts. Who would read a book by a...\n",
       "2      240311                                   You're an idiot.\n",
       "3      240400  Nincompoop, that's a nice one! I'm partial to ...\n",
       "4      240461  testing purposes: \\n\\nyou are an idiot and i c..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>worker</th>\n",
       "      <th>country</th>\n",
       "      <th>all toxic</th>\n",
       "      <th>not toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5167187</td>\n",
       "      <td>868</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5167187</td>\n",
       "      <td>1316</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5167187</td>\n",
       "      <td>1295</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5167187</td>\n",
       "      <td>2856</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5521110</td>\n",
       "      <td>418</td>\n",
       "      <td>VEN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation  comment_id  worker country  all toxic  not toxic\n",
       "0           0     5167187     868     USA      False      False\n",
       "1           1     5167187    1316     USA      False      False\n",
       "2           2     5167187    1295     USA      False       True\n",
       "3           3     5167187    2856     USA      False      False\n",
       "4           4     5521110     418     VEN       True       True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comment_df = pd.read_csv(\"../data/external/toxic_spans/data/comments.csv\")\n",
    "anno_df = pd.read_csv(\"../data/external/toxic_spans/data/annotations.csv\")\n",
    "\n",
    "display(comment_df.head())\n",
    "display(anno_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d03464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>worker</th>\n",
       "      <th>country</th>\n",
       "      <th>all toxic</th>\n",
       "      <th>not toxic</th>\n",
       "      <th>all_toxic</th>\n",
       "      <th>not_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5167187</td>\n",
       "      <td>868</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5167187</td>\n",
       "      <td>1316</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5167187</td>\n",
       "      <td>1295</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5167187</td>\n",
       "      <td>2856</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5521110</td>\n",
       "      <td>418</td>\n",
       "      <td>VEN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation  comment_id  worker country  all toxic  not toxic  all_toxic  \\\n",
       "0           0     5167187     868     USA      False      False          0   \n",
       "1           1     5167187    1316     USA      False      False          0   \n",
       "2           2     5167187    1295     USA      False       True          0   \n",
       "3           3     5167187    2856     USA      False      False          0   \n",
       "4           4     5521110     418     VEN       True       True          1   \n",
       "\n",
       "   not_toxic  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anno_df[\"all_toxic\"] = anno_df[\"all toxic\"].astype(\"int\")\n",
    "anno_df[\"not_toxic\"] = anno_df[\"not toxic\"].astype(\"int\")\n",
    "display(anno_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a120791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_toxic</th>\n",
       "      <th>not_toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239607</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239612</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240311</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240400</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240461</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            all_toxic  not_toxic\n",
       "comment_id                      \n",
       "239607       0.333333   0.333333\n",
       "239612       0.333333   0.666667\n",
       "240311       0.000000   0.000000\n",
       "240400       0.000000   0.000000\n",
       "240461       0.000000   0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>all_toxic</th>\n",
       "      <th>not_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239607</td>\n",
       "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239612</td>\n",
       "      <td>This bitch is nuts. Who would read a book by a...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240311</td>\n",
       "      <td>You're an idiot.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240400</td>\n",
       "      <td>Nincompoop, that's a nice one! I'm partial to ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240461</td>\n",
       "      <td>testing purposes: \\n\\nyou are an idiot and i c...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                       comment_text  all_toxic  \\\n",
       "0      239607  Yet call out all Muslims for the acts of a few...   0.333333   \n",
       "1      239612  This bitch is nuts. Who would read a book by a...   0.333333   \n",
       "2      240311                                   You're an idiot.   0.000000   \n",
       "3      240400  Nincompoop, that's a nice one! I'm partial to ...   0.000000   \n",
       "4      240461  testing purposes: \\n\\nyou are an idiot and i c...   0.000000   \n",
       "\n",
       "   not_toxic  \n",
       "0   0.333333  \n",
       "1   0.666667  \n",
       "2   0.000000  \n",
       "3   0.000000  \n",
       "4   0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anno_df_v2 = anno_df.groupby(\"comment_id\")[\"all_toxic\", \"not_toxic\"].agg(\"mean\")\n",
    "display(anno_df_v2.head())\n",
    "\n",
    "\n",
    "train_df = pd.merge(\n",
    "    comment_df,\n",
    "    anno_df_v2,\n",
    "    on=\"comment_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f7ddf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cols = [\n",
    "    \"all_toxic\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(train_df[\"all_toxic\"], color=\"#4c1c84\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59edfec8",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Pytorch Dataset\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9152f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset:\n",
    "    \n",
    "    def __init__(self, df, tokenizer, max_length, mode, target_cols):\n",
    "        \n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mode = mode\n",
    "        self.target_cols = target_cols\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            self.text = df[\"comment_text\"].values\n",
    "            self.target = df[target_cols].values\n",
    "            \n",
    "        elif self.mode == \"valid\":\n",
    "            self.more_toxic = df[\"more_toxic\"].values\n",
    "            self.less_toxic = df[\"less_toxic\"].values\n",
    "            \n",
    "        else:\n",
    "            self.text = df[\"text\"].values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            \n",
    "            text = self.text[index]\n",
    "            target = self.target[index]\n",
    "            \n",
    "            inputs_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            text_ids = inputs_text[\"input_ids\"]\n",
    "            text_mask = inputs_text[\"attention_mask\"]\n",
    "            text_token_type_ids = inputs_text[\"token_type_ids\"]\n",
    "\n",
    "            return {\n",
    "                'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
    "                'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
    "                'text_token_type_ids': torch.tensor(text_token_type_ids, dtype=torch.long),\n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        elif self.mode == \"valid\":\n",
    "            \n",
    "            more_toxic = self.more_toxic[index]\n",
    "            less_toxic = self.less_toxic[index]\n",
    "\n",
    "            inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                more_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "\n",
    "            inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                less_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            target = 1\n",
    "\n",
    "            more_toxic_ids = inputs_more_toxic[\"input_ids\"]\n",
    "            more_toxic_mask = inputs_more_toxic[\"attention_mask\"]\n",
    "            more_token_type_ids = inputs_more_toxic[\"token_type_ids\"]\n",
    "\n",
    "            less_toxic_ids = inputs_less_toxic[\"input_ids\"]\n",
    "            less_toxic_mask = inputs_less_toxic[\"attention_mask\"]\n",
    "            less_token_type_ids = inputs_less_toxic[\"token_type_ids\"]\n",
    "            \n",
    "            return {\n",
    "                'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n",
    "                'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n",
    "                'more_token_type_ids': torch.tensor(more_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n",
    "                'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n",
    "                'less_token_type_ids': torch.tensor(less_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            text = self.text[index]\n",
    "            \n",
    "            inputs_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            text_ids = inputs_text[\"input_ids\"]\n",
    "            text_mask = inputs_text[\"attention_mask\"]\n",
    "            text_token_type_ids = inputs_text[\"token_type_ids\"]\n",
    "\n",
    "            return {\n",
    "                'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
    "                'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
    "                'text_token_type_ids': torch.tensor(text_token_type_ids, dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e15058",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    DataModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50909d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, valid_df, test_df, cfg):\n",
    "\n",
    "        super().__init__()\n",
    "        self._train_df = train_df\n",
    "        self._valid_df = valid_df\n",
    "        self._test_df = test_df\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._train_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"train\",\n",
    "            target_cols=target_cols\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._valid_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"valid\",\n",
    "            target_cols=target_cols\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.valid_loader)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._test_df,\n",
    "            tokenizer = self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"test\",\n",
    "            target_cols=target_cols\n",
    "        )\n",
    "\n",
    "        return DataLoader(dataset, **self._cfg.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0472b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataCheck\n",
    "seed_everything(config.seed)\n",
    "\n",
    "sample_dataloader = JigsawDataModule(train_df, val_df, test_df, config).train_dataloader()\n",
    "for data in sample_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78974a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 1])\n",
      "tensor([[0.6667],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.7143],\n",
      "        [0.4286]])\n",
      "torch.Size([8, 256, 768]) torch.Size([8, 12, 256, 256])\n",
      "torch.Size([8, 768]) torch.Size([8, 12, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text_ids\"].size())\n",
    "print(data[\"text_mask\"].size())\n",
    "print(data[\"text_token_type_ids\"].size())\n",
    "print(data[\"target\"].size())\n",
    "print(data[\"target\"])\n",
    "output = config.model(\n",
    "    data[\"text_ids\"],\n",
    "    data[\"text_mask\"],\n",
    "    data[\"text_token_type_ids\"],\n",
    "    output_attentions=True\n",
    ")\n",
    "print(output[\"last_hidden_state\"].size(), output[\"attentions\"][-1].size())\n",
    "print(output[\"last_hidden_state\"][:, 0, :].size(), output[\"attentions\"][-1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f6e22",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    LigitningModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e7d5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, cfg, fold_num):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self.criterion = eval(self.cfg.loss)()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.fold_num = fold_num\n",
    "        \n",
    "    def __build_model(self):\n",
    "        \n",
    "        self.base_model = RobertaModel.from_pretrained(\n",
    "            self.cfg.backbone.name\n",
    "        )\n",
    "        print(f\"Use Model: {self.cfg.backbone.name}\")\n",
    "        self.norm = nn.LayerNorm(768)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.head = nn.Linear(768, self.cfg.backbone.output_dim)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        \n",
    "        output = self.base_model(\n",
    "            input_ids=ids, \n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True\n",
    "        )\n",
    "        feature = self.norm(output[\"last_hidden_state\"][:, 0, :])\n",
    "        out = self.drop(feature)\n",
    "        out = self.head(out)\n",
    "        \n",
    "        return {\n",
    "            \"logits\":out, \n",
    "            \"attention\":output[\"attentions\"], \n",
    "            \"mask\":mask,\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        text_ids = batch[\"text_ids\"]\n",
    "        text_mask = batch['text_mask']\n",
    "        text_token_type_ids = batch['text_token_type_ids']\n",
    "        targets = batch['target']\n",
    "        \n",
    "        outputs = self.forward(text_ids, text_mask, text_token_type_ids)\n",
    "        loss = self.criterion(outputs[\"logits\"], targets)\n",
    "        \n",
    "        return {\n",
    "            \"loss\":loss,\n",
    "            \"targets\":targets,\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "\n",
    "        for out in training_step_outputs:\n",
    "\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "\n",
    "        logs = {f\"train_loss/fold{self.fold_num+1}\": meanloss,}\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        more_toxic_ids = batch['more_toxic_ids']\n",
    "        more_toxic_mask = batch['more_toxic_mask']\n",
    "        more_text_token_type_ids = batch['more_token_type_ids']\n",
    "        \n",
    "        less_toxic_ids = batch['less_toxic_ids']\n",
    "        less_toxic_mask = batch['less_toxic_mask']\n",
    "        less_text_token_type_ids = batch['less_token_type_ids']\n",
    "        \n",
    "        targets = batch['target']\n",
    "\n",
    "        more_outputs = self.forward(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        less_outputs = self.forward(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        \n",
    "        more_outputs = torch.sum(more_outputs[\"logits\"], 1)\n",
    "        less_outputs = torch.sum(less_outputs[\"logits\"], 1)\n",
    "        \n",
    "        outputs = more_outputs - less_outputs\n",
    "        logits = outputs.clone()\n",
    "\n",
    "        logits[logits > 0] = 1\n",
    "        loss = self.criterion(logits, targets)\n",
    "\n",
    "        return {\n",
    "            \"loss\":loss,\n",
    "            \"pred\":outputs,\n",
    "            \"targets\":targets,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "        pred_list = []\n",
    "        target_list = []\n",
    "\n",
    "        for out in validation_step_outputs:\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "            pred_list.append(out[\"pred\"].detach().cpu().numpy())\n",
    "            target_list.append(out[\"targets\"].detach().cpu().numpy())\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "        pred_list = np.concatenate(pred_list)\n",
    "        pred_count = sum(x>0 for x in pred_list)/len(pred_list)\n",
    "\n",
    "        logs = {\n",
    "            f\"valid_loss/fold{self.fold_num+1}\":meanloss,\n",
    "            f\"valid_acc/fold{self.fold_num+1}\":pred_count,\n",
    "        }\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = eval(self.cfg.optimizer.name)(\n",
    "            self.parameters(), **self.cfg.optimizer.params\n",
    "        )\n",
    "\n",
    "        self.scheduler = eval(self.cfg.scheduler.name)(\n",
    "            optimizer, **self.cfg.scheduler.params\n",
    "        )\n",
    "        \n",
    "        scheduler = {\"scheduler\": self.scheduler, \"interval\": \"step\",}\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52250ed4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    Training\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38818e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, uniques = pd.factorize(train_df[\"all_toxic\"], sort=True)\n",
    "train_df[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdcc6382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>all_toxic</th>\n",
       "      <th>not_toxic</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239607</td>\n",
       "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239612</td>\n",
       "      <td>This bitch is nuts. Who would read a book by a...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240311</td>\n",
       "      <td>You're an idiot.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240400</td>\n",
       "      <td>Nincompoop, that's a nice one! I'm partial to ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240461</td>\n",
       "      <td>testing purposes: \\n\\nyou are an idiot and i c...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                       comment_text  all_toxic  \\\n",
       "0      239607  Yet call out all Muslims for the acts of a few...   0.333333   \n",
       "1      239612  This bitch is nuts. Who would read a book by a...   0.333333   \n",
       "2      240311                                   You're an idiot.   0.000000   \n",
       "3      240400  Nincompoop, that's a nice one! I'm partial to ...   0.000000   \n",
       "4      240461  testing purposes: \\n\\nyou are an idiot and i c...   0.000000   \n",
       "\n",
       "   not_toxic  label  kfold  \n",
       "0   0.333333      6      2  \n",
       "1   0.666667      6      0  \n",
       "2   0.000000      0      3  \n",
       "3   0.000000      0      1  \n",
       "4   0.000000      0      4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=config.n_fold, \n",
    "    shuffle=True, \n",
    "    random_state=config.seed\n",
    ")\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df[\"label\"])):\n",
    "    train_df.loc[val_idx, \"kfold\"] = int(fold)\n",
    "\n",
    "train_df[\"kfold\"] = train_df[\"kfold\"].astype(int)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abda563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53eca5dc9f6f499b80601609df55e4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.59it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.656 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.59it/s\u001b[0m \u001b[37mloss: 0.656 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4085bc8484694101ad0d8ee82da38649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.45it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.725 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.45it/s\u001b[0m \u001b[37mloss: 0.725 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc34b954c73427581ef96207ef066d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.37it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.925 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.37it/s\u001b[0m \u001b[37mloss: 0.925 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8d9933516040f9b0b0a07c35844d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.25it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.736 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.25it/s\u001b[0m \u001b[37mloss: 0.736 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold5  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee39b19670a54014a564f69c37ae6ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.22it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.699 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.22it/s\u001b[0m \u001b[37mloss: 0.699 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Debug\n",
    "config.trainer.fast_dev_run = True\n",
    "config.backbone.output_dim = len(target_cols)\n",
    "\n",
    "for fold in config.train_fold:\n",
    "    \n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    df_train = train_df[train_df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    datamodule = JigsawDataModule(df_train, val_df, test_df, config)\n",
    "    sample_dataloader = JigsawDataModule(df_train, val_df, test_df, config).train_dataloader()\n",
    "\n",
    "    config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "    model = JigsawModel(config, fold)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=MODEL_DIR,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config.project, \n",
    "        entity=config.entity,\n",
    "        name = f\"{config.exp_name}\",\n",
    "        tags = ['RoBERTa-Base', \"toxic-spans\"]\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epoch,\n",
    "        callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "#         deterministic=True,\n",
    "        logger=[wandb_logger],\n",
    "        **config.trainer\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f55dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdataskywalker\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-01-26 10:32:53.436189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">029_exp</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw/runs/ciq210hx\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw/runs/ciq210hx</a><br/>\n",
       "                Run data is saved locally in <code>/mnt/work/shimizu/kaggle/Jigsaw/notebooks/wandb/run-20220126_103250-ciq210hx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6551d8e879045b386fac6efa806ab0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">5374/5374</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:12 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.67it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.628 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">10hx valid_loss/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.647 valid_acc/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.381                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold1:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.079                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m5374/5374\u001b[0m \u001b[38;5;245m0:08:12 • 0:00:00\u001b[0m \u001b[38;5;249m12.67it/s\u001b[0m \u001b[37mloss: 0.628 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m10hx valid_loss/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.647 valid_acc/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.381                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold1:     \u001b[0m\n",
       "                                                                       \u001b[37m0.079                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebd42b79dba4d41a1a358648d40febd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">5374/5374</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:11 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.72it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.629 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">10hx valid_loss/fold2:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.668 valid_acc/fold2:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.376                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold2:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.082                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m5374/5374\u001b[0m \u001b[38;5;245m0:08:11 • 0:00:00\u001b[0m \u001b[38;5;249m12.72it/s\u001b[0m \u001b[37mloss: 0.629 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m10hx valid_loss/fold2:\u001b[0m\n",
       "                                                                       \u001b[37m0.668 valid_acc/fold2:\u001b[0m\n",
       "                                                                       \u001b[37m0.376                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold2:     \u001b[0m\n",
       "                                                                       \u001b[37m0.082                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c228d519cab44afafb71325d5674528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">5374/5374</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:12 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.68it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.612 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">10hx valid_loss/fold3:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.649 valid_acc/fold3:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.396                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold3:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.081                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m5374/5374\u001b[0m \u001b[38;5;245m0:08:12 • 0:00:00\u001b[0m \u001b[38;5;249m12.68it/s\u001b[0m \u001b[37mloss: 0.612 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m10hx valid_loss/fold3:\u001b[0m\n",
       "                                                                       \u001b[37m0.649 valid_acc/fold3:\u001b[0m\n",
       "                                                                       \u001b[37m0.396                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold3:     \u001b[0m\n",
       "                                                                       \u001b[37m0.081                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016c476df6144fba9b8d472de7af1ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 3    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">3252/5374</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:05:25 • 0:02:46</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.82it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.677 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">10hx valid_loss/fold4:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.611 valid_acc/fold4:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.418                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold4:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.085                 </span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Validation</span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1642/3764</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:02:08 • 0:02:46</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.82it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.677 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">10hx valid_loss/fold4:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.611 valid_acc/fold4:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.418                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold4:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.085                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 3    \u001b[38;2;98;6;224m━━━━━━━━━━━━\u001b[0m\u001b[38;2;98;6;224m╸\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[37m3252/5374\u001b[0m \u001b[38;5;245m0:05:25 • 0:02:46\u001b[0m \u001b[38;5;249m12.82it/s\u001b[0m \u001b[37mloss: 0.677 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m10hx valid_loss/fold4:\u001b[0m\n",
       "                                                                       \u001b[37m0.611 valid_acc/fold4:\u001b[0m\n",
       "                                                                       \u001b[37m0.418                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold4:     \u001b[0m\n",
       "                                                                       \u001b[37m0.085                 \u001b[0m\n",
       "\u001b[37mValidation\u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[37m1642/3764\u001b[0m \u001b[38;5;245m0:02:08 • 0:02:46\u001b[0m \u001b[38;5;249m12.82it/s\u001b[0m \u001b[37mloss: 0.677 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m10hx valid_loss/fold4:\u001b[0m\n",
       "                                                                       \u001b[37m0.611 valid_acc/fold4:\u001b[0m\n",
       "                                                                       \u001b[37m0.418                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold4:     \u001b[0m\n",
       "                                                                       \u001b[37m0.085                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold5  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4688/2676051309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJigsawModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlr_monitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4688/1397220412.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, fold_num)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4688/1397220412.py\u001b[0m in \u001b[0;36m__build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         self.base_model = RobertaModel.from_pretrained(\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Use Model: {self.cfg.backbone.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0m_from_auto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_auto_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_pipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m             )\n\u001b[1;32m   1088\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \"\"\"\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             logger.warn(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             )\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Load config dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m         )\n\u001b[1;32m   1339\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         )\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    452\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    868\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Training\n",
    "config.trainer.fast_dev_run = False\n",
    "config.backbone.output_dim = len(target_cols)\n",
    "\n",
    "for fold in config.train_fold:\n",
    "    \n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    df_train = train_df[train_df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    datamodule = JigsawDataModule(df_train, val_df, test_df, config)\n",
    "    sample_dataloader = JigsawDataModule(df_train, val_df, test_df, config).train_dataloader()\n",
    "\n",
    "    config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "    model = JigsawModel(config, fold)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=MODEL_DIR,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config.project, \n",
    "        entity=config.entity,\n",
    "        name = f\"{config.exp_name}\",\n",
    "        tags = ['RoBERTa-Base', \"toxic-spans\"]\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epoch,\n",
    "        callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "#         deterministic=True,\n",
    "        logger=[wandb_logger],\n",
    "        **config.trainer\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed6cf7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device == cuda\n",
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e3d36ec9248fc936af5c3e8a75b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config.backbone.output_dim = len(target_cols)\n",
    "\n",
    "print(f\"Device == {device}\")\n",
    "\n",
    "MORE = np.zeros((len(val_df), config.backbone.output_dim))\n",
    "LESS = np.zeros((len(val_df), config.backbone.output_dim))\n",
    "PRED = np.zeros((len(test_df), config.backbone.output_dim))\n",
    "\n",
    "attention_array = np.zeros((len(val_df), 256)) # attention格納\n",
    "mask_array = np.zeros((len(val_df), 256)) # mask情報格納,後でattentionと掛け合わせる\n",
    "\n",
    "for fold in config.train_fold:\n",
    "\n",
    "    pred_list = []\n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    valid_dataloader = JigsawDataModule(train_df, val_df, test_df, config).val_dataloader()\n",
    "    model = JigsawModel(config, fold)\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=\"../input/toxicroberta/\",\n",
    "    )\n",
    "    model = model.load_from_checkpoint(MODEL_DIR/f\"best_acc_fold{fold+1}.ckpt\", cfg=config, fold_num=fold)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    more_list = []\n",
    "    less_list = []\n",
    "    \n",
    "    for step, data in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "\n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device)\n",
    "        more_text_token_type_ids = data['more_token_type_ids'].to(device)\n",
    "        \n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device)\n",
    "        less_text_token_type_ids = data['less_token_type_ids'].to(device)\n",
    "        \n",
    "        more_outputs = model(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids,\n",
    "        )\n",
    "        \n",
    "        less_outputs = model(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        more_list.append(more_outputs[\"logits\"].detach().cpu().numpy())\n",
    "        less_list.append(less_outputs[\"logits\"].detach().cpu().numpy())\n",
    "\n",
    "    MORE += np.concatenate(more_list)/len(config.train_fold)\n",
    "    LESS += np.concatenate(less_list)/len(config.train_fold)\n",
    "#     PRED += pred_list/len(config.train_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f23aba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(LESS, MORE)\n",
    "plt.xlabel(\"less-toxic\")\n",
    "plt.ylabel(\"more-toxic\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "655a7509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiki Attack Score: 0.697124\n"
     ]
    }
   ],
   "source": [
    "val_df[\"less_attack\"] = LESS.sum(axis=1)\n",
    "val_df[\"more_attack\"] = MORE.sum(axis=1)\n",
    "val_df[\"diff_attack\"] = val_df[\"more_attack\"] - val_df[\"less_attack\"]\n",
    "attack_score = val_df[val_df[\"diff_attack\"]>0][\"diff_attack\"].count()/len(val_df)\n",
    "print(f\"Wiki Attack Score: {attack_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a13ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa688b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74726285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
