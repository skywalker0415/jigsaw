{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c30644",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1602084551218-a28205125639?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2070&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78163e",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'\n",
    "     style = 'background-color:#4c1c84;\n",
    "              color:#eeebf1;\n",
    "              border-width:5px;\n",
    "              border-color:#4c1c84;\n",
    "              font-family:Comic Sans MS;\n",
    "              border-radius: 50px 50px'>\n",
    "    <p style = 'font-size:24px'>Exp 023</p>\n",
    "    <a href = \"#Config\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">1.Config</a><br>\n",
    "    <a href = \"#Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">2.Settings</a><br>\n",
    "    <a href = \"#Data-Load\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">3.Data Load</a><br>\n",
    "    <a href = \"#Pytorch-Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">4.Pytorch Settings</a><br>\n",
    "    <a href = \"#Training\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">5.Training</a><br>\n",
    "</div>\n",
    "\n",
    "<p style = 'font-size:24px;\n",
    "            color:#4c1c84'>\n",
    "    実施したこと\n",
    "</p>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">WikiAttackデータで学習</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375abe8",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Config\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ec849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/utils/iterative-stratification/\")\n",
    "sys.path.append(\"../src/utils/detoxify\")\n",
    "sys.path.append(\"../src/utils/coral-pytorch/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a9c6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 02:32:59.635473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import psutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "from box import Box\n",
    "from typing import Optional\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from tqdm.auto import tqdm as tqdmp\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "tqdmp.pandas()\n",
    "\n",
    "## Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from transformers import RobertaModel, RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import LukeTokenizer, LukeModel, LukeConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "\n",
    "\n",
    "# Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning import LightningDataModule, LightningDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import rankdata\n",
    "from cuml.svm import SVR as cuml_SVR\n",
    "from cuml.linear_model import Ridge as cuml_Ridge\n",
    "import cudf\n",
    "from detoxify import Detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0839124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "config = {\n",
    "    \"exp_comment\":\"Wiki Attackデータを学習\",\n",
    "    \"seed\": 42,\n",
    "    \"root\": \"/content/drive/MyDrive/kaggle/Jigsaw/raw\",\n",
    "    \"n_fold\": 5,\n",
    "    \"epoch\": 5,\n",
    "    \"max_length\": 128,\n",
    "    \"environment\": \"AWS\",\n",
    "    \"project\": \"Jigsaw\",\n",
    "    \"entity\": \"dataskywalker\",\n",
    "    \"exp_name\": \"023_exp\",\n",
    "    \"margin\": 0.5,\n",
    "    \"train_fold\": [0, 1, 2, 3, 4],\n",
    "\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 1,\n",
    "        \"accumulate_grad_batches\": 8,\n",
    "        \"progress_bar_refresh_rate\": 1,\n",
    "        \"fast_dev_run\": True,\n",
    "        \"num_sanity_val_steps\": 0,\n",
    "    },\n",
    "\n",
    "    \"train_loader\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": True,\n",
    "    },\n",
    "\n",
    "    \"valid_loader\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"test_loader\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"backbone\": {\n",
    "        \"name\": \"roberta-base\",\n",
    "        \"output_dim\": 1,\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"torch.optim.AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 1e-6,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"name\": \"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\",\n",
    "        \"params\": {\n",
    "            \"T_0\": 20,\n",
    "            \"eta_min\": 0,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"loss\": \"nn.BCEWithLogitsLoss\",\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "config.tokenizer = RobertaTokenizer.from_pretrained(config.backbone.name)\n",
    "config.model = RobertaModel.from_pretrained(config.backbone.name)\n",
    "# pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522a894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your environment is 'AWS'.\n",
      "INPUT_DIR is /mnt/work/data/kaggle/Jigsaw\n",
      "MODEL_DIR is ../models/023_exp\n",
      "OUTPUT_DIR is ../data/interim/023_exp\n",
      "UTIL_DIR is /mnt/work/shimizu/kaggle/PetFinder/src/utils\n"
     ]
    }
   ],
   "source": [
    "# 個人的にAWSやKaggle環境やGoogle Colabを行ったり来たりしているのでまとめています\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if config.environment == 'AWS':\n",
    "    \n",
    "    INPUT_DIR = Path('/mnt/work/data/kaggle/Jigsaw/')\n",
    "    MODEL_DIR = Path(f'../models/{config.exp_name}/')\n",
    "    OUTPUT_DIR = Path(f'../data/interim/{config.exp_name}/')\n",
    "    UTIL_DIR = Path('/mnt/work/shimizu/kaggle/PetFinder/src/utils')\n",
    "    \n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"Your environment is 'AWS'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\\nUTIL_DIR is {UTIL_DIR}\")\n",
    "    \n",
    "    \n",
    "elif config.environment == 'Kaggle':\n",
    "    INPUT_DIR = Path('../input/*****')\n",
    "    MODEL_DIR = Path('./')\n",
    "    OUTPUT_DIR = Path('./')\n",
    "    print(f\"Your environment is 'Kaggle'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "\n",
    "    \n",
    "elif config.environment == 'Colab':\n",
    "    INPUT_DIR = Path('/content/drive/MyDrive/kaggle/Jigsaw/raw')\n",
    "    BASE_DIR = Path(\"/content/drive/MyDrive/kaggle/Jigsaw/interim\")\n",
    "\n",
    "    MODEL_DIR = BASE_DIR / f'{config.exp_name}'\n",
    "    OUTPUT_DIR = BASE_DIR / f'{config.exp_name}/'\n",
    "\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print('Please Mount your Google Drive.')\n",
    "    else:\n",
    "        print(f\"Your environment is 'Colab'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please choose 'AWS' or 'Kaggle' or 'Colab'.\\nINPUT_DIR is not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006c5335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed固定\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207659ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 処理時間計測\n",
    "@contextmanager\n",
    "def timer(name:str, slack:bool=False):\n",
    "    t0 = time.time()\n",
    "    p = psutil.Process(os.getpid())\n",
    "    m0 = p.memory_info()[0] / 2. ** 30\n",
    "    print(f'<< {name} >> Start')\n",
    "    yield\n",
    "    \n",
    "    m1 = p.memory_info()[0] / 2. ** 30\n",
    "    delta = m1 - m0\n",
    "    sign = '+' if delta >= 0 else '-'\n",
    "    delta = math.fabs(delta)\n",
    "    \n",
    "    print(f\"<< {name} >> {m1:.1f}GB({sign}{delta:.1f}GB):{time.time() - t0:.1f}sec\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f348f",
   "metadata": {
    "id": "zWE2XhHeTFos"
   },
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Data Load\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edaf320",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DFxNX0CTD9t",
    "outputId": "240b449b-9f09-4519-d155-b4f865053621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/sample_submission.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "## Data Check\n",
    "for dirnames, _, filenames in os.walk(INPUT_DIR):\n",
    "    \n",
    "    for filename in filenames:\n",
    "\n",
    "        print(f'{dirnames}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c7e7e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1      732895  Looks like be have an abuser , can you please ...\n",
       "2     1139051  I confess to having complete (and apparently b...\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4     2084821  It is not just you. This is a laundry list of ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/validation_data.csv\")\n",
    "test_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\")\n",
    "\n",
    "display(val_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58eb420",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal; \n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center;\n",
    "             border-radius: 100px 100px;\">\n",
    "    Wiki Attack\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f628ef63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year  logged_in  \\\n",
       "0   37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "1   44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "2   49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
       "3   89320   Next, maybe you could work on being less cond...  2002       True   \n",
       "4   93890               This page will need disambiguation.   2002       True   \n",
       "\n",
       "        ns  sample  split  \n",
       "0  article  random  train  \n",
       "1  article  random  train  \n",
       "2  article  random  train  \n",
       "3  article  random    dev  \n",
       "4  article  random  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>quoting_attack</th>\n",
       "      <th>recipient_attack</th>\n",
       "      <th>third_party_attack</th>\n",
       "      <th>other_attack</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>1362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37675</td>\n",
       "      <td>2408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37675</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37675</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37675</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  quoting_attack  recipient_attack  third_party_attack  \\\n",
       "0   37675       1362             0.0               0.0                 0.0   \n",
       "1   37675       2408             0.0               0.0                 0.0   \n",
       "2   37675       1493             0.0               0.0                 0.0   \n",
       "3   37675       1439             0.0               0.0                 0.0   \n",
       "4   37675        170             0.0               0.0                 0.0   \n",
       "\n",
       "   other_attack  attack  \n",
       "0           0.0     0.0  \n",
       "1           0.0     0.0  \n",
       "2           0.0     0.0  \n",
       "3           0.0     0.0  \n",
       "4           0.0     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments_df = pd.read_csv('../data/external/WikiAttack/attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations_df = pd.read_csv('../data/external/WikiAttack/attack_annotations.tsv',  sep = '\\t')\n",
    "\n",
    "comments_df = comments_df.reset_index()\n",
    "display(comments_df.head())\n",
    "display(annotations_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3565029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< make train >> Start\n",
      "Wiki Attack All Data is 115864.\n",
      "Wiki Attack train Data is 69526.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102817</td>\n",
       "      <td>NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69521</th>\n",
       "      <td>699756185</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe le...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69522</th>\n",
       "      <td>699813325</td>\n",
       "      <td>`NEWLINE_TOKEN::I'm talking about you making u...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69523</th>\n",
       "      <td>699848324</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69524</th>\n",
       "      <td>699857133</td>\n",
       "      <td>NEWLINE_TOKEN:The way you're trying to describ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69525</th>\n",
       "      <td>699897151</td>\n",
       "      <td>Alternate option===NEWLINE_TOKENIs there perha...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69526 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rev_id                                            comment  year  \\\n",
       "0          37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002   \n",
       "1          44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002   \n",
       "2          49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002   \n",
       "3          93890               This page will need disambiguation.   2002   \n",
       "4         102817  NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...  2002   \n",
       "...          ...                                                ...   ...   \n",
       "69521  699756185  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe le...  2016   \n",
       "69522  699813325  `NEWLINE_TOKEN::I'm talking about you making u...  2016   \n",
       "69523  699848324  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...  2016   \n",
       "69524  699857133  NEWLINE_TOKEN:The way you're trying to describ...  2016   \n",
       "69525  699897151  Alternate option===NEWLINE_TOKENIs there perha...  2016   \n",
       "\n",
       "       logged_in       ns   sample  split    target  \n",
       "0          False  article   random  train  0.000000  \n",
       "1          False  article   random  train  0.000000  \n",
       "2          False  article   random  train  0.000000  \n",
       "3           True  article   random  train  0.000000  \n",
       "4           True     user   random  train  0.000000  \n",
       "...          ...      ...      ...    ...       ...  \n",
       "69521       True  article  blocked  train  0.100000  \n",
       "69522       True  article  blocked  train  0.157895  \n",
       "69523       True  article  blocked  train  0.111111  \n",
       "69524       True  article  blocked  train  0.000000  \n",
       "69525       True  article  blocked  train  0.000000  \n",
       "\n",
       "[69526 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<< make train >> 2.4GB(+0.1GB):0.2sec\n"
     ]
    }
   ],
   "source": [
    "with timer(\"make train\"):\n",
    "    \n",
    "    train_df = comments_df[comments_df[\"split\"]==\"train\"].reset_index(drop=True)\n",
    "    print(f\"Wiki Attack All Data is {len(comments_df)}.\")\n",
    "    print(f\"Wiki Attack train Data is {len(train_df)}.\")\n",
    "    \n",
    "    train_id_list = train_df[\"rev_id\"].unique().tolist()\n",
    "    annotations_train_df = annotations_df[annotations_df[\"rev_id\"].isin(train_id_list)]\n",
    "    \n",
    "    anno_df_v2 = annotations_train_df.groupby(\"rev_id\")[\"attack\"].agg([\"sum\", \"count\"])\n",
    "    anno_df_v2[\"target\"] = anno_df_v2[\"sum\"]/anno_df_v2[\"count\"]\n",
    "    anno_df_v2 = anno_df_v2.reset_index()\n",
    "    \n",
    "    train_df = pd.merge(\n",
    "        train_df,\n",
    "        anno_df_v2[[\"rev_id\", \"target\"]],\n",
    "        on=\"rev_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a05615d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(train_df[\"target\"], color=\"#4c1c84\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d67db",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Pytorch Dataset\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c19efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset:\n",
    "    \n",
    "    def __init__(self, df, tokenizer, max_length, mode):\n",
    "        \n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            self.text = df[\"comment\"].values\n",
    "            self.target = df[\"target\"].values\n",
    "            \n",
    "        elif self.mode == \"valid\":\n",
    "            self.more_toxic = df[\"more_toxic\"].values\n",
    "            self.less_toxic = df[\"less_toxic\"].values\n",
    "            \n",
    "        else:\n",
    "            self.text == df[\"text\"].values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            \n",
    "            text = self.text[index]\n",
    "            target = self.target[index]\n",
    "            \n",
    "            inputs_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            text_ids = inputs_text[\"input_ids\"]\n",
    "            text_mask = inputs_text[\"attention_mask\"]\n",
    "            text_token_type_ids = inputs_text[\"token_type_ids\"]\n",
    "\n",
    "            return {\n",
    "                'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
    "                'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
    "                'text_token_type_ids': torch.tensor(text_token_type_ids, dtype=torch.long),\n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        elif self.mode == \"valid\":\n",
    "            \n",
    "            more_toxic = self.more_toxic[index]\n",
    "            less_toxic = self.less_toxic[index]\n",
    "\n",
    "            inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                more_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "\n",
    "            inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                less_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            target = 1\n",
    "\n",
    "            more_toxic_ids = inputs_more_toxic[\"input_ids\"]\n",
    "            more_toxic_mask = inputs_more_toxic[\"attention_mask\"]\n",
    "            more_token_type_ids = inputs_more_toxic[\"token_type_ids\"]\n",
    "\n",
    "            less_toxic_ids = inputs_less_toxic[\"input_ids\"]\n",
    "            less_toxic_mask = inputs_less_toxic[\"attention_mask\"]\n",
    "            less_token_type_ids = inputs_less_toxic[\"token_type_ids\"]\n",
    "            \n",
    "            return {\n",
    "                'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n",
    "                'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n",
    "                'more_token_type_ids': torch.tensor(more_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n",
    "                'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n",
    "                'less_token_type_ids': torch.tensor(less_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            text = self.text[index]\n",
    "            \n",
    "            input_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            text_ids = inputs_text[\"input_ids\"]\n",
    "            text_mask = inputs_text[\"attention_mask\"]\n",
    "            text_token_type_ids = inputs_text[\"token_type_ids\"]\n",
    "\n",
    "            return {\n",
    "                'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
    "                'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
    "                'text_token_type_ids': torch.tensor(text_token_type_ids, dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e64275",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    DataModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5371383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, valid_df, test_df, cfg):\n",
    "\n",
    "        super().__init__()\n",
    "        self._train_df = train_df\n",
    "        self._valid_df = valid_df\n",
    "        self._test_df = test_df\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._train_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"train\"\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._valid_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"valid\"\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.valid_loader)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._test_df,\n",
    "            tokenizer = self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"test\"\n",
    "        )\n",
    "\n",
    "        return DataLoader(dataset, **self._cfg.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc697cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataCheck\n",
    "seed_everything(config.seed)\n",
    "\n",
    "sample_dataloader = JigsawDataModule(train_df, val_df, test_df, config).train_dataloader()\n",
    "for data in sample_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c97489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32])\n",
      "tensor([0.8000, 0.0000, 0.0556, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3000,\n",
      "        0.0000, 0.3000, 0.3000, 0.1000, 0.1000, 0.8276, 0.0000, 0.0000, 0.0000,\n",
      "        0.1000, 0.2632, 0.0000, 0.0000, 0.2000, 0.1000, 0.0000, 0.1000, 0.1000,\n",
      "        0.6000, 0.6250, 0.0000, 0.0000, 0.2000])\n",
      "torch.Size([32, 128, 768]) torch.Size([32, 12, 128, 128])\n",
      "torch.Size([32, 768]) torch.Size([32, 12, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text_ids\"].size())\n",
    "print(data[\"text_mask\"].size())\n",
    "print(data[\"text_token_type_ids\"].size())\n",
    "print(data[\"target\"].size())\n",
    "print(data[\"target\"])\n",
    "output = config.model(\n",
    "    data[\"text_ids\"],\n",
    "    data[\"text_mask\"],\n",
    "    data[\"text_token_type_ids\"],\n",
    "    output_attentions=True\n",
    ")\n",
    "print(output[\"last_hidden_state\"].size(), output[\"attentions\"][-1].size())\n",
    "print(output[\"last_hidden_state\"][:, 0, :].size(), output[\"attentions\"][-1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afec5f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    LigitningModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67069f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, cfg, fold_num):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self.criterion = eval(self.cfg.loss)()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.fold_num = fold_num\n",
    "        \n",
    "    def __build_model(self):\n",
    "        \n",
    "        self.base_model = RobertaModel.from_pretrained(\n",
    "            self.cfg.backbone.name\n",
    "        )\n",
    "        print(f\"Use Model: {self.cfg.backbone.name}\")\n",
    "        self.norm = nn.LayerNorm(768)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.head = nn.Linear(768, self.cfg.backbone.output_dim)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        \n",
    "        output = self.base_model(\n",
    "            input_ids=ids, \n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True\n",
    "        )\n",
    "        feature = self.norm(output[\"last_hidden_state\"][:, 0, :])\n",
    "        out = self.drop(feature)\n",
    "        out = self.head(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        text_ids = batch[\"text_ids\"]\n",
    "        text_mask = batch['text_mask']\n",
    "        text_token_type_ids = batch['text_token_type_ids']\n",
    "        targets = batch['target']\n",
    "        \n",
    "        outputs = self.forward(text_ids, text_mask, text_token_type_ids)[:, 0]\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        \n",
    "        return {\"loss\":loss, \"targets\":targets}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "        target_list = []\n",
    "\n",
    "        for out in training_step_outputs:\n",
    "\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "            target_list.extend(out[\"targets\"])\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "\n",
    "        logs = {f\"train_loss/fold{self.fold_num+1}\": meanloss,}\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        more_toxic_ids = batch['more_toxic_ids']\n",
    "        more_toxic_mask = batch['more_toxic_mask']\n",
    "        more_text_token_type_ids = batch['more_token_type_ids']\n",
    "        \n",
    "        less_toxic_ids = batch['less_toxic_ids']\n",
    "        less_toxic_mask = batch['less_toxic_mask']\n",
    "        less_text_token_type_ids = batch['less_token_type_ids']\n",
    "        \n",
    "        targets = batch['target']\n",
    "\n",
    "        more_outputs = self.forward(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids\n",
    "        )[:, 0]\n",
    "        \n",
    "        less_outputs = self.forward(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )[:, 0]\n",
    "        \n",
    "        outputs = more_outputs - less_outputs\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        return {\"loss\":loss, \"pred\":outputs, \"targets\":targets}\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "        pred_list = []\n",
    "        target_list = []\n",
    "\n",
    "        for out in validation_step_outputs:\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "            pred_list.append(out[\"pred\"].detach().cpu().numpy())\n",
    "            target_list.append(out[\"targets\"].detach().cpu().numpy())\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "        pred_list = np.concatenate(pred_list)\n",
    "        pred_count = sum(x>0 for x in pred_list)/len(pred_list)\n",
    "\n",
    "        logs = {\n",
    "            f\"valid_loss/fold{self.fold_num+1}\":meanloss,\n",
    "            f\"valid_acc/fold{self.fold_num+1}\":pred_count,\n",
    "        }\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = eval(self.cfg.optimizer.name)(\n",
    "            self.parameters(), **self.cfg.optimizer.params\n",
    "        )\n",
    "\n",
    "        self.scheduler = eval(self.cfg.scheduler.name)(\n",
    "            optimizer, **self.cfg.scheduler.params\n",
    "        )\n",
    "        \n",
    "        scheduler = {\"scheduler\": self.scheduler, \"interval\": \"step\",}\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba9a9c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    Training\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f83dc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102817</td>\n",
       "      <td>NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year  logged_in  \\\n",
       "0   37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "1   44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "2   49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
       "3   93890               This page will need disambiguation.   2002       True   \n",
       "4  102817  NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...  2002       True   \n",
       "\n",
       "        ns  sample  split  target  kfold  \n",
       "0  article  random  train     0.0      1  \n",
       "1  article  random  train     0.0      2  \n",
       "2  article  random  train     0.0      4  \n",
       "3  article  random  train     0.0      1  \n",
       "4     user  random  train     0.0      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = KFold(\n",
    "    n_splits=config.n_fold, \n",
    "    shuffle=True, \n",
    "    random_state=config.seed\n",
    ")\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df[\"target\"])):\n",
    "    train_df.loc[val_idx, \"kfold\"] = int(fold)\n",
    "\n",
    "train_df[\"kfold\"] = train_df[\"kfold\"].astype(int)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a7d4305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7046c8fa8b4222b5c8da0817a6178d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:01 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">1.19it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.658 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:01 • 0:00:00\u001b[0m \u001b[38;5;249m1.19it/s\u001b[0m \u001b[37mloss: 0.658 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925223d444ee49a7a88bc493dc39c45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:01 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">1.17it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.955 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:01 • 0:00:00\u001b[0m \u001b[38;5;249m1.17it/s\u001b[0m \u001b[37mloss: 0.955 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53865e55f6cc45d0909921a64db2a453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:01 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">1.14it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.589 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:01 • 0:00:00\u001b[0m \u001b[38;5;249m1.14it/s\u001b[0m \u001b[37mloss: 0.589 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43959a7ee664e2eb0f5c8093ab8da4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:01 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">1.06it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.573 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:01 • 0:00:00\u001b[0m \u001b[38;5;249m1.06it/s\u001b[0m \u001b[37mloss: 0.573 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold5  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91835da69a941a9916a660b1beca178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:01 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">1.08it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.481 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:01 • 0:00:00\u001b[0m \u001b[38;5;249m1.08it/s\u001b[0m \u001b[37mloss: 0.481 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Debug\n",
    "config.trainer.fast_dev_run = True\n",
    "\n",
    "for fold in config.train_fold:\n",
    "    \n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    df_train = train_df[train_df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    datamodule = JigsawDataModule(df_train, val_df, test_df, config)\n",
    "    sample_dataloader = JigsawDataModule(df_train, val_df, test_df, config).train_dataloader()\n",
    "\n",
    "    config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "    model = JigsawModel(config, fold)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_loss_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        save_last=False,\n",
    "        dirpath=MODEL_DIR,\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config.project, \n",
    "        entity=config.entity,\n",
    "        name = f\"{config.exp_name}\",\n",
    "        tags = ['RoBERTa-Base', \"WikiAttack\"]\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epoch,\n",
    "        callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "#         deterministic=True,\n",
    "        logger=[wandb_logger],\n",
    "        **config.trainer\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a27f8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdataskywalker\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-01-23 18:32:07.835029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">023_exp</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw/runs/29vcd53k\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw/runs/29vcd53k</a><br/>\n",
       "                Run data is saved locally in <code>/mnt/work/shimizu/kaggle/Jigsaw/notebooks/wandb/run-20220123_183204-29vcd53k</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e60593a2824082a8c576b2924496d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2209/2209</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:06 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">3.74it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.324 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">d53k valid_loss/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.689 valid_acc/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.677                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold1:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.038                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2209/2209\u001b[0m \u001b[38;5;245m0:08:06 • 0:00:00\u001b[0m \u001b[38;5;249m3.74it/s\u001b[0m \u001b[37mloss: 0.324 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37md53k valid_loss/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.689 valid_acc/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.677                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold1:     \u001b[0m\n",
       "                                                                       \u001b[37m0.038                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cceb7ac45c42e292437fcde46fffd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2209/2209</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:05 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">3.74it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.308 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">d53k valid_loss/fold2:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.697 valid_acc/fold2:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.677                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold2:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.038                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2209/2209\u001b[0m \u001b[38;5;245m0:08:05 • 0:00:00\u001b[0m \u001b[38;5;249m3.74it/s\u001b[0m \u001b[37mloss: 0.308 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37md53k valid_loss/fold2:\u001b[0m\n",
       "                                                                       \u001b[37m0.697 valid_acc/fold2:\u001b[0m\n",
       "                                                                       \u001b[37m0.677                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold2:     \u001b[0m\n",
       "                                                                       \u001b[37m0.038                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb22588662b74bd69fdb4cc5e49efad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2209/2209</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:06 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">3.74it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.306 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">d53k valid_loss/fold3:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.694 valid_acc/fold3:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.68 train_loss/fold3:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.038                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2209/2209\u001b[0m \u001b[38;5;245m0:08:06 • 0:00:00\u001b[0m \u001b[38;5;249m3.74it/s\u001b[0m \u001b[37mloss: 0.306 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37md53k valid_loss/fold3:\u001b[0m\n",
       "                                                                       \u001b[37m0.694 valid_acc/fold3:\u001b[0m\n",
       "                                                                       \u001b[37m0.68 train_loss/fold3:\u001b[0m\n",
       "                                                                       \u001b[37m0.038                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02c7d5501ff4aed95f9f6db76bc5e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2209/2209</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:05 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">3.75it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.308 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">d53k valid_loss/fold4:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.708 valid_acc/fold4:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.673                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold4:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.039                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2209/2209\u001b[0m \u001b[38;5;245m0:08:05 • 0:00:00\u001b[0m \u001b[38;5;249m3.75it/s\u001b[0m \u001b[37mloss: 0.308 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37md53k valid_loss/fold4:\u001b[0m\n",
       "                                                                       \u001b[37m0.708 valid_acc/fold4:\u001b[0m\n",
       "                                                                       \u001b[37m0.673                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold4:     \u001b[0m\n",
       "                                                                       \u001b[37m0.039                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold5  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5d3e07d42d40e6bfed43e0b8c29312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2209/2209</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:05 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">3.74it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.302 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">d53k valid_loss/fold5:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.695 valid_acc/fold5:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.678                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold5:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.038                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2209/2209\u001b[0m \u001b[38;5;245m0:08:05 • 0:00:00\u001b[0m \u001b[38;5;249m3.74it/s\u001b[0m \u001b[37mloss: 0.302 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37md53k valid_loss/fold5:\u001b[0m\n",
       "                                                                       \u001b[37m0.695 valid_acc/fold5:\u001b[0m\n",
       "                                                                       \u001b[37m0.678                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold5:     \u001b[0m\n",
       "                                                                       \u001b[37m0.038                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Training\n",
    "config.trainer.fast_dev_run = False\n",
    "\n",
    "for fold in config.train_fold:\n",
    "    \n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    df_train = train_df[train_df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    datamodule = JigsawDataModule(df_train, val_df, test_df, config)\n",
    "    sample_dataloader = JigsawDataModule(df_train, val_df, test_df, config).train_dataloader()\n",
    "\n",
    "    config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "    model = JigsawModel(config, fold)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_loss_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        save_last=False,\n",
    "        dirpath=MODEL_DIR,\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config.project, \n",
    "        entity=config.entity,\n",
    "        name = f\"{config.exp_name}\",\n",
    "        tags = ['RoBERTa-Base', \"WikiAttack\"]\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epoch,\n",
    "        callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "#         deterministic=True,\n",
    "        logger=[wandb_logger],\n",
    "        **config.trainer\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df427b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device == cuda\n",
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1032c6fa06674cfa847a094d1c9bdefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448e65286c9541578c0c2efa57344952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aff955e27734eed9ae533b54b1b89e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b71b12f354e4d5eb281a974f387b58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold5  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9918cebe1ff3474f8c0baa0b3bbe7a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device == {device}\")\n",
    "MORE = np.zeros(len(val_df))\n",
    "LESS = np.zeros(len(val_df))\n",
    "PRED = np.zeros(len(test_df))\n",
    "\n",
    "for fold in config.train_fold:\n",
    "\n",
    "    pred_list = []\n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    valid_dataloader = JigsawDataModule(train_df, val_df, test_df, config).val_dataloader()\n",
    "    model = JigsawModel(config, fold)\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_loss_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        save_last=False,\n",
    "        dirpath=\"../input/toxicroberta/\",\n",
    "    )\n",
    "    model = model.load_from_checkpoint(MODEL_DIR/f\"best_loss_fold{fold+1}.ckpt\", cfg=config, fold_num=fold)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    more_list = []\n",
    "    less_list = []\n",
    "    \n",
    "    for step, data in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "\n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device)\n",
    "        more_text_token_type_ids = data['more_token_type_ids'].to(device)\n",
    "        \n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device)\n",
    "        less_text_token_type_ids = data['less_token_type_ids'].to(device)\n",
    "        \n",
    "        more_outputs = model(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids,\n",
    "        )\n",
    "        \n",
    "        less_outputs = model(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        more_list.append(more_outputs[:, 0].detach().cpu().numpy())\n",
    "        less_list.append(less_outputs[:, 0].detach().cpu().numpy())\n",
    "\n",
    "    MORE += np.concatenate(more_list)/len(config.train_fold)\n",
    "    LESS += np.concatenate(less_list)/len(config.train_fold)\n",
    "#     PRED += pred_list/len(config.train_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "092e2ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(LESS, MORE)\n",
    "plt.xlabel(\"less-toxic\")\n",
    "plt.ylabel(\"more-toxic\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "823fc58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiki Attack Score: 0.654145\n"
     ]
    }
   ],
   "source": [
    "val_df[\"less_attack\"] = LESS\n",
    "val_df[\"more_attack\"] = MORE\n",
    "val_df[\"diff_attack\"] = val_df[\"more_attack\"] - val_df[\"less_attack\"]\n",
    "attack_score = val_df[val_df[\"diff_attack\"]>0][\"diff_attack\"].count()/len(val_df)\n",
    "print(f\"Wiki Attack Score: {attack_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da3cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fde91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72392a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
