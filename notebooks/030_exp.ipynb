{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964424dc",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1602084551218-a28205125639?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2070&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92ae9d",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'\n",
    "     style = 'background-color:#4c1c84;\n",
    "              color:#eeebf1;\n",
    "              border-width:5px;\n",
    "              border-color:#4c1c84;\n",
    "              font-family:Comic Sans MS;\n",
    "              border-radius: 50px 50px'>\n",
    "    <p style = 'font-size:24px'>Exp 030</p>\n",
    "    <a href = \"#Config\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">1.Config</a><br>\n",
    "    <a href = \"#Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">2.Settings</a><br>\n",
    "    <a href = \"#Data-Load\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">3.Data Load</a><br>\n",
    "    <a href = \"#Pytorch-Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">4.Pytorch Settings</a><br>\n",
    "    <a href = \"#Training\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">5.Training</a><br>\n",
    "</div>\n",
    "\n",
    "<p style = 'font-size:24px;\n",
    "            color:#4c1c84'>\n",
    "    実施したこと\n",
    "</p>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">使用データ:toxic-spans</li>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">使用モデル:RoBERTa-Base</li>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">Attentionの可視化</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a4223",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Config\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971c0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/utils/iterative-stratification/\")\n",
    "sys.path.append(\"../src/utils/detoxify\")\n",
    "sys.path.append(\"../src/utils/coral-pytorch/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b297e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 15:18:20.267391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import psutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "from box import Box\n",
    "from typing import Optional\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from tqdm.auto import tqdm as tqdmp\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "tqdmp.pandas()\n",
    "\n",
    "## Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from transformers import RobertaModel, RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import LukeTokenizer, LukeModel, LukeConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from transformers import DebertaTokenizer, DebertaModel\n",
    "\n",
    "# Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning import LightningDataModule, LightningDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import rankdata\n",
    "from cuml.svm import SVR as cuml_SVR\n",
    "from cuml.linear_model import Ridge as cuml_Ridge\n",
    "import cudf\n",
    "from detoxify import Detoxify\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from ast import literal_eval\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import spacy\n",
    "from scipy.stats import sem\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96009a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "config = {\n",
    "    \"exp_comment\":\"toxic-spanをRoBERTaで学習\",\n",
    "    \"seed\": 42,\n",
    "    \"root\": \"/content/drive/MyDrive/kaggle/Jigsaw/raw\",\n",
    "    \"n_fold\": 5,\n",
    "    \"epoch\": 5,\n",
    "    \"max_length\": 256,\n",
    "    \"environment\": \"AWS\",\n",
    "    \"project\": \"Jigsaw\",\n",
    "    \"entity\": \"dataskywalker\",\n",
    "    \"exp_name\": \"030_exp\",\n",
    "    \"margin\": 0.5,\n",
    "    \"train_fold\": [0, 1, 2, 3, 4],\n",
    "\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 1,\n",
    "        \"accumulate_grad_batches\": 8,\n",
    "        \"progress_bar_refresh_rate\": 1,\n",
    "        \"fast_dev_run\": True,\n",
    "        \"num_sanity_val_steps\": 0,\n",
    "    },\n",
    "\n",
    "    \"train_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": True,\n",
    "    },\n",
    "\n",
    "    \"valid_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"test_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"backbone\": {\n",
    "        \"name\": \"roberta-base\",\n",
    "        \"output_dim\": 1,\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"torch.optim.AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 1e-6,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"name\": \"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\",\n",
    "        \"params\": {\n",
    "            \"T_0\": 20,\n",
    "            \"eta_min\": 0,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"loss\": \"nn.BCEWithLogitsLoss\",\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "config.tokenizer = RobertaTokenizer.from_pretrained(config.backbone.name)\n",
    "config.model = RobertaModel.from_pretrained(config.backbone.name)\n",
    "# pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7dd5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config.tokenizer.save_pretrained(f\"../data/processed/{config.backbone.name}\")\n",
    "\n",
    "pretrain_model = RobertaModel.from_pretrained(config.backbone.name)\n",
    "pretrain_model.save_pretrained(f\"../data/processed/{config.backbone.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aee6e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your environment is 'AWS'.\n",
      "INPUT_DIR is /mnt/work/data/kaggle/Jigsaw\n",
      "MODEL_DIR is ../models/030_exp\n",
      "OUTPUT_DIR is ../data/interim/030_exp\n",
      "UTIL_DIR is /mnt/work/shimizu/kaggle/PetFinder/src/utils\n"
     ]
    }
   ],
   "source": [
    "# 個人的にAWSやKaggle環境やGoogle Colabを行ったり来たりしているのでまとめています\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if config.environment == 'AWS':\n",
    "    \n",
    "    INPUT_DIR = Path('/mnt/work/data/kaggle/Jigsaw/')\n",
    "    MODEL_DIR = Path(f'../models/{config.exp_name}/')\n",
    "    OUTPUT_DIR = Path(f'../data/interim/{config.exp_name}/')\n",
    "    UTIL_DIR = Path('/mnt/work/shimizu/kaggle/PetFinder/src/utils')\n",
    "    \n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"Your environment is 'AWS'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\\nUTIL_DIR is {UTIL_DIR}\")\n",
    "    \n",
    "    \n",
    "elif config.environment == 'Kaggle':\n",
    "    INPUT_DIR = Path('../input/*****')\n",
    "    MODEL_DIR = Path('./')\n",
    "    OUTPUT_DIR = Path('./')\n",
    "    print(f\"Your environment is 'Kaggle'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "\n",
    "    \n",
    "elif config.environment == 'Colab':\n",
    "    INPUT_DIR = Path('/content/drive/MyDrive/kaggle/Jigsaw/raw')\n",
    "    BASE_DIR = Path(\"/content/drive/MyDrive/kaggle/Jigsaw/interim\")\n",
    "\n",
    "    MODEL_DIR = BASE_DIR / f'{config.exp_name}'\n",
    "    OUTPUT_DIR = BASE_DIR / f'{config.exp_name}/'\n",
    "\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print('Please Mount your Google Drive.')\n",
    "    else:\n",
    "        print(f\"Your environment is 'Colab'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please choose 'AWS' or 'Kaggle' or 'Colab'.\\nINPUT_DIR is not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19c9db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed固定\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688b15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 処理時間計測\n",
    "@contextmanager\n",
    "def timer(name:str, slack:bool=False):\n",
    "    t0 = time.time()\n",
    "    p = psutil.Process(os.getpid())\n",
    "    m0 = p.memory_info()[0] / 2. ** 30\n",
    "    print(f'<< {name} >> Start')\n",
    "    yield\n",
    "    \n",
    "    m1 = p.memory_info()[0] / 2. ** 30\n",
    "    delta = m1 - m0\n",
    "    sign = '+' if delta >= 0 else '-'\n",
    "    delta = math.fabs(delta)\n",
    "    \n",
    "    print(f\"<< {name} >> {m1:.1f}GB({sign}{delta:.1f}GB):{time.time() - t0:.1f}sec\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a6031",
   "metadata": {
    "id": "zWE2XhHeTFos"
   },
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Data Load\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9432887c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DFxNX0CTD9t",
    "outputId": "240b449b-9f09-4519-d155-b4f865053621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/sample_submission.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "## Data Check\n",
    "for dirnames, _, filenames in os.walk(INPUT_DIR):\n",
    "    \n",
    "    for filename in filenames:\n",
    "\n",
    "        print(f'{dirnames}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "533af0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1      732895  Looks like be have an abuser , can you please ...\n",
       "2     1139051  I confess to having complete (and apparently b...\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4     2084821  It is not just you. This is a laundry list of ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/validation_data.csv\")\n",
    "test_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\")\n",
    "\n",
    "display(val_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83084725",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal; \n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center;\n",
    "             border-radius: 100px 100px;\">\n",
    "    Toxic-Span\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb2007b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsd_train_df = pd.read_csv(\"../data/external/toxic_spans/data/tsd_train.csv\")\n",
    "\n",
    "display(tsd_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407d2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = tsd_train_df[\"text\"].values\n",
    "spans = tsd_train_df[\"spans\"].apply(literal_eval)\n",
    "lbl = [1 if len(s) > 0 else 0 for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d72f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr2 = TweetTokenizer()\n",
    "\n",
    "def custom_tokenizer(text_data:np.array) -> np.array:\n",
    "    return tknzr2.tokenize(text_data)\n",
    "\n",
    "def retrieve_word_from_span(lst_span:list, text:str) -> str:\n",
    "    \n",
    "    i = 0\n",
    "    token = []\n",
    "    a = 0\n",
    "    \n",
    "    word = []\n",
    "    \n",
    "    while (i < (len(lst_span) - 1)):\n",
    "        if (lst_span[i] != (lst_span[i+1]-1)):\n",
    "            token.append(lst_span[a:(i+1)])\n",
    "            a = i + 1\n",
    "        elif i == (len(lst_span) - 2):\n",
    "            token.append(lst_span[a:i+2])\n",
    "            \n",
    "        i = i + 1\n",
    "        \n",
    "    for t in token:\n",
    "        word.append(text[t[0]:(t[len(t)-1])+1])\n",
    "        \n",
    "    return word\n",
    "\n",
    "def span_retrived(text_data, spans):\n",
    "    token_labels = []\n",
    "\n",
    "    for i in range(0, len(text_data)):\n",
    "        token_labels.append(retrieve_word_from_span(spans[i], text_data[i]))\n",
    "    \n",
    "    return token_labels\n",
    "\n",
    "def span_convert(text_data, spans):\n",
    "    MAX_LEN = 0\n",
    "    token_labels = []\n",
    "\n",
    "    for i in range(0, len(text_data)):\n",
    "        token_labels.append(retrieve_word_from_span(spans[i], text_data[i]))\n",
    "\n",
    "    lst_seq = []\n",
    "    for i in range(0, len(text_data)):\n",
    "        # token = tknzr.tokenize(text_data[i])\n",
    "        token = custom_tokenizer(text_data[i])\n",
    "        if len(token) > MAX_LEN:\n",
    "            MAX_LEN = len(token)\n",
    "            \n",
    "        seq = np.zeros(len(token), dtype=int)\n",
    "        for j in range(0, len(token)):\n",
    "            for t in token_labels[i]:\n",
    "                # if token[j] in tknzr.tokenize(t):\n",
    "                if token[j] in custom_tokenizer(t):\n",
    "                    seq[j] = 1\n",
    "        lst_seq.append(seq)     \n",
    "\n",
    "    return (token_labels, lst_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b089555c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "      <td>[violent and aggressive immigrant]</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "      <td>[fucking]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "      <td>[Damn]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know th...</td>\n",
       "      <td>[knucklehead]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
       "      <td>[killing]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \\\n",
       "0  Another violent and aggressive immigrant killi...   \n",
       "1  I am 56 years old, I am not your fucking junio...   \n",
       "2                  Damn, a whole family. Sad indeed.   \n",
       "3  What a knucklehead. How can anyone not know th...   \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...   \n",
       "\n",
       "                                token  \\\n",
       "0  [violent and aggressive immigrant]   \n",
       "1                           [fucking]   \n",
       "2                              [Damn]   \n",
       "3                       [knucklehead]   \n",
       "4                           [killing]   \n",
       "\n",
       "                                                 seq  \n",
       "0         [0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "2                        [1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd_train_df['token'], tsd_train_df['seq'] = span_convert(text_data, spans)\n",
    "train_df = deepcopy(tsd_train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a6214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../data/external/toxic_spans/data/toxic_token.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a8fbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"target\"] = lbl\n",
    "target_cols = [\"target\"]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(train_df[\"target\"], color=\"#4c1c84\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f16860",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Pytorch Dataset\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53fd7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset:\n",
    "    \n",
    "    def __init__(self, df, tokenizer, max_length, mode, target_cols):\n",
    "        \n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mode = mode\n",
    "        self.target_cols = target_cols\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            self.text = df[\"text\"].values\n",
    "            self.target = df[target_cols].values\n",
    "            \n",
    "        elif self.mode == \"valid\":\n",
    "            self.more_toxic = df[\"more_toxic\"].values\n",
    "            self.less_toxic = df[\"less_toxic\"].values\n",
    "            \n",
    "        else:\n",
    "            self.text = df[\"text\"].values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            \n",
    "            text = self.text[index]\n",
    "            target = self.target[index]\n",
    "            \n",
    "            inputs_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            text_ids = inputs_text[\"input_ids\"]\n",
    "            text_mask = inputs_text[\"attention_mask\"]\n",
    "            text_token_type_ids = inputs_text[\"token_type_ids\"]\n",
    "\n",
    "            return {\n",
    "                'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
    "                'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
    "                'text_token_type_ids': torch.tensor(text_token_type_ids, dtype=torch.long),\n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        elif self.mode == \"valid\":\n",
    "            \n",
    "            more_toxic = self.more_toxic[index]\n",
    "            less_toxic = self.less_toxic[index]\n",
    "\n",
    "            inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                more_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "\n",
    "            inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                less_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            target = 1\n",
    "\n",
    "            more_toxic_ids = inputs_more_toxic[\"input_ids\"]\n",
    "            more_toxic_mask = inputs_more_toxic[\"attention_mask\"]\n",
    "            more_token_type_ids = inputs_more_toxic[\"token_type_ids\"]\n",
    "\n",
    "            less_toxic_ids = inputs_less_toxic[\"input_ids\"]\n",
    "            less_toxic_mask = inputs_less_toxic[\"attention_mask\"]\n",
    "            less_token_type_ids = inputs_less_toxic[\"token_type_ids\"]\n",
    "            \n",
    "            return {\n",
    "                'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n",
    "                'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n",
    "                'more_token_type_ids': torch.tensor(more_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n",
    "                'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n",
    "                'less_token_type_ids': torch.tensor(less_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            text = self.text[index]\n",
    "            \n",
    "            inputs_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            text_ids = inputs_text[\"input_ids\"]\n",
    "            text_mask = inputs_text[\"attention_mask\"]\n",
    "            text_token_type_ids = inputs_text[\"token_type_ids\"]\n",
    "\n",
    "            return {\n",
    "                'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
    "                'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
    "                'text_token_type_ids': torch.tensor(text_token_type_ids, dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdb55d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    DataModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac70a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, valid_df, test_df, cfg):\n",
    "\n",
    "        super().__init__()\n",
    "        self._train_df = train_df\n",
    "        self._valid_df = valid_df\n",
    "        self._test_df = test_df\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._train_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"train\",\n",
    "            target_cols=target_cols\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._valid_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"valid\",\n",
    "            target_cols=target_cols\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.valid_loader)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._test_df,\n",
    "            tokenizer = self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"test\",\n",
    "            target_cols=target_cols\n",
    "        )\n",
    "\n",
    "        return DataLoader(dataset, **self._cfg.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4616dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataCheck\n",
    "seed_everything(config.seed)\n",
    "\n",
    "sample_dataloader = JigsawDataModule(train_df, val_df, test_df, config).train_dataloader()\n",
    "for data in sample_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b40b7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 1])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "torch.Size([8, 256, 768]) torch.Size([8, 12, 256, 256])\n",
      "torch.Size([8, 768]) torch.Size([8, 12, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text_ids\"].size())\n",
    "print(data[\"text_mask\"].size())\n",
    "print(data[\"text_token_type_ids\"].size())\n",
    "print(data[\"target\"].size())\n",
    "print(data[\"target\"])\n",
    "output = config.model(\n",
    "    data[\"text_ids\"],\n",
    "    data[\"text_mask\"],\n",
    "    data[\"text_token_type_ids\"],\n",
    "    output_attentions=True\n",
    ")\n",
    "print(output[\"last_hidden_state\"].size(), output[\"attentions\"][-1].size())\n",
    "print(output[\"last_hidden_state\"][:, 0, :].size(), output[\"attentions\"][-1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790f39d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    LigitningModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d836cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, cfg, fold_num):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self.criterion = eval(self.cfg.loss)()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.fold_num = fold_num\n",
    "        \n",
    "    def __build_model(self):\n",
    "        \n",
    "        self.base_model = RobertaModel.from_pretrained(\n",
    "            self.cfg.backbone.name\n",
    "        )\n",
    "        print(f\"Use Model: {self.cfg.backbone.name}\")\n",
    "        self.norm = nn.LayerNorm(768)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.head = nn.Linear(768, self.cfg.backbone.output_dim)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        \n",
    "        output = self.base_model(\n",
    "            input_ids=ids, \n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True\n",
    "        )\n",
    "        feature = self.norm(output[\"last_hidden_state\"][:, 0, :])\n",
    "        out = self.drop(feature)\n",
    "        out = self.head(out)\n",
    "        \n",
    "        return {\n",
    "            \"logits\":out, \n",
    "            \"attention\":output[\"attentions\"], \n",
    "            \"mask\":mask,\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        text_ids = batch[\"text_ids\"]\n",
    "        text_mask = batch['text_mask']\n",
    "        text_token_type_ids = batch['text_token_type_ids']\n",
    "        targets = batch['target']\n",
    "        \n",
    "        outputs = self.forward(text_ids, text_mask, text_token_type_ids)\n",
    "        loss = self.criterion(outputs[\"logits\"], targets)\n",
    "        \n",
    "        return {\n",
    "            \"loss\":loss,\n",
    "            \"targets\":targets,\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "\n",
    "        for out in training_step_outputs:\n",
    "\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "\n",
    "        logs = {f\"train_loss/fold{self.fold_num+1}\": meanloss,}\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        more_toxic_ids = batch['more_toxic_ids']\n",
    "        more_toxic_mask = batch['more_toxic_mask']\n",
    "        more_text_token_type_ids = batch['more_token_type_ids']\n",
    "        \n",
    "        less_toxic_ids = batch['less_toxic_ids']\n",
    "        less_toxic_mask = batch['less_toxic_mask']\n",
    "        less_text_token_type_ids = batch['less_token_type_ids']\n",
    "        \n",
    "        targets = batch['target']\n",
    "\n",
    "        more_outputs = self.forward(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        less_outputs = self.forward(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        \n",
    "        more_outputs = torch.sum(more_outputs[\"logits\"], 1)\n",
    "        less_outputs = torch.sum(less_outputs[\"logits\"], 1)\n",
    "        \n",
    "        outputs = more_outputs - less_outputs\n",
    "        logits = outputs.clone()\n",
    "\n",
    "        logits[logits > 0] = 1\n",
    "        loss = self.criterion(logits, targets)\n",
    "\n",
    "        return {\n",
    "            \"loss\":loss,\n",
    "            \"pred\":outputs,\n",
    "            \"targets\":targets,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "        pred_list = []\n",
    "        target_list = []\n",
    "\n",
    "        for out in validation_step_outputs:\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "            pred_list.append(out[\"pred\"].detach().cpu().numpy())\n",
    "            target_list.append(out[\"targets\"].detach().cpu().numpy())\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "        pred_list = np.concatenate(pred_list)\n",
    "        pred_count = sum(x>0 for x in pred_list)/len(pred_list)\n",
    "\n",
    "        logs = {\n",
    "            f\"valid_loss/fold{self.fold_num+1}\":meanloss,\n",
    "            f\"valid_acc/fold{self.fold_num+1}\":pred_count,\n",
    "        }\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = eval(self.cfg.optimizer.name)(\n",
    "            self.parameters(), **self.cfg.optimizer.params\n",
    "        )\n",
    "\n",
    "        self.scheduler = eval(self.cfg.scheduler.name)(\n",
    "            optimizer, **self.cfg.scheduler.params\n",
    "        )\n",
    "        \n",
    "        scheduler = {\"scheduler\": self.scheduler, \"interval\": \"step\",}\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31796602",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    Training\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ef7ffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>seq</th>\n",
       "      <th>target</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "      <td>[violent and aggressive immigrant]</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "      <td>[fucking]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "      <td>[Damn]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know th...</td>\n",
       "      <td>[knucklehead]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
       "      <td>[killing]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \\\n",
       "0  Another violent and aggressive immigrant killi...   \n",
       "1  I am 56 years old, I am not your fucking junio...   \n",
       "2                  Damn, a whole family. Sad indeed.   \n",
       "3  What a knucklehead. How can anyone not know th...   \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...   \n",
       "\n",
       "                                token  \\\n",
       "0  [violent and aggressive immigrant]   \n",
       "1                           [fucking]   \n",
       "2                              [Damn]   \n",
       "3                       [knucklehead]   \n",
       "4                           [killing]   \n",
       "\n",
       "                                                 seq  target  kfold  \n",
       "0         [0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]       1      3  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...       1      1  \n",
       "2                        [1, 0, 0, 0, 0, 0, 0, 0, 0]       1      0  \n",
       "3      [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]       1      4  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...       1      2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=config.n_fold, \n",
    "    shuffle=True, \n",
    "    random_state=config.seed\n",
    ")\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(skf.split(X=train_df, y=train_df[\"target\"])):\n",
    "    train_df.loc[val_idx, \"kfold\"] = int(fold)\n",
    "\n",
    "train_df[\"kfold\"] = train_df[\"kfold\"].astype(int)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b51b5f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630bea5df0604a1caadcc179360f0510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.62it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.279 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.62it/s\u001b[0m \u001b[37mloss: 0.279 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1f507897b041b5affb0aa86c0fdd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.48it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.838 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.48it/s\u001b[0m \u001b[37mloss: 0.838 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adeb147fe6d74b52b3bbfd0a1c76778b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.30it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.594 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.30it/s\u001b[0m \u001b[37mloss: 0.594 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d8ecf7d2cc4eb5a23570e103ce98dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.29it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.501 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.29it/s\u001b[0m \u001b[37mloss: 0.501 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold5  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795c03f2ed54441e8d66b8f5e8da1bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.19it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.53 v_num:  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m2.19it/s\u001b[0m \u001b[37mloss: 0.53 v_num:  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Debug\n",
    "config.trainer.fast_dev_run = True\n",
    "config.backbone.output_dim = len(target_cols)\n",
    "\n",
    "for fold in config.train_fold:\n",
    "    \n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    df_train = train_df[train_df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    datamodule = JigsawDataModule(df_train, val_df, test_df, config)\n",
    "    sample_dataloader = JigsawDataModule(df_train, val_df, test_df, config).train_dataloader()\n",
    "\n",
    "    config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "    model = JigsawModel(config, fold)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=MODEL_DIR,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config.project, \n",
    "        entity=config.entity,\n",
    "        name = f\"{config.exp_name}\",\n",
    "        tags = ['RoBERTa-Base', \"toxic-spans\"]\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epoch,\n",
    "        callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "#         deterministic=True,\n",
    "        logger=[wandb_logger],\n",
    "        **config.trainer\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28ce0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdataskywalker\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-01-26 15:22:14.668514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">030_exp</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw/runs/q6bx94ke\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw/runs/q6bx94ke</a><br/>\n",
       "                Run data is saved locally in <code>/mnt/work/shimizu/kaggle/Jigsaw/notebooks/wandb/run-20220126_152212-q6bx94ke</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4302d3a872af43cc8208a841d46e9b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">4557/4557</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:06:32 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.39it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.261 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">94ke valid_loss/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.563 valid_acc/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.526                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold1: 0.03</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m4557/4557\u001b[0m \u001b[38;5;245m0:06:32 • 0:00:00\u001b[0m \u001b[38;5;249m12.39it/s\u001b[0m \u001b[37mloss: 0.261 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m94ke valid_loss/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.563 valid_acc/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.526                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold1: 0.03\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff50cbc5ac6447aaf195319a22b75ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">3303/4557</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:04:53 • 0:01:38</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.82it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.476 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">94ke                  </span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Validation</span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2510/3764</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:03:16 • 0:01:38</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">12.82it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.476 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">94ke                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[37m3303/4557\u001b[0m \u001b[38;5;245m0:04:53 • 0:01:38\u001b[0m \u001b[38;5;249m12.82it/s\u001b[0m \u001b[37mloss: 0.476 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m94ke                  \u001b[0m\n",
       "\u001b[37mValidation\u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[37m2510/3764\u001b[0m \u001b[38;5;245m0:03:16 • 0:01:38\u001b[0m \u001b[38;5;249m12.82it/s\u001b[0m \u001b[37mloss: 0.476 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37m94ke                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-44:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 499, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 730, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel      │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm         │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear            │    769 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel      │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm         │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear            │    769 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ criterion  │ BCEWithLogitsLoss │      0 │\n",
       "└───┴────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d0d6b49fd3416bb2fcb6ed6116dc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0   </span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">33/4557</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:04 • 0:09:17</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">8.13it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.657 v_num: 94ke</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0   \u001b[0m \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m33/4557\u001b[0m \u001b[38;5;245m0:00:04 • 0:09:17\u001b[0m \u001b[38;5;249m8.13it/s\u001b[0m \u001b[37mloss: 0.657 v_num: 94ke\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 154, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/spawn.py\", line 118, in _main\n",
      "    return self._bootstrap()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    threading._shutdown()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 1307, in _shutdown\n",
      "    lock.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_22171/2676051309.py\", line 15, in <module>\n",
      "    model = JigsawModel(config, fold)\n",
      "  File \"/tmp/ipykernel_22171/1397220412.py\", line 7, in __init__\n",
      "    self.__build_model()\n",
      "  File \"/tmp/ipykernel_22171/1397220412.py\", line 15, in __build_model\n",
      "    self.cfg.backbone.name\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 1086, in from_pretrained\n",
      "    **kwargs,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\", line 440, in from_pretrained\n",
      "    config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\", line 505, in get_config_dict\n",
      "    user_agent=user_agent,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\", line 1337, in cached_path\n",
      "    local_files_only=local_files_only,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\", line 1499, in get_from_cache\n",
      "    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=etag_timeout)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/requests/api.py\", line 104, in head\n",
      "    return request('head', url, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/requests/sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 706, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 382, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 1010, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\", line 421, in connect\n",
      "    tls_in_tls=tls_in_tls,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/urllib3/util/ssl_.py\", line 450, in ssl_wrap_socket\n",
      "    sock, context, tls_in_tls, server_hostname=server_hostname\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/urllib3/util/ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"/opt/conda/lib/python3.7/ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"/opt/conda/lib/python3.7/ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/opt/conda/lib/python3.7/ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22171/2676051309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJigsawModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlr_monitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22171/1397220412.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, fold_num)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22171/1397220412.py\u001b[0m in \u001b[0;36m__build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         self.base_model = RobertaModel.from_pretrained(\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_pipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \"\"\"\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1336\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    449\u001b[0m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "config.trainer.fast_dev_run = False\n",
    "config.backbone.output_dim = len(target_cols)\n",
    "\n",
    "for fold in config.train_fold:\n",
    "    \n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    df_train = train_df[train_df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    datamodule = JigsawDataModule(df_train, val_df, test_df, config)\n",
    "    sample_dataloader = JigsawDataModule(df_train, val_df, test_df, config).train_dataloader()\n",
    "\n",
    "    config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "    model = JigsawModel(config, fold)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=MODEL_DIR,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config.project, \n",
    "        entity=config.entity,\n",
    "        name = f\"{config.exp_name}\",\n",
    "        tags = ['RoBERTa-Base', \"toxic-spans\"]\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epoch,\n",
    "        callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "#         deterministic=True,\n",
    "        logger=[wandb_logger],\n",
    "        **config.trainer\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57a241f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device == cuda\n",
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Model: roberta-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e3d36ec9248fc936af5c3e8a75b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config.backbone.output_dim = len(target_cols)\n",
    "\n",
    "print(f\"Device == {device}\")\n",
    "\n",
    "MORE = np.zeros((len(val_df), config.backbone.output_dim))\n",
    "LESS = np.zeros((len(val_df), config.backbone.output_dim))\n",
    "PRED = np.zeros((len(test_df), config.backbone.output_dim))\n",
    "\n",
    "attention_array = np.zeros((len(val_df), 256)) # attention格納\n",
    "mask_array = np.zeros((len(val_df), 256)) # mask情報格納,後でattentionと掛け合わせる\n",
    "\n",
    "for fold in config.train_fold:\n",
    "\n",
    "    pred_list = []\n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    valid_dataloader = JigsawDataModule(train_df, val_df, test_df, config).val_dataloader()\n",
    "    model = JigsawModel(config, fold)\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=\"../input/toxicroberta/\",\n",
    "    )\n",
    "    model = model.load_from_checkpoint(MODEL_DIR/f\"best_acc_fold{fold+1}.ckpt\", cfg=config, fold_num=fold)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    more_list = []\n",
    "    less_list = []\n",
    "    \n",
    "    for step, data in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "\n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device)\n",
    "        more_text_token_type_ids = data['more_token_type_ids'].to(device)\n",
    "        \n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device)\n",
    "        less_text_token_type_ids = data['less_token_type_ids'].to(device)\n",
    "        \n",
    "        more_outputs = model(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids,\n",
    "        )\n",
    "        \n",
    "        less_outputs = model(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        more_list.append(more_outputs[\"logits\"].detach().cpu().numpy())\n",
    "        less_list.append(less_outputs[\"logits\"].detach().cpu().numpy())\n",
    "\n",
    "    MORE += np.concatenate(more_list)/len(config.train_fold)\n",
    "    LESS += np.concatenate(less_list)/len(config.train_fold)\n",
    "#     PRED += pred_list/len(config.train_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "946f742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(LESS, MORE)\n",
    "plt.xlabel(\"less-toxic\")\n",
    "plt.ylabel(\"more-toxic\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e48b58bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiki Attack Score: 0.697124\n"
     ]
    }
   ],
   "source": [
    "val_df[\"less_attack\"] = LESS.sum(axis=1)\n",
    "val_df[\"more_attack\"] = MORE.sum(axis=1)\n",
    "val_df[\"diff_attack\"] = val_df[\"more_attack\"] - val_df[\"less_attack\"]\n",
    "attack_score = val_df[val_df[\"diff_attack\"]>0][\"diff_attack\"].count()/len(val_df)\n",
    "print(f\"Wiki Attack Score: {attack_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d249d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715ac65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3f472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
