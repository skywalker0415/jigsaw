{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d7c336",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1602084551218-a28205125639?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2070&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b932fb",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'\n",
    "     style = 'background-color:#4c1c84;\n",
    "              color:#eeebf1;\n",
    "              border-width:5px;\n",
    "              border-color:#4c1c84;\n",
    "              font-family:Comic Sans MS;\n",
    "              border-radius: 50px 50px'>\n",
    "    <p style = 'font-size:24px'>Exp 016</p>\n",
    "    <a href = \"#Config\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">1.Config</a><br>\n",
    "    <a href = \"#Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">2.Settings</a><br>\n",
    "    <a href = \"#Data-Load\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">3.Data Load</a><br>\n",
    "    <a href = \"#Pytorch-Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">4.Pytorch Settings</a><br>\n",
    "    <a href = \"#Training\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">5.Training</a><br>\n",
    "</div>\n",
    "\n",
    "<p style = 'font-size:24px;\n",
    "            color:#4c1c84'>\n",
    "    実施したこと\n",
    "</p>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">過去コンペの予測ラベル</li>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">fasttext</li>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">SVR</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e6222",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Config\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2031109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/utils/iterative-stratification/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6b2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import psutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "from box import Box\n",
    "from typing import Optional\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from tqdm.auto import tqdm as tqdmp\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "tqdmp.pandas()\n",
    "\n",
    "## Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from transformers import RobertaModel, RobertaForSequenceClassification\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning import LightningDataModule, LightningDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "# Model\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd0b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/unitaryai_detoxify_master\n",
      "Downloading: \"https://github.com/unitaryai/detoxify/releases/download/v0.1-alpha/toxic_original-c1212f89.ckpt\" to /root/.cache/torch/hub/checkpoints/toxic_original-c1212f89.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f627198650694169b298e01c2d61b04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91780037ede46b6b90430fe9c922fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7f241640c74bf0ad81809b864c51a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e22180e971415db2caec42f6d69a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c4c8a7c62b4c9eacadbf6df272c6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('unitaryai/detoxify','toxic_bert')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf78127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87648fdf060f404eae804c246c8c8c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3b01a69f224ae3b8e04ca3dbaad65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da7dc9fd08b49d5ab2ce771b4e41245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/174 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200e1e12b25c4249a9f946c892dc5cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/811 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bc25bf74af46e8aef6b92c87eee3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"root\": \"/content/drive/MyDrive/kaggle/Jigsaw/raw\",\n",
    "    \"n_fold\": 5,\n",
    "    \"epoch\": 5,\n",
    "    \"max_length\": 256,\n",
    "    \"environment\": \"AWS\",\n",
    "    \"project\": \"Jigsaw\",\n",
    "    \"entity\": \"dataskywalker\",\n",
    "    \"exp_name\": \"016_exp\",\n",
    "    \"margin\": 0.5,\n",
    "    \"train_fold\": [0, 1, 2, 3, 4],\n",
    "\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 1,\n",
    "        \"accumulate_grad_batches\": 64,\n",
    "        \"progress_bar_refresh_rate\": 1,\n",
    "        \"fast_dev_run\": False,\n",
    "        \"num_sanity_val_steps\": 0,\n",
    "    },\n",
    "\n",
    "    \"train_loader\": {\n",
    "        \"batch_size\": 16,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 4,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"valid_loader\": {\n",
    "        \"batch_size\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"test_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"backbone\": {\n",
    "        \"name\": \"unitary/toxic-bert\",\n",
    "        \"output_dim\": 6,\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"torch.optim.AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 1e-5,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"name\": \"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\",\n",
    "        \"params\": {\n",
    "            \"T_0\": 20,\n",
    "            \"eta_min\": 0,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"loss\": \"nn.BCEWithLogitsLoss\",\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "config.tokenizer = BertTokenizer.from_pretrained(config.backbone.name)\n",
    "config.model = BertForSequenceClassification.from_pretrained(config.backbone.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f73408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your environment is 'AWS'.\n",
      "INPUT_DIR is /mnt/work/data/kaggle/Jigsaw\n",
      "MODEL_DIR is ../models/016_exp\n",
      "OUTPUT_DIR is ../data/interim/016_exp\n",
      "UTIL_DIR is /mnt/work/shimizu/kaggle/PetFinder/src/utils\n"
     ]
    }
   ],
   "source": [
    "# 個人的にAWSやKaggle環境やGoogle Colabを行ったり来たりしているのでまとめています\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if config.environment == 'AWS':\n",
    "    \n",
    "    INPUT_DIR = Path('/mnt/work/data/kaggle/Jigsaw/')\n",
    "    MODEL_DIR = Path(f'../models/{config.exp_name}/')\n",
    "    OUTPUT_DIR = Path(f'../data/interim/{config.exp_name}/')\n",
    "    UTIL_DIR = Path('/mnt/work/shimizu/kaggle/PetFinder/src/utils')\n",
    "    \n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"Your environment is 'AWS'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\\nUTIL_DIR is {UTIL_DIR}\")\n",
    "    \n",
    "    \n",
    "elif config.environment == 'Kaggle':\n",
    "    INPUT_DIR = Path('../input/*****')\n",
    "    MODEL_DIR = Path('./')\n",
    "    OUTPUT_DIR = Path('./')\n",
    "    print(f\"Your environment is 'Kaggle'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "\n",
    "    \n",
    "elif config.environment == 'Colab':\n",
    "    INPUT_DIR = Path('/content/drive/MyDrive/kaggle/Jigsaw/raw')\n",
    "    BASE_DIR = Path(\"/content/drive/MyDrive/kaggle/Jigsaw/interim\")\n",
    "\n",
    "    MODEL_DIR = BASE_DIR / f'{config.exp_name}'\n",
    "    OUTPUT_DIR = BASE_DIR / f'{config.exp_name}/'\n",
    "\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print('Please Mount your Google Drive.')\n",
    "    else:\n",
    "        print(f\"Your environment is 'Colab'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please choose 'AWS' or 'Kaggle' or 'Colab'.\\nINPUT_DIR is not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c9f531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed固定\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e997ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 処理時間計測\n",
    "@contextmanager\n",
    "def timer(name:str, slack:bool=False):\n",
    "    t0 = time.time()\n",
    "    p = psutil.Process(os.getpid())\n",
    "    m0 = p.memory_info()[0] / 2. ** 30\n",
    "    print(f'<< {name} >> Start')\n",
    "    yield\n",
    "    \n",
    "    m1 = p.memory_info()[0] / 2. ** 30\n",
    "    delta = m1 - m0\n",
    "    sign = '+' if delta >= 0 else '-'\n",
    "    delta = math.fabs(delta)\n",
    "    \n",
    "    print(f\"<< {name} >> {m1:.1f}GB({sign}{delta:.1f}GB):{time.time() - t0:.1f}sec\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88d239",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Data Load\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22e7ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/sample_submission.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "## Data Check\n",
    "for dirnames, _, filenames in os.walk(INPUT_DIR):\n",
    "    \n",
    "    for filename in filenames:\n",
    "\n",
    "        print(f'{dirnames}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26a46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/validation_data.csv\")\n",
    "test_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c515640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b717c95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0  ...        2006  rejected      0    0    0      0         0   \n",
       "1  ...        2006  rejected      0    0    0      0         0   \n",
       "2  ...        2006  rejected      0    0    0      0         0   \n",
       "3  ...        2006  rejected      0    0    0      0         0   \n",
       "4  ...        2006  rejected      0    0    0      1         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0              0.0                         0                         4  \n",
       "1              0.0                         0                         4  \n",
       "2              0.0                         0                         4  \n",
       "3              0.0                         0                         4  \n",
       "4              0.0                         4                        47  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/external/jigsaw1st/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4780fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183894</th>\n",
       "      <td>5563153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Mr. Milner, after reading your thought provoki...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>352273</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183892</th>\n",
       "      <td>5563151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Or in other words, the road to hell is paved w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>351464</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183891</th>\n",
       "      <td>5563149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Tony -  Russia backed many liberation struggle...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>351814</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183890</th>\n",
       "      <td>5563148</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>DM, how do this dude's \"articles\" make it thro...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>353561</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341396</th>\n",
       "      <td>5754942</td>\n",
       "      <td>0.973936</td>\n",
       "      <td>BURN THIS DOG RAPING WHITE NIGER ALIVE\\nTIME f...</td>\n",
       "      <td>0.569070</td>\n",
       "      <td>0.596872</td>\n",
       "      <td>0.917463</td>\n",
       "      <td>0.887055</td>\n",
       "      <td>0.892268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>365110</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130321</td>\n",
       "      <td>0</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679044</th>\n",
       "      <td>6180251</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>DOGS----\\nEAT\\nSHIT\\nSLEEP\\nBARK\\n\\nNIGERS\\nEA...</td>\n",
       "      <td>0.591236</td>\n",
       "      <td>0.972389</td>\n",
       "      <td>0.909964</td>\n",
       "      <td>0.971789</td>\n",
       "      <td>0.819928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>390746</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701080</td>\n",
       "      <td>0</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443046</th>\n",
       "      <td>5883664</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>.\\n.\\nIs there really a God ?\\n... I once thou...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>373036</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532869</th>\n",
       "      <td>5997855</td>\n",
       "      <td>0.983501</td>\n",
       "      <td>You are murdering feckless SCUM.  Your mother ...</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>0.970669</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.978002</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>379957</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857929</td>\n",
       "      <td>10</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377740</th>\n",
       "      <td>5801652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Awesome! Lets cut the head off hate! Lets stab...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>368010</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1804874 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    target                                       comment_text  \\\n",
       "0          59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1183894  5563153  0.000000  Mr. Milner, after reading your thought provoki...   \n",
       "1183892  5563151  0.000000  Or in other words, the road to hell is paved w...   \n",
       "1183891  5563149  0.000000  Tony -  Russia backed many liberation struggle...   \n",
       "1183890  5563148  0.100000  DM, how do this dude's \"articles\" make it thro...   \n",
       "...          ...       ...                                                ...   \n",
       "1341396  5754942  0.973936  BURN THIS DOG RAPING WHITE NIGER ALIVE\\nTIME f...   \n",
       "1679044  6180251  0.990396  DOGS----\\nEAT\\nSHIT\\nSLEEP\\nBARK\\n\\nNIGERS\\nEA...   \n",
       "1443046  5883664  0.900000  .\\n.\\nIs there really a God ?\\n... I once thou...   \n",
       "1532869  5997855  0.983501  You are murdering feckless SCUM.  Your mother ...   \n",
       "1377740  5801652  1.000000  Awesome! Lets cut the head off hate! Lets stab...   \n",
       "\n",
       "         severe_toxicity   obscene  identity_attack    insult    threat  \\\n",
       "0               0.000000  0.000000         0.000000  0.000000  0.000000   \n",
       "1183894         0.000000  0.000000         0.000000  0.000000  0.000000   \n",
       "1183892         0.000000  0.000000         0.000000  0.000000  0.000000   \n",
       "1183891         0.000000  0.000000         0.000000  0.000000  0.000000   \n",
       "1183890         0.000000  0.000000         0.000000  0.200000  0.000000   \n",
       "...                  ...       ...              ...       ...       ...   \n",
       "1341396         0.569070  0.596872         0.917463  0.887055  0.892268   \n",
       "1679044         0.591236  0.972389         0.909964  0.971789  0.819928   \n",
       "1443046         0.600000  0.800000         0.400000  0.800000  0.500000   \n",
       "1532869         0.644363  0.970669         0.076994  0.978002  0.739688   \n",
       "1377740         1.000000  0.000000         0.000000  1.000000  1.000000   \n",
       "\n",
       "         asian  atheist  ...  article_id    rating  funny  wow  sad  likes  \\\n",
       "0          NaN      NaN  ...        2006  rejected      0    0    0      0   \n",
       "1183894    0.0      0.0  ...      352273  approved      0    0    0      0   \n",
       "1183892    NaN      NaN  ...      351464  approved      0    0    0      0   \n",
       "1183891    NaN      NaN  ...      351814  approved      0    0    0      0   \n",
       "1183890    NaN      NaN  ...      353561  approved      0    0    0      6   \n",
       "...        ...      ...  ...         ...       ...    ...  ...  ...    ...   \n",
       "1341396    NaN      NaN  ...      365110  rejected      0    0    0      0   \n",
       "1679044    NaN      NaN  ...      390746  rejected      0    0    0      0   \n",
       "1443046    0.0      0.0  ...      373036  approved      0    0    0      2   \n",
       "1532869    0.0      0.0  ...      379957  rejected      0    0    0      0   \n",
       "1377740    NaN      NaN  ...      368010  rejected      0    0    0      0   \n",
       "\n",
       "         disagree  sexual_explicit  identity_annotator_count  \\\n",
       "0               0         0.000000                         0   \n",
       "1183894         0         0.000000                         4   \n",
       "1183892         0         0.000000                         0   \n",
       "1183891         0         0.000000                         0   \n",
       "1183890         0         0.000000                         0   \n",
       "...           ...              ...                       ...   \n",
       "1341396         0         0.130321                         0   \n",
       "1679044         0         0.701080                         0   \n",
       "1443046         0         0.900000                        10   \n",
       "1532869         0         0.857929                        10   \n",
       "1377740         0         0.000000                         0   \n",
       "\n",
       "         toxicity_annotator_count  \n",
       "0                               4  \n",
       "1183894                         4  \n",
       "1183892                         4  \n",
       "1183891                         4  \n",
       "1183890                        10  \n",
       "...                           ...  \n",
       "1341396                      1151  \n",
       "1679044                      1666  \n",
       "1443046                        10  \n",
       "1532869                      1091  \n",
       "1377740                         4  \n",
       "\n",
       "[1804874 rows x 45 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(\"severe_toxicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a50f090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59859</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59861</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>hahahahahahahahhha suck it.</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>239579</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>This is a great story. Man. I wonder if the pe...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26650</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>239583</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>It's ridiculous that these guys are being call...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26670</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804863</th>\n",
       "      <td>6333950</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Nah, I am too boring to parody.  This guy Camp...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>399210</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804865</th>\n",
       "      <td>6333955</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Payette's point of view is legitimate and I th...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>399528</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804866</th>\n",
       "      <td>6333957</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>There's no whine like Alberta whine!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>399472</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804867</th>\n",
       "      <td>6333963</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>If Alberta had given them nothing, you'd STILL...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>399472</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804872</th>\n",
       "      <td>6334009</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>Anyone who is quoted as having the following e...</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>399519</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540110 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    target                                       comment_text  \\\n",
       "4          59856  0.893617               haha you guys are a bunch of losers.   \n",
       "5          59859  0.666667                               ur a sh*tty comment.   \n",
       "6          59861  0.457627                        hahahahahahahahhha suck it.   \n",
       "11        239579  0.440000  This is a great story. Man. I wonder if the pe...   \n",
       "13        239583  0.600000  It's ridiculous that these guys are being call...   \n",
       "...          ...       ...                                                ...   \n",
       "1804863  6333950  0.200000  Nah, I am too boring to parody.  This guy Camp...   \n",
       "1804865  6333955  0.166667  Payette's point of view is legitimate and I th...   \n",
       "1804866  6333957  0.300000               There's no whine like Alberta whine!   \n",
       "1804867  6333963  0.200000  If Alberta had given them nothing, you'd STILL...   \n",
       "1804872  6334009  0.621212  Anyone who is quoted as having the following e...   \n",
       "\n",
       "         severe_toxicity   obscene  identity_attack    insult  threat  asian  \\\n",
       "4               0.021277  0.000000         0.021277  0.872340     0.0    0.0   \n",
       "5               0.047619  0.638095         0.000000  0.333333     0.0    NaN   \n",
       "6               0.050847  0.305085         0.000000  0.254237     0.0    NaN   \n",
       "11              0.000000  0.293333         0.000000  0.320000     0.0    0.0   \n",
       "13              0.000000  0.100000         0.000000  0.600000     0.1    NaN   \n",
       "...                  ...       ...              ...       ...     ...    ...   \n",
       "1804863         0.000000  0.000000         0.000000  0.200000     0.0    0.0   \n",
       "1804865         0.000000  0.000000         0.166667  0.166667     0.0    NaN   \n",
       "1804866         0.000000  0.000000         0.000000  0.100000     0.0    NaN   \n",
       "1804867         0.000000  0.000000         0.000000  0.200000     0.0    NaN   \n",
       "1804872         0.030303  0.030303         0.045455  0.621212     0.0    NaN   \n",
       "\n",
       "         atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "4            0.0  ...        2006  rejected      0    0    0      1         0   \n",
       "5            NaN  ...        2006  rejected      0    0    0      0         0   \n",
       "6            NaN  ...        2006  rejected      0    0    0      0         0   \n",
       "11           0.0  ...       26650  approved      0    0    0      1         0   \n",
       "13           NaN  ...       26670  approved      0    0    0      3         0   \n",
       "...          ...  ...         ...       ...    ...  ...  ...    ...       ...   \n",
       "1804863      0.0  ...      399210  approved      0    0    0      0         0   \n",
       "1804865      NaN  ...      399528  approved      0    0    0      0         0   \n",
       "1804866      NaN  ...      399472  approved      0    0    0      0         0   \n",
       "1804867      NaN  ...      399472  approved      0    0    0      0         0   \n",
       "1804872      NaN  ...      399519  approved      0    0    0      0         0   \n",
       "\n",
       "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "4               0.000000                         4                        47  \n",
       "5               0.009524                         0                       105  \n",
       "6               0.220339                         0                        59  \n",
       "11              0.040000                        10                        75  \n",
       "13              0.000000                         0                        10  \n",
       "...                  ...                       ...                       ...  \n",
       "1804863         0.000000                         4                        10  \n",
       "1804865         0.000000                         0                         6  \n",
       "1804866         0.200000                         0                        10  \n",
       "1804867         0.000000                         0                         5  \n",
       "1804872         0.000000                         0                        66  \n",
       "\n",
       "[540110 rows x 45 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"]>0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "267e5831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9975787 , 0.6898789 , 0.9811094 , 0.64655876, 0.94840175,\n",
       "        0.14950171]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = config.tokenizer.encode_plus(\n",
    "    train_df.loc[1532869, \"comment_text\"],\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "outputs = config.model(**inputs)[0]\n",
    "outputs = torch.sigmoid(outputs).detach().numpy()\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916271a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(width=outputs[0, :7],\n",
    "         y=[\"toxicity\",\n",
    "           \"severe_toxicity\",\n",
    "           \"obscene\",\n",
    "           \"threat\",\n",
    "           \"insult\",\n",
    "           \"identity_attack\",\n",
    "          ])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9319330",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Previous Toxic Feature Label\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d611f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature(df:pd.DataFrame, col:str) -> pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    Jigsaw Unintended Bias in Toxicity Classificationコンペで学習されたモデルからの予測ラベル\n",
    "    '''\n",
    "    \n",
    "    text_list = df[col].tolist()\n",
    "    feature = []\n",
    "    \n",
    "    for text in tqdm(text_list, total=len(text_list)):\n",
    "        inputs = config.tokenizer.encode_plus(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        )\n",
    "        outputs = config.model(**inputs)[0]\n",
    "        outputs = torch.sigmoid(outputs).detach().numpy()\n",
    "        feature.append(outputs[0])\n",
    "        \n",
    "    feature_cols = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"]\n",
    "    feature_df = pd.DataFrame(feature, cols=feature_cols)\n",
    "    feature_df = pd.concat([df[[col]], feature_df], axis=1)\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d71b2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< make feature label >> Start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af8549145b14bacb41b81135a1250fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/540110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2592/356918243.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"make feature label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     train_feature_df = make_feature(train_df[train_df[\"target\"]>0.].reset_index(drop=True),\n\u001b[0;32m----> 3\u001b[0;31m                                     \"comment_text\")\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2592/472794010.py\u001b[0m in \u001b[0;36mmake_feature\u001b[0;34m(df, col)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"toxicity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"severe_toxicity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"obscene\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"threat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"insult\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"identity_attack\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mfeature_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mfeature_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'cols'"
     ]
    }
   ],
   "source": [
    "with timer(\"make feature label\"):\n",
    "    train_feature_df = make_feature(train_df[train_df[\"target\"]>0.].reset_index(drop=True),\n",
    "                                    \"comment_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df.to_csv(OUTPUT_DIR/f\"train_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9088750",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45425e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
