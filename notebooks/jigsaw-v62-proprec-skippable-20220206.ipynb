{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f7059e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:37.045272Z",
     "iopub.status.busy": "2022-02-06T14:18:37.044153Z",
     "iopub.status.idle": "2022-02-06T14:18:38.297202Z",
     "shell.execute_reply": "2022-02-06T14:18:38.296489Z",
     "shell.execute_reply.started": "2022-02-06T13:00:17.432174Z"
    },
    "papermill": {
     "duration": 1.283854,
     "end_time": "2022-02-06T14:18:38.297431",
     "exception": false,
     "start_time": "2022-02-06T14:18:37.013577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jigsaw-toxic-severity-rating/sample_submission.csv\n",
      "/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\n",
      "/kaggle/input/jigsaw-toxic-severity-rating/comments_to_score.csv\n",
      "/kaggle/input/ruddit-jigsaw-dataset/LICENSE\n",
      "/kaggle/input/ruddit-jigsaw-dataset/README.md\n",
      "/kaggle/input/ruddit-jigsaw-dataset/requirements.txt\n",
      "/kaggle/input/ruddit-jigsaw-dataset/ruddit-comment-extraction.ipynb\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/create_dataset_variants.py\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/identityterms_group.txt\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/Ruddit.csv\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/ReadMe.md\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/Ruddit_individual_annotations.csv\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/node_dictionary.npy\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/post_with_issues.csv\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/Thread_structure.txt\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/load_node_dictionary.py\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Dataset/sample_input_file.csv\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Models/BERT.py\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Models/create_splits.py\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Models/README.md\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Models/BiLSTM.py\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Models/info.md\n",
      "/kaggle/input/ruddit-jigsaw-dataset/Models/HateBERT.py\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/all_data.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test_public_expanded.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test_private_expanded.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/toxicity_individual_annotations.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/identity_individual_annotations.csv\n",
      "/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test_labels.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation-processed-seqlen128.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test-processed-seqlen128.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train-processed-seqlen128.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\n",
      "/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train-processed-seqlen128.csv\n",
      "/kaggle/input/jigsaw-202201/list_vec_0206_x5_seed10.pkl\n",
      "/kaggle/input/jigsaw-202201/df_uni.pkl\n",
      "/kaggle/input/jigsaw-202201/list_list_model_0205_x3.pkl\n",
      "/kaggle/input/jigsaw-202201/df_train_0206.pkl\n",
      "/kaggle/input/jigsaw-202201/df_mulwi.pkl\n",
      "/kaggle/input/jigsaw-202201/df_uni_0205.pkl\n",
      "/kaggle/input/jigsaw-202201/df_train_0205.pkl\n",
      "/kaggle/input/jigsaw-202201/df_uni_0206.pkl\n",
      "/kaggle/input/jigsaw-202201/df_mulwi_0206.pkl\n",
      "/kaggle/input/jigsaw-202201/df_rud_0206.pkl\n",
      "/kaggle/input/jigsaw-202201/df_rud.pkl\n",
      "/kaggle/input/jigsaw-202201/list_list_model_0206_x5_seed10.pkl\n",
      "/kaggle/input/jigsaw-202201/df_train.pkl\n",
      "/kaggle/input/jigsaw-202201/df_val_0206.pkl\n",
      "/kaggle/input/jigsaw-202201/df_rud_0205.pkl\n",
      "/kaggle/input/jigsaw-202201/df_mulwi_0205.pkl\n",
      "/kaggle/input/jigsaw-202201/list_vec_0205_x3.pkl\n",
      "/kaggle/input/jigsaw-202201/df_val.pkl\n",
      "/kaggle/input/jigsaw-202201/df_val_0205.pkl\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import sys\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import rankdata\n",
    "import pickle\n",
    "# import texthero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50089d51",
   "metadata": {
    "papermill": {
     "duration": 0.026343,
     "end_time": "2022-02-06T14:18:38.350514",
     "exception": false,
     "start_time": "2022-02-06T14:18:38.324171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2/5 KAGGLE_INFERENCE=Trueだと前処理STEP1・STEP2を飛ばしpseudolabelingから開始(時短＆メモリ節約)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b57207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:38.422174Z",
     "iopub.status.busy": "2022-02-06T14:18:38.421183Z",
     "iopub.status.idle": "2022-02-06T14:18:38.423572Z",
     "shell.execute_reply": "2022-02-06T14:18:38.424306Z",
     "shell.execute_reply.started": "2022-02-06T13:00:17.474535Z"
    },
    "papermill": {
     "duration": 0.042899,
     "end_time": "2022-02-06T14:18:38.424539",
     "exception": false,
     "start_time": "2022-02-06T14:18:38.381640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KAGGLE_INFERENCE = True\n",
    "if KAGGLE_INFERENCE:\n",
    "    PREPROC_STEP1 = False\n",
    "    PREPROC_STEP2 = False\n",
    "    TEST_INFERENCE = True\n",
    "    VAL_CHECK = True\n",
    "else:\n",
    "    PREPROC_STEP1 = True  # 前処理STEP1を実行する場合はTrue、skipしてpickleから読む場合はFalse\n",
    "    PREPROC_STEP2 = True  # 前処理STEP2を実行する場合はTrue、skipしてpickleから読む場合はFalse\n",
    "    TEST_INFERENCE = True  # テストデータを使った推論時はTrue\n",
    "    VAL_CHECK = True  # バリデーションチェック時はTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318fa107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:38.490683Z",
     "iopub.status.busy": "2022-02-06T14:18:38.490065Z",
     "iopub.status.idle": "2022-02-06T14:18:38.492098Z",
     "shell.execute_reply": "2022-02-06T14:18:38.492675Z",
     "shell.execute_reply.started": "2022-02-06T13:00:17.482660Z"
    },
    "papermill": {
     "duration": 0.033871,
     "end_time": "2022-02-06T14:18:38.492836",
     "exception": false,
     "start_time": "2022-02-06T14:18:38.458965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PARAM_TFIDF = \"char\"\n",
    "PARAM_TFIDF = \"char_wb\"\n",
    "# PARAM_TFIDF = \"word\"\n",
    "PARAM_RIDGE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f604e7a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:38.549998Z",
     "iopub.status.busy": "2022-02-06T14:18:38.549330Z",
     "iopub.status.idle": "2022-02-06T14:18:38.795169Z",
     "shell.execute_reply": "2022-02-06T14:18:38.794653Z",
     "shell.execute_reply.started": "2022-02-06T13:00:17.496957Z"
    },
    "papermill": {
     "duration": 0.274541,
     "end_time": "2022-02-06T14:18:38.795345",
     "exception": false,
     "start_time": "2022-02-06T14:18:38.520804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2/6 最終版\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "\n",
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text\n",
    "\n",
    "def text_cleaning_hitomoji(text):\n",
    "    \"\"\"1文字だけのテキストを結合する\"\"\"\n",
    "    text = re.sub('\\s(.)\\s', r' #\\1# ', text, 5)\n",
    "    text = re.sub('^(.)\\s', r' #\\1# ', text, 5)\n",
    "    text1 = re.sub('\\s(.)$', r' #\\1# ', text, 5)\n",
    "    text2 = text1\n",
    "    text_old = \"\"\n",
    "    while text2 != text_old:\n",
    "        text_old = text2\n",
    "        text2 = re.sub('#\\s(.)\\s', r'\\1# ', text_old)\n",
    "    text3 = re.sub('#\\s#', r'',text2)\n",
    "    text4 = re.sub('#', r'',text3)\n",
    "    return text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a74c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:38.851463Z",
     "iopub.status.busy": "2022-02-06T14:18:38.850696Z",
     "iopub.status.idle": "2022-02-06T14:18:39.354224Z",
     "shell.execute_reply": "2022-02-06T14:18:39.353678Z",
     "shell.execute_reply.started": "2022-02-06T13:00:17.514183Z"
    },
    "papermill": {
     "duration": 0.532647,
     "end_time": "2022-02-06T14:18:39.354405",
     "exception": false,
     "start_time": "2022-02-06T14:18:38.821758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2/6 最終版\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english') + ['utc', 'jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "def clean(data, col):\n",
    "\n",
    "    # 2022/1/24 まず小文字にする\n",
    "    data[col] = data[col].str.lower()\n",
    "\n",
    "    # 2022/1/22 HTMLタグの削除など\n",
    "    data[col] = data[col].map(text_cleaning)\n",
    "\n",
    "    # 2022/1/31 追加 https://www.kaggle.com/sklasfeld/jigsaw-naive-bayes-and-ridge-regression-explained\n",
    "    data[col] = data[col].str.replace(\"#ofc\", \" of fuckin course \")\n",
    "    data[col] = data[col].str.replace(\"fggt\", \" faggot \")\n",
    "    data[col] = data[col].str.replace(\"your\", \" your \")\n",
    "    data[col] = data[col].str.replace(\"self\", \" self \")\n",
    "    data[col] = data[col].str.replace(\"cuntbag\", \" cunt bag \")\n",
    "    data[col] = data[col].str.replace(\"fartchina\", \" fart china \")    \n",
    "    data[col] = data[col].str.replace(\"youi\", \" you i \")\n",
    "    data[col] = data[col].str.replace(\"cunti\", \" cunt i \")\n",
    "    data[col] = data[col].str.replace(\"sucki\", \" suck i \")\n",
    "    data[col] = data[col].str.replace(\"pagedelete\", \" page delete \")\n",
    "    data[col] = data[col].str.replace(\"cuntsi\", \" cuntsi \")\n",
    "    data[col] = data[col].str.replace(\"i'm\", \" i am \")\n",
    "    data[col] = data[col].str.replace(\"offuck\", \" of fuck \")\n",
    "    data[col] = data[col].str.replace(\"centraliststupid\", \" central ist stupid \")\n",
    "    data[col] = data[col].str.replace(\"hitleri\", \" hitler i \")\n",
    "    data[col] = data[col].str.replace(\"i've\", \" i have \")\n",
    "    data[col] = data[col].str.replace(\"i'll\", \" sick \")\n",
    "    data[col] = data[col].str.replace(\"fuck\", \" fuck \")\n",
    "    data[col] = data[col].str.replace(\"f u c k\", \" fuck \")\n",
    "    data[col] = data[col].str.replace(\"shit\", \" shit \")\n",
    "    data[col] = data[col].str.replace(\"bunksteve\", \" bunk steve \")\n",
    "#     data[col] = data[col].str.replace('wikipedia', ' social medium ')\n",
    "    data[col] = data[col].str.replace(\"faggot\", \" faggot \")\n",
    "    data[col] = data[col].str.replace(\"delanoy\", \" delanoy \")\n",
    "    data[col] = data[col].str.replace(\"jewish\", \" jewish \")\n",
    "    data[col] = data[col].str.replace(\"sexsex\", \" sex \")\n",
    "    data[col] = data[col].str.replace(\"allii\", \" all ii \")\n",
    "    data[col] = data[col].str.replace(\"i'd\", \" i had \")\n",
    "    data[col] = data[col].str.replace(\"'s\", \" is \")\n",
    "    data[col] = data[col].str.replace(\"youbollocks\", \" you bollocks \")\n",
    "    data[col] = data[col].str.replace(\"dick\", \" dick \")\n",
    "    data[col] = data[col].str.replace(\"cuntsi\", \" cuntsi \")\n",
    "    data[col] = data[col].str.replace(\"mothjer\", \" mother \")\n",
    "    data[col] = data[col].str.replace(\"cuntfranks\", \" cunt \")\n",
    "    data[col] = data[col].str.replace(\"ullmann\", \" jewish \")\n",
    "    data[col] = data[col].str.replace(\"mr.\", \" mister \", regex=False)\n",
    "    data[col] = data[col].str.replace(\"aidsaids\", \" aids \")\n",
    "    data[col] = data[col].str.replace(\"njgw\", \" nigger \")\n",
    "#     data[col] = data[col].str.replace(\"wiki\", \" social medium \")\n",
    "    data[col] = data[col].str.replace(\"administrator\", \" admin \")\n",
    "    data[col] = data[col].str.replace(\"gamaliel\", \" jewish \")\n",
    "    data[col] = data[col].str.replace(\"rvv\", \" vanadalism \")\n",
    "    data[col] = data[col].str.replace(\"admins\", \" admin \")\n",
    "    data[col] = data[col].str.replace(\"pensnsnniensnsn\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"pneis\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"pennnis\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"pov.\", \" point of view \", regex=False)\n",
    "    data[col] = data[col].str.replace(\"vandalising\", \" vandalism \")\n",
    "    data[col] = data[col].str.replace(\"cock\", \" dick \")\n",
    "    data[col] = data[col].str.replace(\"asshole\", \" asshole \")\n",
    "    data[col] = data[col].str.replace(\"youi\", \" you \")\n",
    "    data[col] = data[col].str.replace(\"afd\", \" all fucking day \")\n",
    "    data[col] = data[col].str.replace(\"sockpuppets\", \" sockpuppetry \")\n",
    "    data[col] = data[col].str.replace(\"iiprick\", \" iprick \")\n",
    "    data[col] = data[col].str.replace(\"penisi\", \" penis \")\n",
    "    data[col] = data[col].str.replace(\"warrior\", \" warrior \")\n",
    "    data[col] = data[col].str.replace(\"loil\", \" laughing out insanely loud \")\n",
    "    data[col] = data[col].str.replace(\"vandalise\", \" vanadalism \")\n",
    "    data[col] = data[col].str.replace(\"helli\", \" helli \")\n",
    "    data[col] = data[col].str.replace(\"lunchablesi\", \" lunchablesi \")\n",
    "    data[col] = data[col].str.replace(\"special\", \" special \")\n",
    "    data[col] = data[col].str.replace(\"ilol\", \" i lol \")\n",
    "    data[col] = data[col].str.replace(r'\\b[uU]\\b', 'you', regex=True)\n",
    "    data[col] = data[col].str.replace(r\"what's\", \"what is \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'s\", \" is \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'ve\", \" have \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"can't\", \"cannot \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"n't\", \" not \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"i'm\", \"i am \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'re\", \" are \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'d\", \" would \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=False)\n",
    "    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=False)    \n",
    "#     data[col] = data[col].str.replace(r\"what's\", \"what is \", regex=True)    \n",
    "#     data[col] = data[col].str.replace(r\"\\'ve\", \" have \", regex=True)\n",
    "#     data[col] = data[col].str.replace(r\"can't\", \"cannot \", regex=True)\n",
    "#     data[col] = data[col].str.replace(r\"n't\", \" not \", regex=True)\n",
    "#     data[col] = data[col].str.replace(r\"i'm\", \"i am \", regex=True)\n",
    "#     data[col] = data[col].str.replace(r\"\\'re\", \" are \", regex=True)\n",
    "#     data[col] = data[col].str.replace(r\"\\'d\", \" would \", regex=True)\n",
    "#     data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=True)\n",
    "#     data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=True)\n",
    "    data[col] = data[col].str.replace(r\"\\'s\", \" \", regex=False)\n",
    "\n",
    "    # 2022/1/22 数字は削除する\n",
    "    data[col] = data[col].str.replace(r\"[\\d]\", \" \", regex=True)\n",
    "\n",
    "    # Clean some punctutations\n",
    "    data[col] = data[col].str.replace('\\n', ' \\n ')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3', regex=True)\n",
    "    # Replace repeating characters more than 3 times to length of 3\n",
    "    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1', regex=True)\n",
    "    # Add space around repeating characters\n",
    "    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ', regex=True)    \n",
    "    # patterns with repeating characters \n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1', regex=True)\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1', regex=True)\n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n",
    "\n",
    "    # 2022/1/22 特殊文字を除去する\n",
    "    # 2022/1/26 特殊文字を「_」に変換する\n",
    "    data[col] = data[col].str.replace(r'[^a-zA-Z\\d]', r' ', regex=True)\n",
    "\n",
    "    # 2022/1/22 完全に空白を除去する\n",
    "    if PARAM_TFIDF == \"char\":\n",
    "        data[col] = data[col].map(lambda x: '_'.join([word for word in x.split() if word not in (stop)]))\n",
    "    #     data[col] = data[col].apply(lambda x: ''.join([word for word in x.split() if word not in (stop)]))\n",
    "    else:\n",
    "        data[col] = data[col].map(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    data[col] = data[col].map(text_cleaning_hitomoji)\n",
    "\n",
    "#     # 2022/1/22 レンマタイズ（活用を除去）→精度あがらず\n",
    "#     data[col] = data[col].map(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)]))\n",
    "\n",
    "#     # 2022/1/29 stopワードを除去（追加分）→これも精度あがらず\n",
    "#     data[col] = data[col].map(lambda x: ' '.join([word for word in x.split() if word not in (stop_tsuika)]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04aa14c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:39.415678Z",
     "iopub.status.busy": "2022-02-06T14:18:39.414997Z",
     "iopub.status.idle": "2022-02-06T14:18:39.423736Z",
     "shell.execute_reply": "2022-02-06T14:18:39.424203Z",
     "shell.execute_reply.started": "2022-02-06T13:00:19.778701Z"
    },
    "papermill": {
     "duration": 0.043781,
     "end_time": "2022-02-06T14:18:39.424396",
     "exception": false,
     "start_time": "2022-02-06T14:18:39.380615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "# ベクトルとモデルを生成\n",
    "def read_and_clean(path, list_col_name):\n",
    "    df = pd.read_csv(path)\n",
    "    for col in list_col_name:\n",
    "        df = clean(df, col)\n",
    "    print(df.head(3))\n",
    "    return df\n",
    "\n",
    "def get_vec_model(sr_all_text, df, df_pseudo, list_loop, param_bootstrap):\n",
    "    \"\"\"vecは1つ、modelは複数返す\"\"\"\n",
    "    list_model = []\n",
    "    #     count_min = int((len(sr_all_text) / 10000) ** 0.5) + 1\n",
    "    vec = TfidfVectorizer(analyzer=PARAM_TFIDF, max_df=0.9, min_df=1, ngram_range=(2, 6))\n",
    "    vec.fit(sr_all_text)\n",
    "    if param_bootstrap >= 1:\n",
    "        for seed_now in list_loop:\n",
    "            # 有害なものと同件の無害なものをブートストラップする　ここから\n",
    "            # ①有害なものの件数\n",
    "            min_len = len(sr_all_text) * param_bootstrap\n",
    "            str_undersample = f\"アンダーサンプリング有害コメントの{param_bootstrap}倍\"\n",
    "            # ②無害なものを抽出\n",
    "            if min_len < len(df['y'] == 0):\n",
    "                df_y0_bootstrap = df[df['y'] == 0].sample(n=min_len, random_state=seed_now)\n",
    "                print(str_undersample)\n",
    "            else:\n",
    "                df_y0_bootstrap = df[df['y'] == 0]\n",
    "                print(\"アンダーサンプリング全件\")\n",
    "            # ③新しいデータフレームを作る（スコアは正規化する）\n",
    "            df_now = pd.concat([df[df['y'] > 0], df_y0_bootstrap])\n",
    "            df_now[\"y\"] = scipy.stats.zscore(df_now[\"y\"])\n",
    "            # 有害なものと同件の無害なものをブートストラップする　ここまで\n",
    "            print(df_now.shape)\n",
    "            df_now = pd.concat([df_now, df_pseudo]).reset_index(drop=True)\n",
    "            X = vec.transform(df_now['text'])\n",
    "            y = np.around(df_now[\"y\"], decimals=2)\n",
    "            model = Ridge(alpha=PARAM_RIDGE)\n",
    "            model.fit(X, y)\n",
    "            list_model.append(model)\n",
    "    else:\n",
    "        # スコアを正規化する\n",
    "        df[\"y\"] = scipy.stats.zscore(df[\"y\"])\n",
    "        df_now = pd.concat([df, df_pseudo]).reset_index(drop=True)\n",
    "        X = vec.transform(df_now['text'])\n",
    "        y = np.around(df_now[\"y\"], decimals=2)\n",
    "        for ridge_param_now in list_loop:\n",
    "            print(df_now.shape)\n",
    "            model = Ridge(alpha=ridge_param_now)\n",
    "            model.fit(X, y)\n",
    "            list_model.append(model)\n",
    "        \n",
    "    return vec, list_model\n",
    "\n",
    "def get_test(vec, list_model, df):\n",
    "    X = vec.transform(df['text'])\n",
    "    preds = np.zeros(X.shape[0])\n",
    "    for model in list_model:\n",
    "        preds += model.predict(X)\n",
    "    # 2/6 バグ修正\n",
    "    preds /= len(list_model)\n",
    "    return preds\n",
    "\n",
    "def get_omomi(df, omomi, cname):\n",
    "    df[cname] = 0\n",
    "    for k, v in omomi.items():\n",
    "        if k in df.columns:\n",
    "            df[cname] += df[k] * v\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02de9bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T00:43:45.30316Z",
     "iopub.status.busy": "2022-02-01T00:43:45.301832Z",
     "iopub.status.idle": "2022-02-01T00:43:45.329477Z",
     "shell.execute_reply": "2022-02-01T00:43:45.328128Z",
     "shell.execute_reply.started": "2022-02-01T00:43:45.303085Z"
    },
    "papermill": {
     "duration": 0.025347,
     "end_time": "2022-02-06T14:18:39.475842",
     "exception": false,
     "start_time": "2022-02-06T14:18:39.450495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 前処理STEP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5808341b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:39.537012Z",
     "iopub.status.busy": "2022-02-06T14:18:39.536210Z",
     "iopub.status.idle": "2022-02-06T14:18:54.645832Z",
     "shell.execute_reply": "2022-02-06T14:18:54.646294Z",
     "shell.execute_reply.started": "2022-02-06T13:00:19.814313Z"
    },
    "papermill": {
     "duration": 15.143633,
     "end_time": "2022-02-06T14:18:54.646479",
     "exception": false,
     "start_time": "2022-02-06T14:18:39.502846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   comment_id                                               text\n",
      "0      114890  gjalexei asked whether anti editorializing pol...\n",
      "1      732895               looks like abuser please look thanks\n",
      "2     1139051  confess complete apparently blissful ignorance...\n"
     ]
    }
   ],
   "source": [
    "if PREPROC_STEP1:\n",
    "    df_test = read_and_clean(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\", ['text'])\n",
    "    df_test.to_pickle(\"df_test_0206.pkl\")\n",
    "    df_val = read_and_clean(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\", ['less_toxic', 'more_toxic'])\n",
    "    df_val.to_pickle(\"df_val_0206.pkl\")\n",
    "    df_train = read_and_clean(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\", ['comment_text'])\n",
    "    df_train.to_pickle(\"df_train_0206.pkl\")\n",
    "    df_rud =read_and_clean(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\", ['txt'])\n",
    "    df_rud.to_pickle(\"df_rud_0206.pkl\")\n",
    "    df_mulwi = read_and_clean('../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv', ['comment_text'])\n",
    "    df_mulwi.to_pickle(\"df_mulwi_0206.pkl\")\n",
    "    df_uni = read_and_clean('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', ['comment_text'])\n",
    "    df_uni.to_pickle(\"df_uni_0206.pkl\")\n",
    "else:\n",
    "    df_test = read_and_clean(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\", ['text'])\n",
    "    df_val = pd.read_pickle(\"../input/jigsaw-202201/df_val_0206.pkl\")\n",
    "    df_train = pd.read_pickle(\"../input/jigsaw-202201/df_train_0206.pkl\")\n",
    "    df_rud = pd.read_pickle(\"../input/jigsaw-202201/df_rud_0206.pkl\")\n",
    "    df_mulwi = pd.read_pickle(\"../input/jigsaw-202201/df_mulwi_0206.pkl\")\n",
    "    df_uni = pd.read_pickle(\"../input/jigsaw-202201/df_uni_0206.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b2adae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:54.708612Z",
     "iopub.status.busy": "2022-02-06T14:18:54.707488Z",
     "iopub.status.idle": "2022-02-06T14:18:54.737687Z",
     "shell.execute_reply": "2022-02-06T14:18:54.737199Z",
     "shell.execute_reply.started": "2022-02-06T13:00:33.181744Z"
    },
    "papermill": {
     "duration": 0.065039,
     "end_time": "2022-02-06T14:18:54.737823",
     "exception": false,
     "start_time": "2022-02-06T14:18:54.672784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16030,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ①classification\n",
    "dic_omomi = {'obscene': 0.16, 'toxic': 0.32, 'insult': 0.64, 'threat': 1.5, 'identity_hate': 1.5, 'severe_toxic': 2, 'identity_attack': 1.5, 'severe_toxicity': 2}\n",
    "df_train = get_omomi(df_train, dic_omomi, 'toxic_sum')\n",
    "sr_all_text1 = pd.concat([df_train[df_train['toxic_sum'] > 0]['comment_text']]).drop_duplicates()\n",
    "sr_all_text1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bf5dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:54.798068Z",
     "iopub.status.busy": "2022-02-06T14:18:54.797075Z",
     "iopub.status.idle": "2022-02-06T14:18:54.804186Z",
     "shell.execute_reply": "2022-02-06T14:18:54.804697Z",
     "shell.execute_reply.started": "2022-02-06T13:00:33.221938Z"
    },
    "papermill": {
     "duration": 0.04081,
     "end_time": "2022-02-06T14:18:54.804866",
     "exception": false,
     "start_time": "2022-02-06T14:18:54.764056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2312,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ②ruddit\n",
    "df_rud['offensiveness_score'].clip(lower=0, inplace=True)\n",
    "sr_all_text2 = df_rud[df_rud['offensiveness_score'] > 0]['txt'].drop_duplicates()\n",
    "sr_all_text2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9e4522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:54.863376Z",
     "iopub.status.busy": "2022-02-06T14:18:54.862441Z",
     "iopub.status.idle": "2022-02-06T14:18:54.894698Z",
     "shell.execute_reply": "2022-02-06T14:18:54.894192Z",
     "shell.execute_reply.started": "2022-02-06T13:00:33.238022Z"
    },
    "papermill": {
     "duration": 0.063553,
     "end_time": "2022-02-06T14:18:54.894834",
     "exception": false,
     "start_time": "2022-02-06T14:18:54.831281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22176,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ③multiのwiki\n",
    "df_mulwi = get_omomi(df_mulwi, dic_omomi, 'toxic_sum')\n",
    "sr_all_text3 = df_mulwi[df_mulwi['toxic_sum'] > 0]['comment_text'].drop_duplicates()\n",
    "sr_all_text3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c7f777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:54.953953Z",
     "iopub.status.busy": "2022-02-06T14:18:54.953347Z",
     "iopub.status.idle": "2022-02-06T14:18:54.956426Z",
     "shell.execute_reply": "2022-02-06T14:18:54.955781Z",
     "shell.execute_reply.started": "2022-02-06T13:00:33.283130Z"
    },
    "papermill": {
     "duration": 0.034851,
     "end_time": "2022-02-06T14:18:54.956569",
     "exception": false,
     "start_time": "2022-02-06T14:18:54.921718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ④unintended - 1\n",
    "list_normal = ['asian', 'atheist', 'bisexual',\n",
    "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
    "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
    "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
    "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
    "       'other_sexual_orientation', 'physical_disability',\n",
    "       'psychiatric_or_mental_illness', 'transgender', 'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6cfe33e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:55.018582Z",
     "iopub.status.busy": "2022-02-06T14:18:55.017136Z",
     "iopub.status.idle": "2022-02-06T14:18:58.952866Z",
     "shell.execute_reply": "2022-02-06T14:18:58.952388Z",
     "shell.execute_reply.started": "2022-02-06T13:00:33.292942Z"
    },
    "papermill": {
     "duration": 3.969255,
     "end_time": "2022-02-06T14:18:58.953014",
     "exception": false,
     "start_time": "2022-02-06T14:18:54.983759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49144,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ④unintended - 2\n",
    "df_uni = get_omomi(df_uni, dic_omomi, 'toxic_sum')\n",
    "df_uni['normal_sum'] = df_uni[list_normal].sum(axis=1)\n",
    "df_uni = df_uni[df_uni['normal_sum'] == 0]\n",
    "df_uni_toxic = df_uni.nlargest(50000, 'toxic_sum', keep=\"all\") # toxicな上位50000件だけを取り出す\n",
    "df_uni_non_toxic = df_uni[df_uni['toxic_sum'] == 0]\n",
    "df_uni = pd.concat([df_uni_toxic, df_uni_non_toxic]).reset_index(drop=True)\n",
    "sr_all_text4 = df_uni[df_uni['toxic_sum'] > 0]['comment_text'].drop_duplicates()\n",
    "sr_all_text4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afbb54",
   "metadata": {
    "papermill": {
     "duration": 0.027741,
     "end_time": "2022-02-06T14:18:59.008710",
     "exception": false,
     "start_time": "2022-02-06T14:18:58.980969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 前処理STEP2：TF-IDFベクトライザ及びRidge推論器を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d404db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:59.069837Z",
     "iopub.status.busy": "2022-02-06T14:18:59.069138Z",
     "iopub.status.idle": "2022-02-06T14:18:59.071689Z",
     "shell.execute_reply": "2022-02-06T14:18:59.071189Z",
     "shell.execute_reply.started": "2022-02-06T13:00:37.930906Z"
    },
    "papermill": {
     "duration": 0.035625,
     "end_time": "2022-02-06T14:18:59.071817",
     "exception": false,
     "start_time": "2022-02-06T14:18:59.036192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PREPROC_STEP2:\n",
    "    # ①classification\n",
    "    print(f\"df_train:{df_train.shape}\")\n",
    "    df = df_train[['comment_text', 'toxic_sum']].rename(columns={'comment_text': 'text', 'toxic_sum': 'y'})\n",
    "    df_pseudo = pd.DataFrame()\n",
    "    vec1, list_model1 = get_vec_model(sr_all_text1, df, df_pseudo, [i + 217 for i in range(10)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95195919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:59.132745Z",
     "iopub.status.busy": "2022-02-06T14:18:59.129861Z",
     "iopub.status.idle": "2022-02-06T14:18:59.134651Z",
     "shell.execute_reply": "2022-02-06T14:18:59.135111Z",
     "shell.execute_reply.started": "2022-02-06T13:00:37.945820Z"
    },
    "papermill": {
     "duration": 0.035546,
     "end_time": "2022-02-06T14:18:59.135300",
     "exception": false,
     "start_time": "2022-02-06T14:18:59.099754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PREPROC_STEP2:\n",
    "    # ②ruddit\n",
    "    print(f\"df_rud:{df_rud.shape}\")\n",
    "    df = df_rud[['txt', 'offensiveness_score']].rename(columns={'txt': 'text', 'offensiveness_score': 'y'})\n",
    "    df_pseudo = pd.DataFrame()\n",
    "    vec2, list_model2 = get_vec_model(sr_all_text2, df, df_pseudo, [0.5, 1.0, 1.5, 2.0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60e28e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:59.195275Z",
     "iopub.status.busy": "2022-02-06T14:18:59.194565Z",
     "iopub.status.idle": "2022-02-06T14:18:59.198867Z",
     "shell.execute_reply": "2022-02-06T14:18:59.199336Z",
     "shell.execute_reply.started": "2022-02-06T13:00:37.955926Z"
    },
    "papermill": {
     "duration": 0.036378,
     "end_time": "2022-02-06T14:18:59.199534",
     "exception": false,
     "start_time": "2022-02-06T14:18:59.163156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PREPROC_STEP2:\n",
    "    # ③multiのwiki\n",
    "    print(f\"df_mulwi:{df_mulwi.shape}\")\n",
    "    df = df_mulwi[['comment_text', 'toxic_sum']].rename(columns={'comment_text': 'text', 'toxic_sum': 'y'})\n",
    "    df_pseudo = pd.DataFrame()\n",
    "    vec3, list_model3 = get_vec_model(sr_all_text3, df, df_pseudo, [i + 217 for i in range(10)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b035c5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:59.258429Z",
     "iopub.status.busy": "2022-02-06T14:18:59.257696Z",
     "iopub.status.idle": "2022-02-06T14:18:59.262302Z",
     "shell.execute_reply": "2022-02-06T14:18:59.262809Z",
     "shell.execute_reply.started": "2022-02-06T13:00:37.971690Z"
    },
    "papermill": {
     "duration": 0.036049,
     "end_time": "2022-02-06T14:18:59.262987",
     "exception": false,
     "start_time": "2022-02-06T14:18:59.226938",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PREPROC_STEP2:\n",
    "    # ④unintended\n",
    "    print(f\"df_uni:{df_uni.shape}\")\n",
    "    df = df_uni[['comment_text', 'toxic_sum']].rename(columns={'comment_text': 'text', 'toxic_sum': 'y'})\n",
    "    df_pseudo = pd.DataFrame()\n",
    "    vec4, list_model4 = get_vec_model(sr_all_text4, df, df_pseudo, [i + 217 for i in range(10)], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff2dd1",
   "metadata": {
    "papermill": {
     "duration": 0.028471,
     "end_time": "2022-02-06T14:18:59.318662",
     "exception": false,
     "start_time": "2022-02-06T14:18:59.290191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 前処理STEP2：生成したTF-IDFベクトライザ及びRidge推論器をpickle化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d78e461d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:18:59.380361Z",
     "iopub.status.busy": "2022-02-06T14:18:59.379665Z",
     "iopub.status.idle": "2022-02-06T14:19:01.286781Z",
     "shell.execute_reply": "2022-02-06T14:19:01.287252Z",
     "shell.execute_reply.started": "2022-02-06T13:00:37.992458Z"
    },
    "papermill": {
     "duration": 1.938566,
     "end_time": "2022-02-06T14:19:01.287452",
     "exception": false,
     "start_time": "2022-02-06T14:18:59.348886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PREPROC_STEP2:\n",
    "    # 生成したベクトライザとridge推論器を保存する\n",
    "    list_vec = [vec1, vec2, vec3, vec4]\n",
    "    with open(\"list_vec_0206_x5_seed10.pkl\", mode='wb') as f:\n",
    "        pickle.dump(list_vec, f)\n",
    "    list_list_model = [list_model1, list_model2, list_model3, list_model4]\n",
    "    with open(\"list_list_model_0206_x5_seed10.pkl\", mode='wb') as f:\n",
    "        pickle.dump(list_list_model, f)\n",
    "else:\n",
    "    # あらかじめ作っておいたベクトライザとridge推論器をdatasetから読み込む\n",
    "    with open(\"../input/jigsaw-202201/list_vec_0206_x5_seed10.pkl\", mode='rb') as f:\n",
    "        vec1, vec2, vec3, vec4 = pickle.load(f)\n",
    "    with open(\"../input/jigsaw-202201/list_list_model_0206_x5_seed10.pkl\", mode='rb') as f:\n",
    "        list_model1, list_model2, list_model3, list_model4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd858a5",
   "metadata": {
    "papermill": {
     "duration": 0.027129,
     "end_time": "2022-02-06T14:19:01.342179",
     "exception": false,
     "start_time": "2022-02-06T14:19:01.315050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ここから本処理：pseudoラベリング用に事前推論する（m1234_pseudo_score）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "769f230f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:19:01.401448Z",
     "iopub.status.busy": "2022-02-06T14:19:01.400496Z",
     "iopub.status.idle": "2022-02-06T14:19:21.310475Z",
     "shell.execute_reply": "2022-02-06T14:19:21.309786Z",
     "shell.execute_reply.started": "2022-02-06T13:00:38.435780Z"
    },
    "papermill": {
     "duration": 19.940815,
     "end_time": "2022-02-06T14:19:21.310623",
     "exception": false,
     "start_time": "2022-02-06T14:19:01.369808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TEST_INFERENCE:\n",
    "    df_test['m1score'] = get_test(vec1, list_model1, df_test)\n",
    "    df_test['m2score'] = get_test(vec2, list_model2, df_test)\n",
    "    df_test['m3score'] = get_test(vec3, list_model3, df_test)\n",
    "    df_test['m4score'] = get_test(vec4, list_model4, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c69ca39b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:19:21.370755Z",
     "iopub.status.busy": "2022-02-06T14:19:21.370075Z",
     "iopub.status.idle": "2022-02-06T14:19:21.382896Z",
     "shell.execute_reply": "2022-02-06T14:19:21.383342Z",
     "shell.execute_reply.started": "2022-02-06T13:01:10.647283Z"
    },
    "papermill": {
     "duration": 0.044005,
     "end_time": "2022-02-06T14:19:21.383554",
     "exception": false,
     "start_time": "2022-02-06T14:19:21.339549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      comment_id                                               text   m1score  \\\n",
      "0         114890  gjalexei asked whether anti editorializing pol... -0.457048   \n",
      "1         732895               looks like abuser please look thanks  0.312879   \n",
      "2        1139051  confess complete apparently blissful ignorance...  0.022502   \n",
      "3        1434512  freud ideas certainly much discussed today wou... -0.308689   \n",
      "4        2084821  laundry list stupid allegations scooped god kn...  0.046197   \n",
      "...          ...                                                ...       ...   \n",
      "7532   504235362                            go away annoying vandal  0.152712   \n",
      "7533   504235566                                        user vandal -0.082836   \n",
      "7534   504308177  sorry sound like pain one following tad stalki... -0.530685   \n",
      "7535   504570375     well pretty fuck ing irrelevant unblocked aint  0.504162   \n",
      "7536   504598250  team name great britain northern ireland blind...  0.059553   \n",
      "\n",
      "       m2score   m3score   m4score  m1234_pseudo_score  \n",
      "0     0.188498 -0.176815 -0.286551           -0.182979  \n",
      "1    -0.226348  0.249732  0.368422            0.176171  \n",
      "2     0.150208  0.035300  0.070720            0.069683  \n",
      "3     0.101604 -0.375382 -0.464779           -0.261812  \n",
      "4     0.317173  0.165799  0.118146            0.161829  \n",
      "...        ...       ...       ...                 ...  \n",
      "7532 -0.421490  0.134088 -0.010699           -0.036347  \n",
      "7533 -0.769679 -0.026129 -0.314493           -0.298284  \n",
      "7534  0.124866 -0.555368 -0.369778           -0.332741  \n",
      "7535  1.647653  0.603563  0.718359            0.868434  \n",
      "7536 -0.050119 -0.089910 -0.006501           -0.021744  \n",
      "\n",
      "[7537 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# pseudo labeling（正規化しているのでスケールを気にせず単純平均でよい）\n",
    "df_pseudo = df_test.copy()\n",
    "df_pseudo['m1234_pseudo_score'] = df_pseudo[['m1score', 'm2score', 'm3score', 'm4score']].mean(axis=1)\n",
    "print(df_pseudo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a354503",
   "metadata": {
    "papermill": {
     "duration": 0.0272,
     "end_time": "2022-02-06T14:19:21.438535",
     "exception": false,
     "start_time": "2022-02-06T14:19:21.411335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 再び、TF-IDFベクトライザ及びRidge推論器を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f50b7d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:19:21.497097Z",
     "iopub.status.busy": "2022-02-06T14:19:21.496481Z",
     "iopub.status.idle": "2022-02-06T14:29:43.713587Z",
     "shell.execute_reply": "2022-02-06T14:29:43.714617Z",
     "shell.execute_reply.started": "2022-02-06T13:01:10.668022Z"
    },
    "papermill": {
     "duration": 622.248927,
     "end_time": "2022-02-06T14:29:43.715280",
     "exception": false,
     "start_time": "2022-02-06T14:19:21.466353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train:(159571, 9)\n",
      "(18039,)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(106420, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(106420, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(106420, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(106420, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(106420, 2)\n"
     ]
    }
   ],
   "source": [
    "# ①classification\n",
    "print(f\"df_train:{df_train.shape}\")\n",
    "df = df_train[['comment_text', 'toxic_sum']].rename(columns={'comment_text': 'text', 'toxic_sum': 'y'})\n",
    "df_pseudo_add = df_pseudo.rename(columns={'m1234_pseudo_score': 'y'})\n",
    "sr_all_text11 = pd.concat([df[df['y'] > 0]['text'], df_pseudo_add[df_pseudo_add['y'] > 0]['text']]).drop_duplicates()\n",
    "print(sr_all_text11.shape)\n",
    "vec11, list_model11 = get_vec_model(sr_all_text11, df, df_pseudo_add, [i + 217 for i in range(5)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b24a18d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:29:43.837436Z",
     "iopub.status.busy": "2022-02-06T14:29:43.826709Z",
     "iopub.status.idle": "2022-02-06T14:30:03.479174Z",
     "shell.execute_reply": "2022-02-06T14:30:03.480110Z",
     "shell.execute_reply.started": "2022-02-06T13:16:38.636764Z"
    },
    "papermill": {
     "duration": 19.705446,
     "end_time": "2022-02-06T14:30:03.480428",
     "exception": false,
     "start_time": "2022-02-06T14:29:43.774982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rud:(5838, 5)\n",
      "(7678,)\n",
      "(13375, 7)\n",
      "(13375, 7)\n",
      "(13375, 7)\n",
      "(13375, 7)\n"
     ]
    }
   ],
   "source": [
    "# ②ruddit\n",
    "print(f\"df_rud:{df_rud.shape}\")\n",
    "df = df_rud[['txt', 'offensiveness_score']].rename(columns={'txt': 'text', 'offensiveness_score': 'y'})\n",
    "df_pseudo_add = df_pseudo.rename(columns={'m1234_pseudo_score': 'y'})\n",
    "sr_all_text12 = pd.concat([df[df['y'] > 0]['text'], df_pseudo_add[df_pseudo_add['y'] > 0]['text']]).drop_duplicates()\n",
    "print(sr_all_text12.shape)\n",
    "vec12, list_model12 = get_vec_model(sr_all_text12, df, df_pseudo_add, [0.5, 1.0, 1.5, 2.0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec79bb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:30:03.666132Z",
     "iopub.status.busy": "2022-02-06T14:30:03.662351Z",
     "iopub.status.idle": "2022-02-06T14:44:23.024881Z",
     "shell.execute_reply": "2022-02-06T14:44:23.025809Z",
     "shell.execute_reply.started": "2022-02-06T13:17:05.825595Z"
    },
    "papermill": {
     "duration": 859.484965,
     "end_time": "2022-02-06T14:44:23.026133",
     "exception": false,
     "start_time": "2022-02-06T14:30:03.541168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mulwi:(223549, 9)\n",
      "(24185,)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(143393, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(143393, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(143393, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(143393, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(143393, 2)\n"
     ]
    }
   ],
   "source": [
    "# ③multiのwiki\n",
    "print(f\"df_mulwi:{df_mulwi.shape}\")\n",
    "df = df_mulwi[['comment_text', 'toxic_sum']].rename(columns={'comment_text': 'text', 'toxic_sum': 'y'})\n",
    "df_pseudo_add = df_pseudo.rename(columns={'m1234_pseudo_score': 'y'})\n",
    "sr_all_text13 = pd.concat([df[df['y'] > 0]['text'], df_pseudo_add[df_pseudo_add['y'] > 0]['text']]).drop_duplicates()\n",
    "print(sr_all_text13.shape)\n",
    "vec13, list_model13 = get_vec_model(sr_all_text13, df, df_pseudo_add, [i + 217 for i in range(5)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5217f07e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:44:23.144737Z",
     "iopub.status.busy": "2022-02-06T14:44:23.144038Z",
     "iopub.status.idle": "2022-02-06T14:58:15.779172Z",
     "shell.execute_reply": "2022-02-06T14:58:15.777910Z",
     "shell.execute_reply.started": "2022-02-06T13:37:45.984813Z"
    },
    "papermill": {
     "duration": 832.688686,
     "end_time": "2022-02-06T14:58:15.779520",
     "exception": false,
     "start_time": "2022-02-06T14:44:23.090834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_uni:(1207439, 47)\n",
      "(54506,)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(322530, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(322530, 2)\n",
      "アンダーサンプリング有害コメントの5倍\n",
      "(322530, 2)\n"
     ]
    }
   ],
   "source": [
    "# ④unintended\n",
    "print(f\"df_uni:{df_uni.shape}\")\n",
    "df = df_uni[['comment_text', 'toxic_sum']].rename(columns={'comment_text': 'text', 'toxic_sum': 'y'})\n",
    "df_pseudo_add = df_pseudo.rename(columns={'m1234_pseudo_score': 'y'})\n",
    "sr_all_text14 = pd.concat([df[df['y'] > 0]['text'], df_pseudo_add[df_pseudo_add['y'] > 0]['text']]).drop_duplicates()\n",
    "print(sr_all_text14.shape)\n",
    "vec14, list_model14 = get_vec_model(sr_all_text14, df, df_pseudo_add, [i + 217 for i in range(3)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1f6c627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:58:15.935943Z",
     "iopub.status.busy": "2022-02-06T14:58:15.899532Z",
     "iopub.status.idle": "2022-02-06T14:58:37.036842Z",
     "shell.execute_reply": "2022-02-06T14:58:37.036164Z",
     "shell.execute_reply.started": "2022-02-06T13:57:50.929766Z"
    },
    "papermill": {
     "duration": 21.193868,
     "end_time": "2022-02-06T14:58:37.036988",
     "exception": false,
     "start_time": "2022-02-06T14:58:15.843120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TEST_INFERENCE:\n",
    "    df_test['m11score'] = get_test(vec11, list_model11, df_test)\n",
    "    df_test['m12score'] = get_test(vec12, list_model12, df_test)\n",
    "    df_test['m13score'] = get_test(vec13, list_model13, df_test)\n",
    "    df_test['m14score'] = get_test(vec14, list_model14, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e7d6d",
   "metadata": {
    "papermill": {
     "duration": 0.03322,
     "end_time": "2022-02-06T14:58:37.102974",
     "exception": false,
     "start_time": "2022-02-06T14:58:37.069754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# バリデーションチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88c0692f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:58:37.171493Z",
     "iopub.status.busy": "2022-02-06T14:58:37.170885Z",
     "iopub.status.idle": "2022-02-06T14:58:37.177804Z",
     "shell.execute_reply": "2022-02-06T14:58:37.178274Z",
     "shell.execute_reply.started": "2022-02-06T13:58:22.396114Z"
    },
    "papermill": {
     "duration": 0.042867,
     "end_time": "2022-02-06T14:58:37.178437",
     "exception": false,
     "start_time": "2022-02-06T14:58:37.135570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_check(vec, list_model, df, cname1, cname2):\n",
    "    X_less_toxic = vec.transform(df['less_toxic'])\n",
    "    X_more_toxic = vec.transform(df['more_toxic'])\n",
    "    df[cname1] = 0\n",
    "    df[cname2] = 0\n",
    "    for model in list_model:    \n",
    "        df['less'] = model.predict(X_less_toxic)\n",
    "        df['more'] = model.predict(X_more_toxic)\n",
    "        df_lessmore = pd.DataFrame(scipy.stats.zscore(df[['less', 'more']].to_numpy(), axis=None), index=df.index, columns=['less_zscore', 'more_zscore'])\n",
    "        df[cname1] += df_lessmore['less_zscore']\n",
    "        df[cname2] += df_lessmore['more_zscore']\n",
    "    print(cname1, cname2)\n",
    "\n",
    "    print((df[cname1] < df[cname2]).mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8603b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:58:37.247526Z",
     "iopub.status.busy": "2022-02-06T14:58:37.246915Z",
     "iopub.status.idle": "2022-02-06T14:59:54.543025Z",
     "shell.execute_reply": "2022-02-06T14:59:54.543524Z",
     "shell.execute_reply.started": "2022-02-06T13:58:22.410535Z"
    },
    "papermill": {
     "duration": 77.332042,
     "end_time": "2022-02-06T14:59:54.543701",
     "exception": false,
     "start_time": "2022-02-06T14:58:37.211659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1p1 m1p2\n",
      "0.6838381825428458\n",
      "m11p1 m11p2\n",
      "0.6873588415039192\n"
     ]
    }
   ],
   "source": [
    "# list_model_tmp = [list_model1[0]]\n",
    "if VAL_CHECK:\n",
    "    df_val = val_check(vec1, list_model1, df_val, 'm1p1', 'm1p2')\n",
    "    df_val = val_check(vec11, list_model11, df_val, 'm11p1', 'm11p2')\n",
    "    # ノーマル0.670\n",
    "    # 有害データのみ0.667\n",
    "    # 1～0.8、(2, 6)にして0.669\n",
    "    # v16 0.6688\n",
    "    # v17 0.6700\n",
    "    # v17-2 0.6702\n",
    "    # v19 cleanを適用すると精度が下がる0.663\n",
    "    # v19-2 HTMLcleanを適用すると精度上がる0.665\n",
    "    # v21 空白除去すると精度高い0.671\n",
    "    # v21-2 記号除去すると精度高い0.674\n",
    "    # v21-3 char_wbに戻すと0.669\n",
    "    # v21-3 小文字にしたら0.671まで改善\n",
    "    # v27 単体で0.6867\n",
    "    # v31 0.6867\n",
    "    # v35 0.6763\n",
    "    # v35-2 0.677\n",
    "    # v35-2 0.677\n",
    "    # v35-2 0.678\n",
    "    # v35-2 0.678\n",
    "    # v35-3 0.678\n",
    "    # v37 0.678\n",
    "    # v38 0.683\n",
    "    # v39 0.683\n",
    "    # v41 0.6839\n",
    "    # v47 0.6847\n",
    "    # v48 0.6861\n",
    "    # v48-2 0.6870\n",
    "    # v51 0.6773(3倍) 0.6713(pseudo) バグあり\n",
    "    # v51-2 0.6773(3倍) 0.6707(psuedo) バグあり\n",
    "    # v52 0.6833(5倍) 0.6795(pseudo) バグあり\n",
    "    # v53 0.6841(5倍) 0.6843(pseudo)\n",
    "    # v58 0.6818(5倍) 0.6776(pseudo > 0のみ)\n",
    "    # v59 0.6801(5×3倍) 0.6802(pseudo5×3倍)\n",
    "    # v61 0.6838(x5 seed x10) 0.6794(pseudo x5 seed x5) バグあり\n",
    "    # v61 0.6838(x5 seed x10) 0.6873(pseudo x5 seed x5) バグ修正後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffaf6232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:59:54.613788Z",
     "iopub.status.busy": "2022-02-06T14:59:54.612813Z",
     "iopub.status.idle": "2022-02-06T15:01:09.753085Z",
     "shell.execute_reply": "2022-02-06T15:01:09.753636Z",
     "shell.execute_reply.started": "2022-02-06T14:00:24.986632Z"
    },
    "papermill": {
     "duration": 75.177253,
     "end_time": "2022-02-06T15:01:09.753824",
     "exception": false,
     "start_time": "2022-02-06T14:59:54.576571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2p1 m2p2\n",
      "0.6532483060980471\n",
      "m12p1 m12p2\n",
      "0.6825760595190647\n"
     ]
    }
   ],
   "source": [
    "if VAL_CHECK:\n",
    "    df_val = val_check(vec2, list_model2, df_val, 'm2p1', 'm2p2')\n",
    "    df_val = val_check(vec12, list_model12, df_val, 'm12p1', 'm12p2')\n",
    "    # 0.632\n",
    "    # 1～0.8、(2, 6)にして0.647→LB悪化したため元に戻す\n",
    "    # v16 0.6320\n",
    "    # v17 0.6350\n",
    "    # v17-2 0.6362\n",
    "    # v19 cleanを適用すると精度が下がる0.6324\n",
    "    # v19-2 HTMLcleanを適用すると精度上がる0.6335\n",
    "    # v21 空白除去すると精度悪い0.627\n",
    "    # v21-2 記号除去すると精度高い0.636\n",
    "    # v21-3 char_wbに戻すと0.638\n",
    "    # v21-3 小文字にしたら0.636に悪化\n",
    "    # v27 単体で0.6199\n",
    "    # v35 0.638\n",
    "    # v35-2 0.638\n",
    "    # v35-2 0.641\n",
    "    # v35-2 0.643\n",
    "    # v35-2 0.641\n",
    "    # v35-3 0.641\n",
    "    # v37 0.649\n",
    "    # v38 0.651\n",
    "    # v39 0.650\n",
    "    # v41 0.6514\n",
    "    # v48 0.6538\n",
    "    # v51 0.6536 0.6362(pseudo) バグあり\n",
    "    # v51-2 0.6536 0.6536(psuedo) バグあり\n",
    "    # v52 0.6532 0.6620(pseudo) バグあり\n",
    "    # v53 0.6532 0.6867(pseudo)\n",
    "    # v58 0.6504 0.6776(pseudo > 0のみ)\n",
    "    # v59 0.6504 0.6851(pseudo)\n",
    "    # v61 0.6532 0.6852(pseudo) バグあり\n",
    "    # v61 0.6532 0.6825(pseudo) バグ修正後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef0a322a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T15:01:09.892484Z",
     "iopub.status.busy": "2022-02-06T15:01:09.871660Z",
     "iopub.status.idle": "2022-02-06T15:02:27.297351Z",
     "shell.execute_reply": "2022-02-06T15:02:27.297837Z",
     "shell.execute_reply.started": "2022-02-06T14:02:21.466269Z"
    },
    "papermill": {
     "duration": 77.50769,
     "end_time": "2022-02-06T15:02:27.298015",
     "exception": false,
     "start_time": "2022-02-06T15:01:09.790325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m3p1 m3p2\n",
      "0.6824432044639298\n",
      "m13p1 m13p2\n",
      "0.6847681679287897\n"
     ]
    }
   ],
   "source": [
    "if VAL_CHECK:\n",
    "    df_val = val_check(vec3, list_model3, df_val, 'm3p1', 'm3p2')\n",
    "    df_val = val_check(vec13, list_model13, df_val, 'm13p1', 'm13p2')\n",
    "    # v35 0.676\n",
    "    # v35-2 0.676\n",
    "    # v35-2 0.678\n",
    "    # v35-2 0.678\n",
    "    # v35-2 0.679\n",
    "    # v35-3 0.679\n",
    "    # v37 0.679\n",
    "    # v38 0.684\n",
    "    # v39 0.684\n",
    "    # v41 0.6844\n",
    "    # v48 0.6861\n",
    "    # v48-2 0.6867\n",
    "    # v51 0.6793(3倍) 0.6794(pseudo) バグあり\n",
    "    # v51-2 0.6793(3倍) 0.6782(pseudo) バグあり\n",
    "    # v52 0.6794(3倍) 0.6807(pseudo) バグあり\n",
    "    # v53 0.6822(5倍) 0.6826(pseudo)\n",
    "    # v58 0.6809(5倍) 0.6751(pseudo > 0のみ)\n",
    "    # v59 0.6787(5×3倍) (pseudo5×3倍)\n",
    "    # v61 0.6824(x5 seed x10) 0.6760(pseudo x5 seed x5) バグあり\n",
    "    # v61 0.6824(x5 seed x10) 0.6847(pseudo x5 seed x5) バグ修正後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "175931b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T15:02:27.372794Z",
     "iopub.status.busy": "2022-02-06T15:02:27.371841Z",
     "iopub.status.idle": "2022-02-06T15:03:44.703566Z",
     "shell.execute_reply": "2022-02-06T15:03:44.704032Z",
     "shell.execute_reply.started": "2022-02-06T14:04:19.538370Z"
    },
    "papermill": {
     "duration": 77.371893,
     "end_time": "2022-02-06T15:03:44.704209",
     "exception": false,
     "start_time": "2022-02-06T15:02:27.332316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m4p1 m4p2\n",
      "0.6712169523050352\n",
      "m14p1 m14p2\n",
      "0.6760661618174572\n"
     ]
    }
   ],
   "source": [
    "if VAL_CHECK:\n",
    "    df_val = val_check(vec4, list_model4, df_val, 'm4p1', 'm4p2')\n",
    "    df_val = val_check(vec14, list_model14, df_val, 'm14p1', 'm14p2')\n",
    "    # v51 0.6795(2倍) 0.6764(pseudo) バグあり\n",
    "    # v53 0.6710(5倍) 0.6829(pseudo)\n",
    "    # v58 0.6737(5倍) 0.6653(pseudo > 0のみ)\n",
    "    # v59 0.6709(3×3倍) 0.6807(pseudo3×3倍)\n",
    "    # v61 0.6712(x5 seed x10) 0.6763(pseudo x5 seed x5) バグあり\n",
    "    # v61 0.6712(x5 seed x10) 0.6760(pseudo x5 seed x5) バグ修正後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e188f4be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T15:03:44.783910Z",
     "iopub.status.busy": "2022-02-06T15:03:44.782823Z",
     "iopub.status.idle": "2022-02-06T15:03:44.799153Z",
     "shell.execute_reply": "2022-02-06T15:03:44.799693Z",
     "shell.execute_reply.started": "2022-02-06T14:06:19.396317Z"
    },
    "papermill": {
     "duration": 0.060908,
     "end_time": "2022-02-06T15:03:44.799854",
     "exception": false,
     "start_time": "2022-02-06T15:03:44.738946",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1\n",
      "m2\n",
      "m3\n",
      "m4\n",
      "m11\n",
      "m12\n",
      "m13\n",
      "m14\n",
      "0.6912780656303973\n"
     ]
    }
   ],
   "source": [
    "# 2/6 v62 submit時はテストデータが増えるので、pseudoラベリングの重みを減らした方がよさそう→pseudo50%\n",
    "# 2/6 v61バグ修正後 1:5が一番CV高いので、1:5にする。（pseudo83%）\n",
    "# 2/5 v58田村メモ m11～m14の重みを高めすぎるとCVが悪化するので、元モデルと4:1でマージする。\n",
    "dic_omomi = {\"m1\": 1, \"m2\": 1, \"m3\": 1, \"m4\": 1, \"m11\": 1, \"m12\": 1, \"m13\": 1, \"m14\": 1}\n",
    "if VAL_CHECK:\n",
    "    df_val['p1'] = 0\n",
    "    df_val['p2'] = 0\n",
    "    for k, v in dic_omomi.items():\n",
    "        print(k)\n",
    "        df_val['p1'] += df_val[f'{k}p1'] * v\n",
    "        df_val['p2'] += df_val[f'{k}p2'] * v\n",
    "    print((df_val['p1'] < df_val['p2']).mean())\n",
    "    # Validation Accuracy\n",
    "    # 0.678\n",
    "    # 0.6786\n",
    "    # 1+2+3+5+7＝0.692\n",
    "    # v16 2021/1/19 0.6892\n",
    "    # v17 0.6865\n",
    "    # v17-2 0.6863\n",
    "    # v19 0.6882に上がった\n",
    "    # 2+3+4+5+6＝0.690\n",
    "    # v19-2 0.6910に上がった\n",
    "    # v21 空白除去すると精度やや下がる 0.690\n",
    "    # v22 記号を除去したら上がった0.6917\n",
    "    # v35 0.682\n",
    "    # v35-2 0.682\n",
    "    # 0.683\n",
    "    # v35-2 0.685\n",
    "    # v35-3 0.685\n",
    "    # v37 0.6916\n",
    "    # v41 0.6919\n",
    "    # v46 0.6956\n",
    "    # v48 0.6935\n",
    "    # v51 0.6822\n",
    "    # v53 0.6925 10-15-5-35\n",
    "    # v58 0.6902 5倍だと元モデルの精度が悪い\n",
    "    # v59 0.6907 3倍だと1つ1つの精度は悪いがアンサンブルすると5倍より良くなる\n",
    "    # v59 0.6899(9:1) 0.6896(4:1) 0.6883(1:1)\n",
    "    # v61 0.6910(m1～4のみ)\n",
    "    # v61 0.6921(重み1:5) バグ修正後\n",
    "    # v61 0.6912(重み1:1) バグ修正後"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a7035",
   "metadata": {
    "papermill": {
     "duration": 0.034868,
     "end_time": "2022-02-06T15:03:44.869188",
     "exception": false,
     "start_time": "2022-02-06T15:03:44.834320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# バリデーション14251件のスコアをCSV化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c9ef75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T15:03:44.942947Z",
     "iopub.status.busy": "2022-02-06T15:03:44.941974Z",
     "iopub.status.idle": "2022-02-06T15:03:45.859460Z",
     "shell.execute_reply": "2022-02-06T15:03:45.858908Z",
     "shell.execute_reply.started": "2022-02-06T14:06:19.431756Z"
    },
    "papermill": {
     "duration": 0.955541,
     "end_time": "2022-02-06T15:03:45.859634",
     "exception": false,
     "start_time": "2022-02-06T15:03:44.904093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text       score\n",
      "0                This article sucks \\n\\nwoo woo wooooooo    2.001099\n",
      "1      \"And yes, people should recognize that but the...  -36.039877\n",
      "2       Western Media?\\n\\nYup, because every crime in...  -24.241773\n",
      "3      And you removed it! You numbskull! I don't car...  -12.329818\n",
      "4       smelly vagina \\n\\nBluerasberry why don't you ...   14.996967\n",
      "...                                                  ...         ...\n",
      "14246   Hey you fucking jew \\nwhy the fuck did you ge...  173.233618\n",
      "14247   i hate your guts \\n\\ni hope you feel good abo...    7.305034\n",
      "14248  \":::fuck you animal! remember this shit yourse...   69.134670\n",
      "14249      Some Say She is a little mothyer fukin bitchy   32.490363\n",
      "14250                       Piss off you slant eyed-gook   13.360951\n",
      "\n",
      "[14251 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "if VAL_CHECK:\n",
    "    # df_val.to_csv(\"df_val.csv\", index=False)\n",
    "    df_val_moto = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "    df_val_concat1 = pd.concat([df_val_moto['less_toxic'], df_val['p1']], axis=1).rename(columns={'less_toxic' : 'text', 'p1': 'score'})\n",
    "    df_val_concat2 = pd.concat([df_val_moto['more_toxic'], df_val['p2']], axis=1).rename(columns={'more_toxic' : 'text', 'p2': 'score'})\n",
    "    df_val_concat = pd.concat([df_val_concat1, df_val_concat2]).reset_index(drop=True)\n",
    "    df_val_concat = df_val_concat.drop_duplicates().reset_index(drop=True)\n",
    "    df_val_concat.to_csv(\"df_val14251_tamura0206v62.csv\", index=False)\n",
    "    print(df_val_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f97ce2",
   "metadata": {
    "papermill": {
     "duration": 0.034922,
     "end_time": "2022-02-06T15:03:45.931106",
     "exception": false,
     "start_time": "2022-02-06T15:03:45.896184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# テストデータのスコア計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d64e8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T15:03:46.012081Z",
     "iopub.status.busy": "2022-02-06T15:03:46.011269Z",
     "iopub.status.idle": "2022-02-06T15:03:46.057679Z",
     "shell.execute_reply": "2022-02-06T15:03:46.058132Z",
     "shell.execute_reply.started": "2022-02-06T14:06:20.303910Z"
    },
    "papermill": {
     "duration": 0.091279,
     "end_time": "2022-02-06T15:03:46.058326",
     "exception": false,
     "start_time": "2022-02-06T15:03:45.967047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1\n",
      "m2\n",
      "m3\n",
      "m4\n",
      "m11\n",
      "m12\n",
      "m13\n",
      "m14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>m1score</th>\n",
       "      <th>m2score</th>\n",
       "      <th>m3score</th>\n",
       "      <th>m4score</th>\n",
       "      <th>m11score</th>\n",
       "      <th>m12score</th>\n",
       "      <th>m13score</th>\n",
       "      <th>m14score</th>\n",
       "      <th>sum_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>gjalexei asked whether anti editorializing pol...</td>\n",
       "      <td>-0.457048</td>\n",
       "      <td>0.188498</td>\n",
       "      <td>-0.176815</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.405754</td>\n",
       "      <td>-0.093755</td>\n",
       "      <td>-0.177341</td>\n",
       "      <td>-0.352116</td>\n",
       "      <td>-1.760883</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>looks like abuser please look thanks</td>\n",
       "      <td>0.312879</td>\n",
       "      <td>-0.226348</td>\n",
       "      <td>0.249732</td>\n",
       "      <td>0.368422</td>\n",
       "      <td>0.314798</td>\n",
       "      <td>-0.076618</td>\n",
       "      <td>0.255697</td>\n",
       "      <td>0.348907</td>\n",
       "      <td>1.547470</td>\n",
       "      <td>3355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>confess complete apparently blissful ignorance...</td>\n",
       "      <td>0.022502</td>\n",
       "      <td>0.150208</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.070720</td>\n",
       "      <td>0.052958</td>\n",
       "      <td>0.094190</td>\n",
       "      <td>0.032764</td>\n",
       "      <td>-0.038913</td>\n",
       "      <td>0.419730</td>\n",
       "      <td>2567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>freud ideas certainly much discussed today wou...</td>\n",
       "      <td>-0.308689</td>\n",
       "      <td>0.101604</td>\n",
       "      <td>-0.375382</td>\n",
       "      <td>-0.464779</td>\n",
       "      <td>-0.273844</td>\n",
       "      <td>-0.101876</td>\n",
       "      <td>-0.350290</td>\n",
       "      <td>-0.495752</td>\n",
       "      <td>-2.269008</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>laundry list stupid allegations scooped god kn...</td>\n",
       "      <td>0.046197</td>\n",
       "      <td>0.317173</td>\n",
       "      <td>0.165799</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>0.128581</td>\n",
       "      <td>0.343045</td>\n",
       "      <td>0.233642</td>\n",
       "      <td>0.142724</td>\n",
       "      <td>1.495305</td>\n",
       "      <td>3317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>504235362</td>\n",
       "      <td>go away annoying vandal</td>\n",
       "      <td>0.152712</td>\n",
       "      <td>-0.421490</td>\n",
       "      <td>0.134088</td>\n",
       "      <td>-0.010699</td>\n",
       "      <td>0.118355</td>\n",
       "      <td>-0.099579</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.005427</td>\n",
       "      <td>-0.030752</td>\n",
       "      <td>2156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>504235566</td>\n",
       "      <td>user vandal</td>\n",
       "      <td>-0.082836</td>\n",
       "      <td>-0.769679</td>\n",
       "      <td>-0.026129</td>\n",
       "      <td>-0.314493</td>\n",
       "      <td>-0.135856</td>\n",
       "      <td>-0.343289</td>\n",
       "      <td>-0.070324</td>\n",
       "      <td>-0.387961</td>\n",
       "      <td>-2.130567</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>504308177</td>\n",
       "      <td>sorry sound like pain one following tad stalki...</td>\n",
       "      <td>-0.530685</td>\n",
       "      <td>0.124866</td>\n",
       "      <td>-0.555368</td>\n",
       "      <td>-0.369778</td>\n",
       "      <td>-0.472119</td>\n",
       "      <td>-0.201527</td>\n",
       "      <td>-0.502755</td>\n",
       "      <td>-0.445282</td>\n",
       "      <td>-2.952648</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>504570375</td>\n",
       "      <td>well pretty fuck ing irrelevant unblocked aint</td>\n",
       "      <td>0.504162</td>\n",
       "      <td>1.647653</td>\n",
       "      <td>0.603563</td>\n",
       "      <td>0.718359</td>\n",
       "      <td>0.649643</td>\n",
       "      <td>1.158418</td>\n",
       "      <td>0.708011</td>\n",
       "      <td>0.715865</td>\n",
       "      <td>6.705675</td>\n",
       "      <td>5496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>504598250</td>\n",
       "      <td>team name great britain northern ireland blind...</td>\n",
       "      <td>0.059553</td>\n",
       "      <td>-0.050119</td>\n",
       "      <td>-0.089910</td>\n",
       "      <td>-0.006501</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>-0.080423</td>\n",
       "      <td>0.021455</td>\n",
       "      <td>-0.098706</td>\n",
       "      <td>2092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id                                               text   m1score  \\\n",
       "0         114890  gjalexei asked whether anti editorializing pol... -0.457048   \n",
       "1         732895               looks like abuser please look thanks  0.312879   \n",
       "2        1139051  confess complete apparently blissful ignorance...  0.022502   \n",
       "3        1434512  freud ideas certainly much discussed today wou... -0.308689   \n",
       "4        2084821  laundry list stupid allegations scooped god kn...  0.046197   \n",
       "...          ...                                                ...       ...   \n",
       "7532   504235362                            go away annoying vandal  0.152712   \n",
       "7533   504235566                                        user vandal -0.082836   \n",
       "7534   504308177  sorry sound like pain one following tad stalki... -0.530685   \n",
       "7535   504570375     well pretty fuck ing irrelevant unblocked aint  0.504162   \n",
       "7536   504598250  team name great britain northern ireland blind...  0.059553   \n",
       "\n",
       "       m2score   m3score   m4score  m11score  m12score  m13score  m14score  \\\n",
       "0     0.188498 -0.176815 -0.286551 -0.405754 -0.093755 -0.177341 -0.352116   \n",
       "1    -0.226348  0.249732  0.368422  0.314798 -0.076618  0.255697  0.348907   \n",
       "2     0.150208  0.035300  0.070720  0.052958  0.094190  0.032764 -0.038913   \n",
       "3     0.101604 -0.375382 -0.464779 -0.273844 -0.101876 -0.350290 -0.495752   \n",
       "4     0.317173  0.165799  0.118146  0.128581  0.343045  0.233642  0.142724   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7532 -0.421490  0.134088 -0.010699  0.118355 -0.099579  0.101288 -0.005427   \n",
       "7533 -0.769679 -0.026129 -0.314493 -0.135856 -0.343289 -0.070324 -0.387961   \n",
       "7534  0.124866 -0.555368 -0.369778 -0.472119 -0.201527 -0.502755 -0.445282   \n",
       "7535  1.647653  0.603563  0.718359  0.649643  1.158418  0.708011  0.715865   \n",
       "7536 -0.050119 -0.089910 -0.006501  0.029699  0.017540 -0.080423  0.021455   \n",
       "\n",
       "      sum_score  score  \n",
       "0     -1.760883    701  \n",
       "1      1.547470   3355  \n",
       "2      0.419730   2567  \n",
       "3     -2.269008    388  \n",
       "4      1.495305   3317  \n",
       "...         ...    ...  \n",
       "7532  -0.030752   2156  \n",
       "7533  -2.130567    464  \n",
       "7534  -2.952648    118  \n",
       "7535   6.705675   5496  \n",
       "7536  -0.098706   2092  \n",
       "\n",
       "[7537 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sum_score'] = 0\n",
    "for k, v in dic_omomi.items():\n",
    "    print(k)\n",
    "    df_test['sum_score'] += df_test[f'{k}score'] * v\n",
    "df_test['score'] = rankdata(df_test['sum_score'], method='ordinal') # 同値に無理やり順位を付ける場合はordinal\n",
    "df_test[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ae557",
   "metadata": {
    "papermill": {
     "duration": 0.035895,
     "end_time": "2022-02-06T15:03:46.130597",
     "exception": false,
     "start_time": "2022-02-06T15:03:46.094702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d1fbd",
   "metadata": {
    "papermill": {
     "duration": 0.035683,
     "end_time": "2022-02-06T15:03:46.202667",
     "exception": false,
     "start_time": "2022-02-06T15:03:46.166984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b05455",
   "metadata": {
    "papermill": {
     "duration": 0.035689,
     "end_time": "2022-02-06T15:03:46.274712",
     "exception": false,
     "start_time": "2022-02-06T15:03:46.239023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d5113",
   "metadata": {
    "papermill": {
     "duration": 0.03685,
     "end_time": "2022-02-06T15:03:46.347469",
     "exception": false,
     "start_time": "2022-02-06T15:03:46.310619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2719.957881,
   "end_time": "2022-02-06T15:03:48.005316",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-06T14:18:28.047435",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
