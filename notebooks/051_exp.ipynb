{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef0dc98",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1602084551218-a28205125639?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2070&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353168d",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-block alert-info'\n",
    "     style = 'background-color:#4c1c84;\n",
    "              color:#eeebf1;\n",
    "              border-width:5px;\n",
    "              border-color:#4c1c84;\n",
    "              font-family:Comic Sans MS;\n",
    "              border-radius: 50px 50px'>\n",
    "    <p style = 'font-size:24px'>Exp 051</p>\n",
    "    <a href = \"#Config\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">1.Config</a><br>\n",
    "    <a href = \"#Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">2.Settings</a><br>\n",
    "    <a href = \"#Data-Load\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">3.Data Load</a><br>\n",
    "    <a href = \"#Pytorch-Settings\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">4.Pytorch Settings</a><br>\n",
    "    <a href = \"#Training\"\n",
    "       style = \"color:#eeebf1;\n",
    "                font-size:14px\">5.Training</a><br>\n",
    "</div>\n",
    "\n",
    "<p style = 'font-size:24px;\n",
    "            color:#4c1c84'>\n",
    "    実施したこと\n",
    "</p>\n",
    "    <li style = \"color:#4c1c84;\n",
    "                font-size:14px\">RoBERTa-ConcatLayer</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6ce9d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Config\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dc25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/utils/iterative-stratification/\")\n",
    "sys.path.append(\"../src/utils/detoxify\")\n",
    "sys.path.append(\"../src/utils/coral-pytorch/\")\n",
    "sys.path.append(\"../src/utils/pyspellchecker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f74d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ../src/utils/faiss/\n",
      "Requirement already satisfied: faiss-gpu==1.6.3 in /opt/conda/lib/python3.7/site-packages (1.6.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from faiss-gpu==1.6.3) (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links ../src/utils/faiss/ faiss-gpu==1.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38b2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 17:45:25.582949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import psutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "from box import Box\n",
    "from typing import Optional\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "\n",
    "from tqdm.auto import tqdm as tqdmp\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "tqdmp.pandas()\n",
    "\n",
    "## Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, AutoModelForSequenceClassification\n",
    "from transformers import RobertaModel, RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import LukeTokenizer, LukeModel, LukeConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertForMaskedLM\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from transformers import DebertaTokenizer, DebertaModel\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning import LightningDataModule, LightningDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import rankdata\n",
    "from cuml.svm import SVR as cuml_SVR\n",
    "from cuml.linear_model import Ridge as cuml_Ridge\n",
    "import cudf\n",
    "from detoxify import Detoxify\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from ast import literal_eval\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import spacy\n",
    "from scipy.stats import sem\n",
    "from copy import deepcopy\n",
    "from spellchecker import SpellChecker\n",
    "from typing import Text, Set, List\n",
    "\n",
    "import faiss\n",
    "import cudf, cuml, cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer as cuTfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors as cuNearestNeighbors\n",
    "from cuml.decomposition.tsvd import TruncatedSVD as cuTruncatedSVD\n",
    "from cuml.decomposition.pca import PCA as cuPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e8912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "config = {\n",
    "    \"exp_comment\":\"Psuedo Labeling\",\n",
    "    \"seed\": 1234,\n",
    "    \"root\": \"/content/drive/MyDrive/kaggle/Jigsaw/raw\",\n",
    "    \"n_fold\": 5,\n",
    "    \"epoch\": 5,\n",
    "    \"max_length\": 256,\n",
    "    \"environment\": \"AWS\",\n",
    "    \"project\": \"Jigsaw\",\n",
    "    \"entity\": \"dataskywalker\",\n",
    "    \"exp_name\": \"051_exp\",\n",
    "    \"margin\": 0.5,\n",
    "    \"train_fold\": [0, 1, 2, 3, 4],\n",
    "\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 1,\n",
    "        \"accumulate_grad_batches\": 8,\n",
    "        \"progress_bar_refresh_rate\": 1,\n",
    "        \"fast_dev_run\": True,\n",
    "        \"num_sanity_val_steps\": 0,\n",
    "    },\n",
    "\n",
    "    \"train_loader\": {\n",
    "        \"batch_size\": 8,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": True,\n",
    "    },\n",
    "\n",
    "    \"valid_loader\": {\n",
    "        \"batch_size\": 2,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"test_loader\": {\n",
    "        \"batch_size\": 2,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"drop_last\": False,\n",
    "    },\n",
    "\n",
    "    \"backbone\": {\n",
    "        \"name\": \"roberta-base\",\n",
    "        \"output_dim\": 1,\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"torch.optim.AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 1e-6,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"name\": \"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\",\n",
    "        \"params\": {\n",
    "            \"T_0\": 20,\n",
    "            \"eta_min\": 0,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"loss\": \"nn.MarginRankingLoss\",\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "config.tokenizer = RobertaTokenizer.from_pretrained(config.backbone.name)\n",
    "config.model = RobertaModel.from_pretrained(config.backbone.name)\n",
    "# pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce4a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config.tokenizer.save_pretrained(f\"../data/processed/{config.backbone.name}\")\n",
    "pretrain_model = RobertaModel.from_pretrained(config.backbone.name)\n",
    "pretrain_model.save_pretrained(f\"../data/processed/{config.backbone.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c33232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your environment is 'AWS'.\n",
      "INPUT_DIR is /mnt/work/data/kaggle/Jigsaw\n",
      "MODEL_DIR is ../models/051_exp\n",
      "OUTPUT_DIR is ../data/interim/051_exp\n",
      "UTIL_DIR is /mnt/work/shimizu/kaggle/PetFinder/src/utils\n"
     ]
    }
   ],
   "source": [
    "# 個人的にAWSやKaggle環境やGoogle Colabを行ったり来たりしているのでまとめています\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if config.environment == 'AWS':\n",
    "    \n",
    "    INPUT_DIR = Path('/mnt/work/data/kaggle/Jigsaw/')\n",
    "    MODEL_DIR = Path(f'../models/{config.exp_name}/')\n",
    "    OUTPUT_DIR = Path(f'../data/interim/{config.exp_name}/')\n",
    "    UTIL_DIR = Path('/mnt/work/shimizu/kaggle/PetFinder/src/utils')\n",
    "    \n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"Your environment is 'AWS'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\\nUTIL_DIR is {UTIL_DIR}\")\n",
    "    \n",
    "    \n",
    "elif config.environment == 'Kaggle':\n",
    "    INPUT_DIR = Path('../input/*****')\n",
    "    MODEL_DIR = Path('./')\n",
    "    OUTPUT_DIR = Path('./')\n",
    "    print(f\"Your environment is 'Kaggle'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "\n",
    "    \n",
    "elif config.environment == 'Colab':\n",
    "    INPUT_DIR = Path('/content/drive/MyDrive/kaggle/Jigsaw/raw')\n",
    "    BASE_DIR = Path(\"/content/drive/MyDrive/kaggle/Jigsaw/interim\")\n",
    "\n",
    "    MODEL_DIR = BASE_DIR / f'{config.exp_name}'\n",
    "    OUTPUT_DIR = BASE_DIR / f'{config.exp_name}/'\n",
    "\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print('Please Mount your Google Drive.')\n",
    "    else:\n",
    "        print(f\"Your environment is 'Colab'.\\nINPUT_DIR is {INPUT_DIR}\\nMODEL_DIR is {MODEL_DIR}\\nOUTPUT_DIR is {OUTPUT_DIR}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please choose 'AWS' or 'Kaggle' or 'Colab'.\\nINPUT_DIR is not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7253542b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed固定\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689c4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 処理時間計測\n",
    "@contextmanager\n",
    "def timer(name:str, slack:bool=False):\n",
    "    t0 = time.time()\n",
    "    p = psutil.Process(os.getpid())\n",
    "    m0 = p.memory_info()[0] / 2. ** 30\n",
    "    print(f'<< {name} >> Start')\n",
    "    yield\n",
    "    \n",
    "    m1 = p.memory_info()[0] / 2. ** 30\n",
    "    delta = m1 - m0\n",
    "    sign = '+' if delta >= 0 else '-'\n",
    "    delta = math.fabs(delta)\n",
    "    \n",
    "    print(f\"<< {name} >> {m1:.1f}GB({sign}{delta:.1f}GB):{time.time() - t0:.1f}sec\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e14e3",
   "metadata": {
    "id": "zWE2XhHeTFos"
   },
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Data Load\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd9d40b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DFxNX0CTD9t",
    "outputId": "240b449b-9f09-4519-d155-b4f865053621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/sample_submission.csv\n",
      "/mnt/work/data/kaggle/Jigsaw/validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "## Data Check\n",
    "for dirnames, _, filenames in os.walk(INPUT_DIR):\n",
    "    \n",
    "    for filename in filenames:\n",
    "\n",
    "        print(f'{dirnames}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ff1a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1      732895  Looks like be have an abuser , can you please ...\n",
       "2     1139051  I confess to having complete (and apparently b...\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4     2084821  It is not just you. This is a laundry list of ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/validation_data.csv\")\n",
    "test_df = pd.read_csv(\"/mnt/work/data/kaggle/Jigsaw/comments_to_score.csv\")\n",
    "\n",
    "display(val_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "558827fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< Count less text & more text >> Start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>less_count</th>\n",
       "      <th>more_count</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nThe comment directly above this one are fr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nwhy should people have to read crap posted...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nGo F yourself you cottonheadednittymuggins.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nU POUR ADMIN, U UPDATE VANDAL COUNT, WHILE R...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n koreans claim  \\n\\ni see youve seen the ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14246</th>\n",
       "      <td>{{unblock|The reason I used sockpuppets was to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14247</th>\n",
       "      <td>{{unblock}}  BECAUSE BAIL OUT IS THE BEST FUCK...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14248</th>\n",
       "      <td>|Christopher Connor]]. I am off to my daily ma...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14249</th>\n",
       "      <td>}} \\n\\nSomeone should address this fucking pro...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>~What's with you that you're so annoying and p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14251 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  less_count  \\\n",
       "0      \\n\\nThe comment directly above this one are fr...         1.0   \n",
       "1      \\n\\nwhy should people have to read crap posted...         1.0   \n",
       "2          \\nGo F yourself you cottonheadednittymuggins.         1.0   \n",
       "3      \\nU POUR ADMIN, U UPDATE VANDAL COUNT, WHILE R...         3.0   \n",
       "4       \\n\\n koreans claim  \\n\\ni see youve seen the ...         4.0   \n",
       "...                                                  ...         ...   \n",
       "14246  {{unblock|The reason I used sockpuppets was to...         0.0   \n",
       "14247  {{unblock}}  BECAUSE BAIL OUT IS THE BEST FUCK...         0.0   \n",
       "14248  |Christopher Connor]]. I am off to my daily ma...         0.0   \n",
       "14249  }} \\n\\nSomeone should address this fucking pro...         0.0   \n",
       "14250  ~What's with you that you're so annoying and p...         0.0   \n",
       "\n",
       "       more_count    target  \n",
       "0             2.0  0.666667  \n",
       "1             8.0  0.888889  \n",
       "2             2.0  0.666667  \n",
       "3             0.0  0.000000  \n",
       "4             2.0  0.333333  \n",
       "...           ...       ...  \n",
       "14246         3.0  1.000000  \n",
       "14247         3.0  1.000000  \n",
       "14248         6.0  1.000000  \n",
       "14249         1.0  1.000000  \n",
       "14250         3.0  1.000000  \n",
       "\n",
       "[14251 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<< Count less text & more text >> 2.6GB(+0.0GB):0.1sec\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Count less text & more text\"):\n",
    "    less_df = val_df.groupby([\"less_toxic\"])[\"worker\"].agg(\"count\").reset_index()\n",
    "    less_df.columns = [\"text\", \"less_count\"]\n",
    "\n",
    "    more_df = val_df.groupby([\"more_toxic\"])[\"worker\"].agg(\"count\").reset_index()\n",
    "    more_df.columns = [\"text\", \"more_count\"]\n",
    "    \n",
    "    text_df = pd.merge(\n",
    "        less_df,\n",
    "        more_df,\n",
    "        on=\"text\",\n",
    "        how=\"outer\"\n",
    "    )\n",
    "\n",
    "    text_df[\"less_count\"] = text_df[\"less_count\"].fillna(0)\n",
    "    text_df[\"more_count\"] = text_df[\"more_count\"].fillna(0)\n",
    "    \n",
    "    text_df[\"target\"] = text_df[\"more_count\"]/(text_df[\"less_count\"] + text_df[\"more_count\"])\n",
    "    \n",
    "    display(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cbfdf",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Make Fold\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2464c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = set(val_df[\"less_toxic\"].to_list() + val_df[\"more_toxic\"].to_list())\n",
    "# text2id = {t:id for id,t in enumerate(texts)}\n",
    "# val_df['less_id'] = val_df['less_toxic'].map(text2id)\n",
    "# val_df['more_id'] = val_df['more_toxic'].map(text2id)\n",
    "# val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f25ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_ids = len(text2id)\n",
    "# idarr = np.zeros((len_ids, len_ids), dtype=bool)\n",
    "\n",
    "# for lid, mid in val_df[['less_id', 'more_id']].values:\n",
    "#     min_id = min(lid, mid)\n",
    "#     max_id = max(lid, mid)\n",
    "#     idarr[max_id, min_id] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adbb056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_ids(i, this_list):\n",
    "#     for j in range(len_ids):\n",
    "#         if idarr[i, j]:\n",
    "#             idarr[i, j] = False\n",
    "#             this_list.append(j)\n",
    "#             this_list = add_ids(j,this_list)\n",
    "#             #print(j,i)\n",
    "#     for j in range(i+1,len_ids):\n",
    "#         if idarr[j, i]:\n",
    "#             idarr[j, i] = False\n",
    "#             this_list.append(j)\n",
    "#             this_list = add_ids(j,this_list)\n",
    "#             #print(j,i)\n",
    "#     return this_list\n",
    "\n",
    "# group_list = []\n",
    "# for i in tqdm(range(len_ids)):\n",
    "#     for j in range(i+1,len_ids):\n",
    "#         if idarr[j, i]:\n",
    "#             this_list = add_ids(i,[i])\n",
    "# #             print(this_list)\n",
    "#             group_list.append(this_list)\n",
    "\n",
    "# id2groupid = {}\n",
    "# for gid,ids in enumerate(group_list):\n",
    "#     for id in ids:\n",
    "#         id2groupid[id] = gid\n",
    "\n",
    "# val_df['less_gid'] = val_df['less_id'].map(id2groupid)\n",
    "# val_df['more_gid'] = val_df['more_id'].map(id2groupid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a59cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('unique text counts:', len_ids)\n",
    "# print('grouped text counts:', len(group_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51fafa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now we can use GroupKFold with group id\n",
    "# group_kfold = GroupKFold(n_splits=config.n_fold)\n",
    "\n",
    "# # Since df.less_gid and df.more_gid are the same, let's use df.less_gid here.\n",
    "# for fold, (trn, val) in enumerate(group_kfold.split(val_df, val_df, val_df.less_gid)): \n",
    "#     val_df.loc[val , \"fold\"] = fold\n",
    "\n",
    "# val_df[\"fold\"] = val_df[\"fold\"].astype(int)\n",
    "# val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "223add0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.to_csv(OUTPUT_DIR/\"val_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32e622",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:45px; font-family:Comic Sans MS ; font-weight : normal; background-color: #4c1c84 ; color : #eeebf1; text-align: center; border-radius: 100px 100px;\">\n",
    "    Pytorch Dataset\n",
    "</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b371065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_id</th>\n",
       "      <th>more_id</th>\n",
       "      <th>less_gid</th>\n",
       "      <th>more_gid</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>12975</td>\n",
       "      <td>7916</td>\n",
       "      <td>1478</td>\n",
       "      <td>1478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>9110</td>\n",
       "      <td>3902</td>\n",
       "      <td>604</td>\n",
       "      <td>604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>724</td>\n",
       "      <td>377</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>8540</td>\n",
       "      <td>9299</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>9227</td>\n",
       "      <td>5952</td>\n",
       "      <td>1736</td>\n",
       "      <td>1736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  less_id  more_id  \\\n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...    12975     7916   \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...     9110     3902   \n",
       "2  \"Atom you don't believe actual photos of mastu...      724      377   \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...     8540     9299   \n",
       "4           hey \\n\\nway to support nazis, you racist     9227     5952   \n",
       "\n",
       "   less_gid  more_gid  fold  \n",
       "0      1478      1478     3  \n",
       "1       604       604     2  \n",
       "2       356       356     4  \n",
       "3       228       228     4  \n",
       "4      1736      1736     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df = pd.read_csv(OUTPUT_DIR/\"val_df.csv\")\n",
    "display(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a92edbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset:\n",
    "    \n",
    "    def __init__(self, df, tokenizer, max_length, mode):\n",
    "        \n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            self.more_toxic = df[\"more_toxic\"].values\n",
    "            self.less_toxic = df[\"less_toxic\"].values\n",
    "            \n",
    "        elif self.mode == \"valid\":\n",
    "            self.more_toxic = df[\"more_toxic\"].values\n",
    "            self.less_toxic = df[\"less_toxic\"].values\n",
    "            \n",
    "        else:\n",
    "            self.text = df[\"text\"].values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            \n",
    "            more_toxic = self.more_toxic[index]\n",
    "            less_toxic = self.less_toxic[index]\n",
    "\n",
    "            inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                more_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "\n",
    "            inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                less_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            target = 1\n",
    "\n",
    "            more_toxic_ids = inputs_more_toxic[\"input_ids\"]\n",
    "            more_toxic_mask = inputs_more_toxic[\"attention_mask\"]\n",
    "            more_token_type_ids = inputs_more_toxic[\"token_type_ids\"]\n",
    "\n",
    "            less_toxic_ids = inputs_less_toxic[\"input_ids\"]\n",
    "            less_toxic_mask = inputs_less_toxic[\"attention_mask\"]\n",
    "            less_token_type_ids = inputs_less_toxic[\"token_type_ids\"]\n",
    "            \n",
    "            return {\n",
    "                'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n",
    "                'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n",
    "                'more_token_type_ids': torch.tensor(more_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n",
    "                'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n",
    "                'less_token_type_ids': torch.tensor(less_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        elif self.mode == \"valid\":\n",
    "            \n",
    "            more_toxic = self.more_toxic[index]\n",
    "            less_toxic = self.less_toxic[index]\n",
    "\n",
    "            inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                more_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "\n",
    "            inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                less_toxic,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            target = 1\n",
    "\n",
    "            more_toxic_ids = inputs_more_toxic[\"input_ids\"]\n",
    "            more_toxic_mask = inputs_more_toxic[\"attention_mask\"]\n",
    "            more_token_type_ids = inputs_more_toxic[\"token_type_ids\"]\n",
    "\n",
    "            less_toxic_ids = inputs_less_toxic[\"input_ids\"]\n",
    "            less_toxic_mask = inputs_less_toxic[\"attention_mask\"]\n",
    "            less_token_type_ids = inputs_less_toxic[\"token_type_ids\"]\n",
    "            \n",
    "            return {\n",
    "                'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n",
    "                'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n",
    "                'more_token_type_ids': torch.tensor(more_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n",
    "                'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n",
    "                'less_token_type_ids': torch.tensor(less_token_type_ids, dtype=torch.long),\n",
    "                \n",
    "                'target': torch.tensor(target, dtype=torch.float)\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            text = self.text[index]\n",
    "            \n",
    "            inputs_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=True,\n",
    "                max_length = self.max_len,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            \n",
    "            text_ids = inputs_text[\"input_ids\"]\n",
    "            text_mask = inputs_text[\"attention_mask\"]\n",
    "            text_token_type_ids = inputs_text[\"token_type_ids\"]\n",
    "\n",
    "            return {\n",
    "                'text_ids': torch.tensor(text_ids, dtype=torch.long),\n",
    "                'text_mask': torch.tensor(text_mask, dtype=torch.long),\n",
    "                'text_token_type_ids': torch.tensor(text_token_type_ids, dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feafa024",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    DataModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6be9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, valid_df, test_df, cfg):\n",
    "\n",
    "        super().__init__()\n",
    "        self._train_df = train_df\n",
    "        self._valid_df = valid_df\n",
    "        self._test_df = test_df\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._train_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"train\",\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._valid_df, \n",
    "            tokenizer=self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"valid\",\n",
    "            )\n",
    "        return DataLoader(dataset, **self._cfg.valid_loader)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = JigsawDataset(\n",
    "            df=self._test_df,\n",
    "            tokenizer = self._cfg.tokenizer,\n",
    "            max_length=self._cfg.max_length,\n",
    "            mode=\"test\",\n",
    "        )\n",
    "\n",
    "        return DataLoader(dataset, **self._cfg.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be74a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataCheck\n",
    "seed_everything(config.seed)\n",
    "\n",
    "sample_dataloader = JigsawDataModule(val_df, val_df, test_df, config).train_dataloader()\n",
    "for data in sample_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3a32e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "torch.Size([8, 256, 768]) torch.Size([8, 12, 256, 256])\n",
      "torch.Size([8, 768]) torch.Size([8, 12, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"more_toxic_ids\"].size())\n",
    "print(data[\"more_toxic_mask\"].size())\n",
    "print(data[\"more_token_type_ids\"].size())\n",
    "print(data[\"target\"].size())\n",
    "print(data[\"target\"])\n",
    "output = config.model(\n",
    "    data[\"more_toxic_ids\"],\n",
    "    data[\"more_toxic_mask\"],\n",
    "    data[\"more_token_type_ids\"],\n",
    "    output_hidden_states=True,\n",
    "    output_attentions=True,\n",
    ")\n",
    "print(output[\"hidden_states\"][-1].size(), output[\"attentions\"][-1].size())\n",
    "print(output[\"hidden_states\"][-1][:, 1, :].size(), output[\"attentions\"][-1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b0b40",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    LigitningModule\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d007010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=config.margin)(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f2ddd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, cfg, fold_num):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.__build_model()\n",
    "        self.criterion = criterion\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.fold_num = fold_num\n",
    "        \n",
    "    def __build_model(self):\n",
    "        \n",
    "        self.base_model = RobertaModel.from_pretrained(\n",
    "            self.cfg.backbone.name\n",
    "        )\n",
    "#         print(f\"Use Model: {self.cfg.backbone.name}\")\n",
    "        self.norm = nn.LayerNorm(768*4)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.head = nn.Linear(768*4, self.cfg.backbone.output_dim)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        \n",
    "        output = self.base_model(\n",
    "            input_ids=ids, \n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        sequence_output = torch.cat(\n",
    "            [output[\"hidden_states\"][-1*i][:,0] for i in [1, 2, 3, 4]],\n",
    "            dim=1\n",
    "        )\n",
    "        feature = self.norm(sequence_output)\n",
    "        feature = self.drop(feature)\n",
    "        out = self.head(feature)\n",
    "\n",
    "        return {\n",
    "            \"logits\":out, \n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        more_toxic_ids = batch['more_toxic_ids']\n",
    "        more_toxic_mask = batch['more_toxic_mask']\n",
    "        more_text_token_type_ids = batch['more_token_type_ids']\n",
    "        \n",
    "        less_toxic_ids = batch['less_toxic_ids']\n",
    "        less_toxic_mask = batch['less_toxic_mask']\n",
    "        less_text_token_type_ids = batch['less_token_type_ids']\n",
    "        \n",
    "        targets = batch['target']\n",
    "        \n",
    "        more_outputs = self.forward(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        less_outputs = self.forward(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        loss = self.criterion(more_outputs[\"logits\"], less_outputs[\"logits\"], targets)\n",
    "\n",
    "        \n",
    "        return {\n",
    "            \"loss\":loss,\n",
    "            \"targets\":targets,\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "\n",
    "        for out in training_step_outputs:\n",
    "\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "\n",
    "        logs = {f\"train_loss/fold{self.fold_num+1}\": meanloss,}\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        more_toxic_ids = batch['more_toxic_ids']\n",
    "        more_toxic_mask = batch['more_toxic_mask']\n",
    "        more_text_token_type_ids = batch['more_token_type_ids']\n",
    "        \n",
    "        less_toxic_ids = batch['less_toxic_ids']\n",
    "        less_toxic_mask = batch['less_toxic_mask']\n",
    "        less_text_token_type_ids = batch['less_token_type_ids']\n",
    "        \n",
    "        targets = batch['target']\n",
    "\n",
    "        more_outputs = self.forward(\n",
    "            more_toxic_ids, \n",
    "            more_toxic_mask,\n",
    "            more_text_token_type_ids\n",
    "        )\n",
    "        \n",
    "        less_outputs = self.forward(\n",
    "            less_toxic_ids, \n",
    "            less_toxic_mask,\n",
    "            less_text_token_type_ids\n",
    "        )\n",
    "\n",
    "        \n",
    "        outputs = more_outputs[\"logits\"] - less_outputs[\"logits\"]\n",
    "        logits = outputs.clone()[:, 0]\n",
    "\n",
    "        logits[logits > 0] = 1\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, targets)\n",
    "\n",
    "        return {\n",
    "            \"loss\":loss,\n",
    "            \"pred\":outputs,\n",
    "            \"targets\":targets,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "\n",
    "        loss_list = []\n",
    "        pred_list = []\n",
    "        target_list = []\n",
    "\n",
    "        for out in validation_step_outputs:\n",
    "            loss_list.extend([out[\"loss\"].cpu().detach().tolist()])\n",
    "            pred_list.append(out[\"pred\"][:, 0].detach().cpu().numpy())\n",
    "            target_list.append(out[\"targets\"].detach().cpu().numpy())\n",
    "\n",
    "        meanloss = sum(loss_list)/len(loss_list)\n",
    "        pred_list = np.concatenate(pred_list)\n",
    "        pred_count = sum(x>0 for x in pred_list)/len(pred_list)\n",
    "\n",
    "        logs = {\n",
    "            f\"valid_loss/fold{self.fold_num+1}\":meanloss,\n",
    "            f\"valid_acc/fold{self.fold_num+1}\":pred_count,\n",
    "        }\n",
    "\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True\n",
    "        )\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = eval(self.cfg.optimizer.name)(\n",
    "            self.parameters(), **self.cfg.optimizer.params\n",
    "        )\n",
    "\n",
    "        self.scheduler = eval(self.cfg.scheduler.name)(\n",
    "            optimizer, **self.cfg.scheduler.params\n",
    "        )\n",
    "        \n",
    "        scheduler = {\"scheduler\": self.scheduler, \"interval\": \"step\",}\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b50d1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    Training\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7215e225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_id</th>\n",
       "      <th>more_id</th>\n",
       "      <th>less_gid</th>\n",
       "      <th>more_gid</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>12975</td>\n",
       "      <td>7916</td>\n",
       "      <td>1478</td>\n",
       "      <td>1478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>9110</td>\n",
       "      <td>3902</td>\n",
       "      <td>604</td>\n",
       "      <td>604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>724</td>\n",
       "      <td>377</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>8540</td>\n",
       "      <td>9299</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>9227</td>\n",
       "      <td>5952</td>\n",
       "      <td>1736</td>\n",
       "      <td>1736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  less_id  more_id  \\\n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...    12975     7916   \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...     9110     3902   \n",
       "2  \"Atom you don't believe actual photos of mastu...      724      377   \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...     8540     9299   \n",
       "4           hey \\n\\nway to support nazis, you racist     9227     5952   \n",
       "\n",
       "   less_gid  more_gid  fold  \n",
       "0      1478      1478     3  \n",
       "1       604       604     2  \n",
       "2       356       356     4  \n",
       "3       228       228     4  \n",
       "4      1736      1736     1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skf = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
    "\n",
    "# for fold, (_, val_idx) in enumerate(skf.split(X=val_df, y=val_df[\"worker\"])):\n",
    "#     val_df.loc[val_idx, \"kfold\"] = int(fold)\n",
    "\n",
    "# val_df[\"kfold\"] = val_df[\"kfold\"].astype(int)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de66b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Debug\n",
    "# config.trainer.fast_dev_run = True\n",
    "# config.backbone.output_dim = 1\n",
    "\n",
    "# for fold in config.train_fold:\n",
    "    \n",
    "#     print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "#     df_train = val_df[val_df.fold != fold].reset_index(drop=True)\n",
    "#     df_valid = val_df[val_df.fold != fold].reset_index(drop=True)\n",
    "\n",
    "#     datamodule = JigsawDataModule(df_train, df_valid, test_df, config)\n",
    "#     sample_dataloader = JigsawDataModule(df_train, df_valid, test_df, config).train_dataloader()\n",
    "\n",
    "#     config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "#     model = JigsawModel(config, fold)\n",
    "#     lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "#     loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "#         filename=f\"best_acc_fold{fold+1}\",\n",
    "#         monitor=f\"valid_acc/fold{fold+1}\",\n",
    "#         save_top_k=1,\n",
    "#         mode=\"max\",\n",
    "#         save_last=False,\n",
    "#         dirpath=MODEL_DIR,\n",
    "#         save_weights_only=True,\n",
    "#     )\n",
    "\n",
    "#     wandb_logger = WandbLogger(\n",
    "#         project=config.project, \n",
    "#         entity=config.entity,\n",
    "#         name = f\"{config.exp_name}\",\n",
    "#         tags = ['RoBERTa-Base', \"MarginRankLoss\"]\n",
    "#     )\n",
    "\n",
    "#     lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=config.epoch,\n",
    "#         callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "# #         deterministic=True,\n",
    "#         logger=[wandb_logger],\n",
    "#         **config.trainer\n",
    "#     )\n",
    "#     trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d7913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdataskywalker\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-02-05 11:38:25.178936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">051_exp</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dataskywalker/Jigsaw/runs/6qduq7kv\" target=\"_blank\">https://wandb.ai/dataskywalker/Jigsaw/runs/6qduq7kv</a><br/>\n",
       "                Run data is saved locally in <code>/mnt/work/shimizu/kaggle/Jigsaw/notebooks/wandb/run-20220205_113823-6qduq7kv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm    │  6.1 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout      │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear       │  3.1 K │\n",
       "└───┴────────────┴──────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm    │  6.1 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout      │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear       │  3.1 K │\n",
       "└───┴────────────┴──────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3863e7ef5e104ff0bd5952bc93034e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">6021/6021</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:14:17 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">20.10it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.368 v_num:    </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">q7kv valid_loss/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.512 valid_acc/fold1:</span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.681                 </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train_loss/fold1:     </span>\n",
       "                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.051                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 4    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m6021/6021\u001b[0m \u001b[38;5;245m0:14:17 • 0:00:00\u001b[0m \u001b[38;5;249m20.10it/s\u001b[0m \u001b[37mloss: 0.368 v_num:    \u001b[0m\n",
       "                                                                       \u001b[37mq7kv valid_loss/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.512 valid_acc/fold1:\u001b[0m\n",
       "                                                                       \u001b[37m0.681                 \u001b[0m\n",
       "                                                                       \u001b[37mtrain_loss/fold1:     \u001b[0m\n",
       "                                                                       \u001b[37m0.051                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel │  124 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ norm       │ LayerNorm    │  6.1 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ drop       │ Dropout      │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head       │ Linear       │  3.1 K │\n",
       "└───┴────────────┴──────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel │  124 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ norm       │ LayerNorm    │  6.1 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ drop       │ Dropout      │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head       │ Linear       │  3.1 K │\n",
       "└───┴────────────┴──────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                      \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                          \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                      \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                          \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203ac86a3b6c4a62abbf256d4e7888ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "config.trainer.fast_dev_run = False\n",
    "config.backbone.output_dim = 1\n",
    "\n",
    "for fold in config.train_fold:\n",
    "    \n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    df_train = val_df[val_df.fold != fold].reset_index(drop=True)\n",
    "    df_valid = val_df[val_df.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    datamodule = JigsawDataModule(df_train, df_valid, test_df, config)\n",
    "    sample_dataloader = JigsawDataModule(df_train, df_valid, test_df, config).train_dataloader()\n",
    "\n",
    "    config.scheduler.params.T_0 = config.epoch * len(sample_dataloader)\n",
    "    model = JigsawModel(config, fold)\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=MODEL_DIR,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=config.project, \n",
    "        entity=config.entity,\n",
    "        name = f\"{config.exp_name}\",\n",
    "        tags = ['RoBERTa-Base', \"MarginRankLoss\", \"ConcatLayer\"]\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epoch,\n",
    "        callbacks=[loss_checkpoint, lr_monitor, RichProgressBar()],\n",
    "#         deterministic=True,\n",
    "        logger=[wandb_logger],\n",
    "        **config.trainer\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b82e92",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:45px;\n",
    "             font-family:Comic Sans MS ;\n",
    "             font-weight : normal;\n",
    "             background-color: #eeebf1 ;\n",
    "             color : #4c1c84;\n",
    "             text-align: center; \n",
    "             border-radius: 100px 100px;\">\n",
    "    Inference\n",
    "</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d19e2f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\n\\n July 2011 \\n Please stop adding inapprop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PatrickFlaherty reverted my post 3 TIMES today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fradulent claim \\n\\nI am most certainly not a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuck off you son of a bitch!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\n\\n Do Some Research Before You Label A Fact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  \"\\n\\n July 2011 \\n Please stop adding inapprop...\n",
       "1  PatrickFlaherty reverted my post 3 TIMES today...\n",
       "2   Fradulent claim \\n\\nI am most certainly not a...\n",
       "3                      fuck off you son of a bitch!!\n",
       "4  \"\\n\\n Do Some Research Before You Label A Fact..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14251, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_df = pd.DataFrame()\n",
    "text_df[\"text\"] = list(set(val_df[\"less_toxic\"].unique().tolist() + val_df[\"more_toxic\"].unique().tolist()))\n",
    "\n",
    "display(text_df.head())\n",
    "display(text_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4f8f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device == cuda\n",
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold1  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a3701b985e42cb89e0dc3b27103b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold2  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3266faf28504154806dbbeda1a8585d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold3  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c23481123a4518af337176b9c81aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold4  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab34b33ccf943589d9074dc13618ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★★★★★★★★★★★★★★★★★★★★★★★  Fold5  ★★★★★★★★★★★★★★★★★★★★★★★★★\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8644dec02e14647b0f096601a2487ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Device == {device}\")\n",
    "\n",
    "PRED = np.zeros(len(text_df))\n",
    "\n",
    "for fold in config.train_fold:\n",
    "\n",
    "    pred_list = []\n",
    "    print(\"★\"*25, f\" Fold{fold+1} \", \"★\"*25)\n",
    "\n",
    "    test_dataloader = JigsawDataModule(val_df, val_df, text_df, config).test_dataloader()\n",
    "    model = JigsawModel(config, fold)\n",
    "\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=f\"best_acc_fold{fold+1}\",\n",
    "        monitor=f\"valid_acc/fold{fold+1}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        dirpath=\"../input/toxicroberta/\",\n",
    "    )\n",
    "    model = model.load_from_checkpoint(MODEL_DIR/f\"best_acc_fold{fold+1}.ckpt\", cfg=config, fold_num=fold)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    attention_list = []\n",
    "    feature_list = []\n",
    "    mask_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    for step, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "\n",
    "        text_ids = data[\"text_ids\"].to(device)\n",
    "        text_mask = data[\"text_mask\"].to(device)\n",
    "        text_token_type_ids = data[\"text_token_type_ids\"].to(device)\n",
    "        \n",
    "        mask_list.append(text_mask.detach().cpu().numpy())\n",
    "            \n",
    "        outputs = model(\n",
    "            text_ids, \n",
    "            text_mask,\n",
    "            text_token_type_ids,\n",
    "        )\n",
    "        \n",
    "        pred_list.append(outputs[\"logits\"][:, 0].detach().cpu().numpy())\n",
    "\n",
    "    PRED += np.concatenate(pred_list)/len(config.train_fold)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7bfeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df[\"target\"] = PRED\n",
    "text_df.to_pickle(OUTPUT_DIR/f\"{config.exp_name}__text_df.pkl\")\n",
    "# np.save(OUTPUT_DIR/'toxic-attention.npy', attention_array)\n",
    "# np.save(OUTPUT_DIR/'toxic-mask.npy', mask_array)\n",
    "# np.save(OUTPUT_DIR/'toxic-feature.npy', feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3a1e7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(text_df[\"target\"], color=\"#4c1c84\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8f464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
